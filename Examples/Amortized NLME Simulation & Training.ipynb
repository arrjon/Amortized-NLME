{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model\n",
    "\n",
    "## Simulation & Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bayesflow.simulation import GenerativeModel\n",
    "from bayesflow import diagnostics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8448e674c4b2ff95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde',\n",
    "              'pharmacokinetic_model', 'clairon_small_model'][2]\n",
    "if model_name == 'fröhlich-detailed' or model_name == 'pharmacokinetic_model' or 'clairon' in model_name:\n",
    "    # this is needed so julia is recognized correctly\n",
    "    from juliacall import Main as jl\n",
    "\n",
    "# specify which model to use\n",
    "network_idx = 15\n",
    "load_best_network = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show or save plots\n",
    "show_plots = True\n",
    "save_plots = False\n",
    "    \n",
    "# training params\n",
    "early_stopping = True  # if training should be stopped if no improvement on a validation set can be seen\n",
    "presimulate = False  # if simulations should be generated before or while training of the neural networks\n",
    "train_network = False  # if neural networks should be trained or only load (already trained) networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "To train your own model you should define \n",
    "```\n",
    "def batch_simulator(param_samples: np.ndarray, other_args) -> np.ndarray:\n",
    "```\n",
    "which takes in parameters in the form of (#simulations, #parameters) and a model-class of the form\n",
    "\n",
    "```\n",
    "class myModel(NlmeBaseAmortizer):\n",
    "    def __init__(self, name: str = 'myModel'):\n",
    "        # define names of parameters\n",
    "        param_names = ['name1', 'name2']\n",
    "\n",
    "        # define prior values (for log-parameters)\n",
    "        prior_mean = np.array([0, 0])\n",
    "        prior_cov = np.diag([1, 1])\n",
    "        self.prior_type = 'normal'\n",
    "\n",
    "        super().__init__(name=name,\n",
    "                         param_names=param_names,\n",
    "                         prior_mean=prior_mean,\n",
    "                         prior_cov=prior_cov)\n",
    "\n",
    "        self.simulator = Simulator(batch_simulator_fun=partial(batch_simulator,\n",
    "                                                                  other_args=other_args))\n",
    "```\n",
    "where you specify your parameters, a parameter-prior on the individual level (standard is normal distribution) and connect your `batch_simulator` to the model.\n",
    "\n",
    "In this notebook, the example models are loaded from an external file, where each model defines its own `batch_simulator` function, which is used to generate simulations and some other further helper function to generate plots etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf260c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "presimulation_path = '../data/'\n",
    "\n",
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    model = FroehlichModelSimple(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "    use_presimulation = False\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    model = FroehlichModelDetailed(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_froehlich_detailed'\n",
    "\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    model = FroehlichModelSDE(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_froehlich_sde'\n",
    "    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    model = PharmacokineticModel(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_pharma'\n",
    "    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    model = ClaironSmallModel(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_small_clairon'\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if show_plots:\n",
    "    # the example models all support this function (which is optional)\n",
    "    model.plot_example()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f64b5b9e73dd23b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example training\n",
    "max_epochs = 1\n",
    "iterations_per_epoch = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b00214ba6bce9430"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if presimulate:\n",
    "    # if you want to generate simulations before training use this code block\n",
    "    generative_model = GenerativeModel(model.prior, model.simulator)\n",
    "    start_time = perf_counter()\n",
    "    np.random.seed(42)\n",
    "    generative_model.presimulate_and_save(batch_size=128, \n",
    "                                          folder_path=presimulation_path,\n",
    "                                          iterations_per_epoch=iterations_per_epoch,\n",
    "                                          epochs=max_epochs,\n",
    "                                          disable_user_input=True)\n",
    "    end_time = perf_counter()\n",
    "    print(f'simulation time: {(end_time-start_time)/60} minutes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd61cc5af258596"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d45083fd2df63ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create your neural amortizer, the class NlmeBaseAmortizer predefines a network\n",
    "# if you want to change the network architecture, check out the examples in the function 'load_amortizer_configuration' in one of the models classes \n",
    "# you can change summary and inference network to a wide range of architectures\n",
    "trainer = model.build_trainer('../networks/' + model.network_name)\n",
    "print(model.network_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f26e0cc5ebc90932"
  },
  {
   "cell_type": "markdown",
   "source": [
    "each epoch a number of iterations each with batch_size many simulations is performed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8057db1e429a962c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = {}\n",
    "if train_network and not use_presimulation:\n",
    "    # online training: simulation is done whenever needed\n",
    "    start_time = perf_counter()\n",
    "    history = trainer.train_online(epochs=max_epochs,\n",
    "                                  iterations_per_epoch=iterations_per_epoch,\n",
    "                                  batch_size=128,\n",
    "                                  early_stopping=early_stopping,\n",
    "                                  validation_sims=iterations_per_epoch)\n",
    "    end_time = perf_counter()\n",
    "    print(f'training time: {(end_time-start_time)/60} minutes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d096777fe7956c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_network and use_presimulation:\n",
    "    # prepare optimizer for offline training (simulations were done before training)\n",
    "    trainer._setup_optimizer(optimizer=None,\n",
    "                             epochs=max_epochs,\n",
    "                             iterations_per_epoch=iterations_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858bc0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if train_network and use_presimulation:\n",
    "    # simulation done before, start training now\n",
    "    start_time = perf_counter()\n",
    "    history = trainer.train_from_presimulation(presimulation_path=presimulation_path,\n",
    "                                               optimizer=trainer.optimizer,\n",
    "                                               max_epochs=max_epochs,\n",
    "                                               early_stopping=early_stopping,\n",
    "                                               validation_sims=iterations_per_epoch)\n",
    "\n",
    "    end_time = perf_counter()\n",
    "    print(f'training time: {(end_time-start_time)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9684cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load or save losses\n",
    "if train_network:\n",
    "    history['train_losses'].to_csv(f\"../networks/losses/{model.network_name}_train_losses.csv\")\n",
    "    history['val_losses'].to_csv(f\"../networks/losses/{model.network_name}_val_losses.csv\")\n",
    "else:\n",
    "    train_losses = pd.read_csv(f\"../networks/losses/{model.network_name}_train_losses.csv\", index_col=0)\n",
    "    val_losses = pd.read_csv(f\"../networks/losses/{model.network_name}_val_losses.csv\", index_col=0)\n",
    "    history = {'train_losses': train_losses,\n",
    "              'val_losses': val_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b15192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training loss\n",
    "fig_losses = diagnostics.plot_losses(history['train_losses'], val_losses=history['val_losses'],\n",
    "                                     moving_average=True)\n",
    "if save_plots:\n",
    "    fig_losses.savefig(f'../plots/calibration/{model_name}/{model.network_name}_fig_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load real data (here for the first time), simulate posterior and plot\n",
    "test_data = model.load_data(n_data=25)  # or load synthetic data with synthetic=True\n",
    "data_posterior_draws = model.draw_posterior_samples(data=test_data, n_samples=100)\n",
    "\n",
    "rows = 5\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(test_data) / rows)), tight_layout=True, \n",
    "                       figsize=(10, rows*3), sharey='row')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(len(test_data))):\n",
    "    axis[p_id] = model.prepare_plotting(test_data[p_id], data_posterior_draws[p_id], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "    axis[p_id].set_title(f'Individual {p_id}')\n",
    "    if p_id % rows != 0:\n",
    "        axis[p_id].set_ylabel('')\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.01))\n",
    "if save_plots:\n",
    "    fig.savefig(f'../plots/calibration/{model_name}/{model.network_name}_fit.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e273381deae9877"
  },
  {
   "cell_type": "markdown",
   "id": "2a9fa2a8",
   "metadata": {},
   "source": [
    "## Validate Posteriors using SBC-Plots\n",
    "\n",
    "To check if the training converged, you should validate the posteriors using the following visual diagnostics.\n",
    "If you want, you can also compare the posteriors to any other method (like MCMC or ABC). Check out the \"Validate Posterior with MCMC\"-notebook in the Experiments folder for a comparison to MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb007564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_sims = model.generate_simulations_from_prior(trainer=trainer, n_samples=2500)\n",
    "posterior_draws = model.draw_posterior_samples(data=new_sims['summary_conditions'], n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sbc = diagnostics.plot_sbc_histograms(post_samples=posterior_draws,\n",
    "                                          prior_samples=new_sims['parameters'],\n",
    "                                          param_names=model.log_param_names)\n",
    "\n",
    "for _ax in fig_sbc.axes[model.n_params:]:  \n",
    "    _ax.remove()  # TODO: this is a bug in BayesFlow, figure should be cleaned already\n",
    "if save_plots:\n",
    "    fig_sbc.savefig(f'../plots/calibration/{model_name}/{model.network_name}_fig_sbc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed81830",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ecdf_diff = diagnostics.plot_sbc_ecdf(post_samples=posterior_draws,\n",
    "                                          prior_samples=new_sims['parameters'],\n",
    "                                          difference=True,\n",
    "                                          stacked=False,\n",
    "                                          param_names=model.log_param_names)\n",
    "\n",
    "if save_plots:\n",
    "    fig_ecdf_diff.savefig(f'../plots/calibration/{model_name}/{model.network_name}_fig_ecdf_diff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7add029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_posterior = diagnostics.plot_posterior_2d(posterior_draws=posterior_draws[0],\n",
    "                                              prior=model.prior,\n",
    "                                              param_names=model.log_param_names)\n",
    "\n",
    "if save_plots:\n",
    "    fig_posterior.savefig(f'../plots/calibration/{model_name}/{model.network_name}_fig_posterior.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1d8e5",
   "metadata": {},
   "source": [
    "### Get SBC Plots for Different Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37567e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if checkpoints are saved during optimization one can look at earlier calibration plots\n",
    "ckpt_list = []# [1, 10, 100, 200, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de5011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ckpt in ckpt_list:\n",
    "    print('Load checkpoint', ckpt)\n",
    "    # restore checkpoint\n",
    "    trainer.checkpoint.restore('../networks/' + model.network_name + f'/ckpt-{ckpt}')\n",
    "    # sample posterior\n",
    "    posterior_draws = model.draw_posterior_samples(data=new_sims['summary_conditions'], n_samples=250)\n",
    "\n",
    "    # make sbc plots\n",
    "    fig_ecdf_diff = diagnostics.plot_sbc_ecdf(post_samples=posterior_draws,\n",
    "                                              prior_samples=new_sims['parameters'],\n",
    "                                              difference=True,\n",
    "                                              stacked=False,\n",
    "                                              param_names=model.log_param_names)\n",
    "    if save_plots:\n",
    "        fig_ecdf_diff.savefig(f'../plots/calibration/epochs_compare/{model.network_name}_fig_ecdf_diff_{ckpt}_.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5284c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
