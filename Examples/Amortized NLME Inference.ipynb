{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import visualize, optimize, profile, engine\n",
    "\n",
    "from inference.helper_functions import (create_mixed_effect_model_param_names,\n",
    "                                        analyse_correlation_in_posterior,\n",
    "                                        create_fixed_params)\n",
    "from inference.inference_functions import run_population_optimization\n",
    "from inference.ploting_routines import (plot_real_vs_synthetic,\n",
    "                                        plot_real_and_estimated,\n",
    "                                        plot_normal_distributions,\n",
    "                                        plot_parameter_estimates,\n",
    "                                        visualize_pesto_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "# Load individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    prior_type = ['normal', 'uniform'][0]\n",
    "    n_measurements = [4, 40][0]\n",
    "    individual_model = ClaironSmallModel(load_best=True, prior_type=prior_type, n_measurements=n_measurements)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5004f8ac29b11a4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define how many data points are used for optimization\n",
    "n_data = 10000\n",
    "load_real_data = True\n",
    "# load data\n",
    "true_pop_parameters = None\n",
    "results_to_compare = None\n",
    "if 'Froehlich' in individual_model.name:\n",
    "    obs_data = individual_model.load_data(n_data=n_data, synthetic=not load_real_data, \n",
    "                                          load_egfp=True, load_d2egfp=True)  # if both are loaded, a 2d-list is returned\n",
    "    if not load_real_data:\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_data)\n",
    "    \n",
    "    # load SDE data for comparison\n",
    "    #from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    #model_sde = FroehlichModelSDE(load_best=True)\n",
    "    #obs_data = model_sde.load_data(n_data=n_data, synthetic=True)\n",
    "    #true_pop_parameters_sde = model_sde.load_synthetic_parameter(n_data=n_data)\n",
    "else:\n",
    "    if load_real_data:\n",
    "        obs_data = individual_model.load_data(n_data=n_data, seed=0)\n",
    "    else:\n",
    "        synthetic_fixed_indices = [3]\n",
    "        obs_data, true_pop_parameters = individual_model.load_data(n_data=n_data, synthetic=True, \n",
    "                                                                   return_synthetic_params=True,\n",
    "                                                                   synthetic_fixed_indices=synthetic_fixed_indices,\n",
    "                                                                   seed=0)\n",
    "        \n",
    "#outlier_id = [14, 71, 101, 107, 124, 171]    \n",
    "#obs_data = np.array([obs_data[i] for i in range(len(obs_data)) if i not in outlier_id])\n",
    "\n",
    "n_data = len(obs_data)  # in case less data is available\n",
    "print(len(obs_data), 'individuals')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b460a0b1044c110e"
  },
  {
   "cell_type": "markdown",
   "id": "6e26e6a9",
   "metadata": {},
   "source": [
    "# Estimating Population Parameters\n",
    "\n",
    "Now we want to use the amortizer to generate samples such that we can minimize the negative log-likelihood of the data given the population parameters of the mixed effect model:\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx \n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\log\\left( \\frac1M \\sum_j^M \\frac{p(\\phi_j \\mid \\beta,\\Psi)}{p(\\phi_j)} \\right).\n",
    "$$\n",
    "\n",
    "Remark: the objective value is not the likelihood value since the sum over $\\log p(y_i)$ is missing.\n",
    "\n",
    "\n",
    "$\\beta$ is called ```theta_population``` in the code.\n",
    "\n",
    "\n",
    "$\\log \\phi$ cell specific parameters, sampled from $\\mathcal{N}(\\beta,\\Psi)$\n",
    "$$\n",
    "    p( \\phi \\mid \\beta,\\Psi) = (2\\pi)^{-k/2}\\vert \\Psi\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1} \\exp \\left(-\\frac12 (\\log \\phi-\\beta)^T \\Psi^{-1}  (\\log \\phi-\\beta) \\right)\n",
    "$$\n",
    "\n",
    "Assumptions to start with: $\\Psi$ is a diagonal matrix, need better parameterization for other types\n",
    "\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx\n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log \\frac1M \\sum_j^M \\frac{p( \\phi_j \\mid \\beta,\\Psi)}{p( \\phi_j)} \\right) \\\\\n",
    "     =  \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log\\left(\\vert \\Psi\\vert^{-1/2} \\right) -\\log M -\n",
    "    \\log\\left(\\vert \\Sigma\\vert^{-1/2}\\right) +\\log \\sum_j^M \\exp \\left(-\\frac12 (\\log\\phi_j-\\beta)^T \\Psi^{-1}  (\\log\\phi_j-\\beta) + \\frac12 (\\log\\phi_j-\\mu)^T \\Sigma^{-1}  (\\log\\phi_j-\\mu) \\right)\\right)\n",
    "$$\n",
    "\n",
    "if the prior is $p( \\phi) = (2\\pi)^{-k/2}\\vert \\Sigma\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1}\\exp \\left(-\\frac12 (\\log \\phi-\\mu)^T \\Sigma^{-1}  (\\log\\phi-\\mu) \\right)$.\n",
    "\n",
    "\n",
    "For purpose of optimization we also parametrize $\\Psi$ by a log-transformation since diagonal entries must be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee0f98",
   "metadata": {},
   "source": [
    "## Define Objective Function\n",
    "\n",
    "- you have to choose the covariance format (diag or cholesky)\n",
    "- if you want to use covariates, you have to specify the covariate mapping to the parameters of the log-normal distribution\n",
    "- a covariate mapping takes in parameter samples (n_indv, n_samples, n_params), covariates (n_indv, n_covariates) and parameter vector with parameters needed to map the covariates into the other parameter from the mixed effects model and returns transformed parameter samples (n_indv, n_samples, n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov_type = ['diag', 'cholesky'][1]\n",
    "use_covariates = True\n",
    "\n",
    "mixed_effect_params_names = create_mixed_effect_model_param_names(individual_model.param_names, \n",
    "                                                                  cov_type=cov_type)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23617593538cd87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build covariate mapping if needed\n",
    "covariates_bounds = None\n",
    "covariate_mapping = None\n",
    "n_covariates_params = 0\n",
    "covariates = None\n",
    "covariates_names = []\n",
    "\n",
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    # experiment specific gamma\n",
    "    gamma_index = [ni for ni, name in enumerate(mixed_effect_params_names) if 'gamma' in name]\n",
    "    gamma_index_cov = [ni for ni, name in enumerate(mixed_effect_params_names[individual_model.n_params:]) if 'gamma' in name]\n",
    "    covariates_names = [name + '-d2eGFP' for name in mixed_effect_params_names if 'gamma' in name]\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-5, 5]] * n_covariates_params)\n",
    "    \n",
    "    mixed_effect_params_names = mixed_effect_params_names + covariates_names\n",
    "    \n",
    "elif use_covariates and 'clairon' in model_name:\n",
    "    covariates_names = ['c_age', 'c_gender']\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-1, 1], [-1, 1]])\n",
    "    \n",
    "    mixed_effect_params_names = mixed_effect_params_names + covariates_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ef4562ceda1aab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    # obs_data consists of two groups, first group is eGFP, second group is d2eGFP\n",
    "    if covariates is None:\n",
    "        assert len(obs_data) == 2, 'you should load two groups of data'\n",
    "        covariates = np.concatenate((np.zeros(len(obs_data[0])), np.ones(len(obs_data[1]))))[:, np.newaxis]\n",
    "        obs_data = np.concatenate((obs_data[0], obs_data[1]))\n",
    "        n_data = len(obs_data)\n",
    "        \n",
    "    from inference.nlme_objective import get_inverse_covariance\n",
    "    def multi_experiment_mapping(beta: np.ndarray,\n",
    "                                 psi_inverse_vector: np.ndarray,\n",
    "                                 covariates: np.ndarray,\n",
    "                                 covariates_params: np.ndarray):\n",
    "        \"\"\"individual_param_i = gamma_{eGFP} * (1-c) + gamma_{d2eGFP} * c + random_effect_{eGFP}, c in {0,1}\"\"\"        \n",
    "        # add param_of_cov*covariates to parameter gamma\n",
    "        # covariate_params[0] > 0 expected since lifetime of d2eGFP is lower than eGFP\n",
    "        beta_transformed = np.repeat(beta[np.newaxis, :], covariates.shape[0], axis=0)\n",
    "        psi_inverse_vector_transformed = np.repeat(psi_inverse_vector[np.newaxis, :], covariates.shape[0], axis=0)\n",
    "        psi_inverse_transformed = np.zeros((covariates.shape[0], beta.shape[0], beta.shape[0]))\n",
    "                   \n",
    "        # flatten since only one covariate     \n",
    "        beta_transformed[:, gamma_index[0]] = beta_transformed[:, gamma_index[0]] * (1-covariates.flatten()) + covariates_params[0] * covariates.flatten()\n",
    "        for i, c_i in enumerate(gamma_index_cov):\n",
    "            psi_inverse_vector_transformed[:, c_i] = psi_inverse_vector[c_i] * (1-covariates.flatten()) + covariates_params[1+i] * covariates.flatten()\n",
    "        \n",
    "        for s_id in range(covariates.shape[0]):\n",
    "            psi_inverse = get_inverse_covariance(psi_inverse_vector_transformed[s_id],\n",
    "                                                 covariance_format=cov_type,\n",
    "                                                 param_dim=beta.shape[0])\n",
    "            psi_inverse_transformed[s_id, :, :] = psi_inverse\n",
    "        return beta_transformed, psi_inverse_transformed\n",
    "    \n",
    "    covariate_mapping = multi_experiment_mapping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20e10a5c8a8d7ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse correlations between parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ebfa71aac1a925"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_correlation_pairs = analyse_correlation_in_posterior(model=individual_model, \n",
    "                                                          mixed_effect_params_names=mixed_effect_params_names, \n",
    "                                                          obs_data=obs_data,\n",
    "                                                          threshold_corr=0.3)\n",
    "print('Parameter pairs of high correlation in individual posterior:', np.array(mixed_effect_params_names)[high_correlation_pairs])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de47356800882bb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed and Random Effects\n",
    "\n",
    "Decide which parameters to fix\n",
    "- a fixed effect is modeled as a random effect with variance 0 (all parameters follow a normal distribution)\n",
    "- variance of error parameters in the individual model are usually supposed to be a fixed parameter in the population model\n",
    "- correlations with these error parameters are usually fixed to 0\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d1c49ce426eda8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'Froehlich' in individual_model.name:\n",
    "    # fix variance of error parameters and correlations with sigma if cholesky covariance is used\n",
    "    fix_names = ['var-$\\sigma$'] + [name for name in mixed_effect_params_names if '\\sigma' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "elif 'Pharmacokinetic' in individual_model.name:\n",
    "    fix_error_var = ['var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fix_error_var_val = [0] * len(fix_error_var)\n",
    "    # fix variance of fixed parameters\n",
    "    fixed_effects_var = ['var-$\\\\theta_1$', 'var-$\\\\theta_5$', 'var-$\\\\theta_7$', 'var-$\\\\theta_8$', \n",
    "                         'var-$\\\\theta_{10}$', 'var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fixed_effects_var_val = [0] * len(fixed_effects_var)\n",
    "    # fix mean of random effect\n",
    "    random_effect_mean = ['pop-$\\eta_4$']\n",
    "    random_effect_mean_val = [0]\n",
    "    \n",
    "    # put all fixed parameters together\n",
    "    fix_names = fix_error_var + fixed_effects_var + random_effect_mean\n",
    "    fixed_values = fix_error_var_val + fixed_effects_var_val + random_effect_mean_val\n",
    "    \n",
    "    # if correlations are used, only allow the same as in the original model\n",
    "    # hence correlations with the error parameter are fixed as well\n",
    "    if cov_type == 'cholesky':\n",
    "        non_fix_corr = ['corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$']\n",
    "        fixed_corr = [x for x in mixed_effect_params_names if 'corr_' in x and x not in non_fix_corr]\n",
    "        fix_names += fixed_corr\n",
    "        fixed_values += [0] * len(fixed_corr)\n",
    "    \n",
    "elif 'Clairon' in individual_model.name:\n",
    "    fix_names = ['var-error_constant', 'var-error_prop'] + [name for name in mixed_effect_params_names if \n",
    "                                                            'error' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "else:\n",
    "    raise NotImplementedError('model not yet implemented')\n",
    "    \n",
    "# \"fix\" is here in the context of parameters which are not optimized\n",
    "fixed_indices, fixed_values = create_fixed_params(fix_names=fix_names, \n",
    "                                                  fixed_values=fixed_values,\n",
    "                                                  params_list=mixed_effect_params_names, \n",
    "                                                  fix_low_correlation=False,  # only applies to cholesky covariance\n",
    "                                                  high_correlation_pairs=high_correlation_pairs)\n",
    "print(mixed_effect_params_names)\n",
    "# note: inf values in fixed_values will be set to upper or lower bound respectively"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7555718ecb980b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fixed_indices, unique_indices = np.unique(np.array(fixed_indices), return_index=True)\n",
    "fixed_values = np.array(fixed_values)[unique_indices]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43b36c67c26baaa3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Population Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f974f1d64fa036"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a717d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_optimization, obj_fun_amortized = run_population_optimization(\n",
    "    individual_model=individual_model,\n",
    "    data=obs_data,\n",
    "    param_names=mixed_effect_params_names,\n",
    "    cov_type=cov_type,\n",
    "    n_multi_starts=10,\n",
    "    n_samples_opt=10,\n",
    "    covariates_bounds=covariates_bounds,\n",
    "    covariates=covariates,\n",
    "    n_covariates_params=n_covariates_params,\n",
    "    covariate_mapping=covariate_mapping,\n",
    "    huber_loss=False,\n",
    "    x_fixed_indices=fixed_indices,\n",
    "    x_fixed_vals=fixed_values,\n",
    "    file_name=f'../Experiments/multi-experiment/{model_name}_{cov_type}2.hdf5',\n",
    "    verbose=True,\n",
    "    trace_record=False,\n",
    "    pesto_multi_processes=10,\n",
    "    use_result_as_start=False,\n",
    "    result=None, #result_optimization\n",
    "    #pesto_optimizer=optimize.FidesOptimizer()\n",
    "    use_njit=True\n",
    ")\n",
    "\n",
    "print(result_optimization.optimize_result.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "from pypesto import store\n",
    "result_optimization = store.read_result(\n",
    "    filename='../output/clairon_small_model-diag-n_data_742.hdf5',\n",
    ")\n",
    "obj_fun_amortized = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "502f853ba2139ef1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d40875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_pesto_result(result_optimization, use_batch_coloring=True, obj_fun_amortized=obj_fun_amortized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show best result\n",
    "results = result_optimization.optimize_result.x\n",
    "estimated_beta, psi_inverse, estimated_psi_vector, estimated_covariates_params = obj_fun_amortized.get_params(results[-1])\n",
    "estimated_psi = np.linalg.inv(psi_inverse)\n",
    "estimated_var = estimated_psi.diagonal()\n",
    "estimated_corr = estimated_psi[np.tril_indices(obj_fun_amortized.param_dim, k=-1)]\n",
    "\n",
    "display(pd.DataFrame(estimated_beta,\n",
    "                     index=mixed_effect_params_names[:individual_model.n_params],\n",
    "                     columns=['estimated population parameters']))\n",
    "display(pd.DataFrame(estimated_var,\n",
    "                     index=mixed_effect_params_names[individual_model.n_params:individual_model.n_params*2],\n",
    "                     columns=['estimated population parameters']))\n",
    "if cov_type == 'cholesky':\n",
    "    display(pd.DataFrame(estimated_corr,\n",
    "                         index=mixed_effect_params_names[individual_model.n_params*2:-n_covariates_params],\n",
    "                         columns=['estimated population parameters']))\n",
    "    \n",
    "display(pd.DataFrame(np.var([r for r in results], axis=0),\n",
    "                     index=result_optimization.problem.x_names,\n",
    "                     columns=['variance of multi-start results']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6441a2da84ce4968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_normal_distributions(estimated_beta, estimated_psi, \n",
    "                          title='Population Parameter Distribution',\n",
    "                          lb=result_optimization.problem.lb_full,\n",
    "                          ub=result_optimization.problem.ub_full,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "plot_normal_distributions(individual_model.prior_mean, individual_model.prior_cov, \n",
    "                          title='Prior Parameter Distribution with Individual Posterior Samples',\n",
    "                          posterior_samples=obj_fun_amortized.param_samples,\n",
    "                          lb=result_optimization.problem.lb_full,\n",
    "                          ub=result_optimization.problem.ub_full,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "if true_pop_parameters is not None:\n",
    "    if true_pop_parameters.ndim == 2:\n",
    "        true_mean = np.mean(true_pop_parameters, axis=0)\n",
    "        true_cov = np.diag(np.var(true_pop_parameters, axis=0))\n",
    "    else:\n",
    "        true_mean = true_pop_parameters[:individual_model.n_params]\n",
    "        true_cov = np.diag(true_pop_parameters[individual_model.n_params:])\n",
    "    true_cov[true_cov < 0.001] = 0.001  # smaller cannot be estimated\n",
    "    \n",
    "    plot_normal_distributions(true_mean, \n",
    "                              true_cov, \n",
    "                              title='True Population Parameter Distribution',\n",
    "                              #posterior_samples=obj_fun_amortized.param_samples,\n",
    "                              lb=result_optimization.problem.lb_full,\n",
    "                              ub=result_optimization.problem.ub_full,\n",
    "                              param_names_plot=individual_model.log_param_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdac67b65f2d7a97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875e9ee",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "if 'fröhlich' in model_name:\n",
    "    plot_real_vs_synthetic(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "    plot_real_and_estimated(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           seed=0)\n",
    "    \n",
    "    if n_covariates_params > 0:\n",
    "        print(estimated_covariates_params)\n",
    "        estimated_beta_d2, estimated_inv_psi_d2 = covariate_mapping(estimated_beta, \n",
    "                                                                    estimated_psi_vector, \n",
    "                                                                    np.ones(1), \n",
    "                                                                    estimated_covariates_params)\n",
    "        print(estimated_beta[1], estimated_beta_d2[0, 1])\n",
    "        estimated_beta_d2 = estimated_beta_d2[-1]  # only second group, mean is the same for the whole group\n",
    "        estimated_inv_psi_d2 = estimated_inv_psi_d2[-1]\n",
    "        estimated_psi_d2 = np.linalg.inv(estimated_inv_psi_d2)\n",
    "        \n",
    "        plot_real_vs_synthetic(estimated_mean=estimated_beta_d2,\n",
    "                           estimated_cov=estimated_psi_d2,\n",
    "                           data=obs_data[n_data//2:],\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "        plot_real_and_estimated(estimated_mean=estimated_beta_d2,\n",
    "                               estimated_cov=estimated_psi_d2,\n",
    "                               data=obs_data[n_data//2:],\n",
    "                               model_name=individual_model.name,\n",
    "                               n_trajectories=n_data//2,\n",
    "                               simulator=individual_model.simulator,\n",
    "                               seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70f2e8",
   "metadata": {},
   "source": [
    "# Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186fb11",
   "metadata": {},
   "source": [
    "Uncertainty based on profiles -> more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_options = profile.ProfileOptions(\n",
    "    #min_step_size=0.0001, #0.001\n",
    "    #step_size_factor=1.25, #1.25\n",
    "    delta_ratio_max=0.01, #0.1\n",
    "    #default_step_size=0.0001, #0.01\n",
    "    #ratio_min=0.145 #0.145\n",
    ")\n",
    "\n",
    "result_optimization = profile.parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    "    optimizer=optimize.ScipyOptimizer(), #(options={'disp': True}),\n",
    "    engine=engine.MultiProcessEngine(10),\n",
    "    #profile_options=profile_options,\n",
    "    #filename=f'../Experiments/synthetic_results_amortized/uncertainty_{individual_model.name}_cells_{n_data}_samples_{100}.hd5',\n",
    "    #overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(result_optimization, size=(16,12), \n",
    "                   profile_list_ids=list(np.arange(len(result_optimization.profile_result.list)))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(result_optimization, profile_list=len(result_optimization.profile_result.list)-1)\n",
    "#ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac88c2",
   "metadata": {},
   "source": [
    "Uncertainty based on FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_optimization = profile.approximate_parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(result_optimization, \n",
    "                   profile_list_ids=list(np.arange(len(result_optimization.profile_result.list)))\n",
    "                   )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(result_optimization, profile_list=len(result_optimization.profile_result.list)-1)\n",
    "ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d4fffc09c3b1cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pypesto import store\n",
    "\n",
    "store.write_result(result_optimization, \n",
    "                   f'../Experiments/synthetic_results_amortized/uncertainty_{model_name}_cells_500_samples_100.hdf5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65ac907dd6a1f312",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f54af7d4a4b98fab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
