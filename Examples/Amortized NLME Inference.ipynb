{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import visualize, optimize, profile, engine\n",
    "\n",
    "from inference.helper_functions import (create_mixed_effect_model_param_names,\n",
    "                                        analyse_correlation_in_posterior,\n",
    "                                        create_fixed_params)\n",
    "from inference.inference_functions import run_population_optimization\n",
    "from inference.nlme_objective import get_covariance\n",
    "from inference.ploting_routines import (plot_real_vs_synthetic,\n",
    "                                        plot_real_and_estimated,\n",
    "                                        plot_estimated_distributions,\n",
    "                                        plot_normal_distributions,\n",
    "                                        visualize_pesto_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "# Load individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    prior_type = ['normal', 'uniform'][0]\n",
    "    individual_model = ClaironSmallModel(load_best=True, prior_type=prior_type)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5004f8ac29b11a4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define how many data points are used for optimization\n",
    "n_data = 200\n",
    "load_real_data = False\n",
    "# load data\n",
    "true_pop_parameters = None\n",
    "results_to_compare = None\n",
    "if 'Froehlich' in individual_model.name:\n",
    "    obs_data = individual_model.load_data(n_data=n_data, synthetic=not load_real_data, \n",
    "                                          load_egfp=True, load_d2egfp=False)  # if both are loaded, a 2d-list is returned\n",
    "    if not load_real_data:\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_data)\n",
    "    \n",
    "    # load SDE data for comparison\n",
    "    #from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    #model_sde = FroehlichModelSDE(load_best=True)\n",
    "    #obs_data = model_sde.load_data(n_data=n_data, synthetic=True)\n",
    "    #true_pop_parameters_sde = model_sde.load_synthetic_parameter(n_data=n_data)\n",
    "else:\n",
    "    if load_real_data:\n",
    "        obs_data = individual_model.load_data(n_data=n_data, seed=0)\n",
    "    else:\n",
    "        obs_data, true_pop_parameters = individual_model.load_data(n_data=n_data, synthetic=True, return_synthetic_params=True, seed=0)\n",
    "\n",
    "print(len(obs_data), 'individuals')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b460a0b1044c110e"
  },
  {
   "cell_type": "raw",
   "source": [
    "from models.clairon_small_model import convert_bf_to_observables \n",
    "for d in obs_data:\n",
    "    y, t_measurements, doses_time_points, dose_amount = convert_bf_to_observables(d)\n",
    "    plt.plot(t_measurements, y)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdf9b8d77a602fab"
  },
  {
   "cell_type": "raw",
   "source": [
    "from models.clairon_small_model import convert_bf_to_observables \n",
    "# make format colum y and measurement time\n",
    "id_full = []\n",
    "y_full = []\n",
    "t_full = []\n",
    "id_full_doses = []\n",
    "dose_amount_full = []\n",
    "dose_time_points_full = []\n",
    "for d_id, d in enumerate(obs_data):\n",
    "    y, t_measurements, doses_time_points, dose_amount = convert_bf_to_observables(d)\n",
    "    id_full.append([d_id]*len(y))\n",
    "    y_full.append(y)\n",
    "    t_full.append(t_measurements)\n",
    "    \n",
    "    id_full_doses.append(d_id)\n",
    "    dose_time_points_full.append(doses_time_points)\n",
    "\n",
    "    \n",
    "t_full = np.array(t_full).flatten()\n",
    "y_full = np.array(y_full).flatten()\n",
    "id_full = np.array(id_full).flatten()\n",
    "id_full_doses = np.array(id_full_doses).flatten()\n",
    "dose_time_points_full = np.array(dose_time_points_full).flatten()\n",
    "\n",
    "data_m = np.stack((id_full, t_full, y_full), axis=0).T\n",
    "data_d = np.concatenate((id_full_doses[:, np.newaxis], dose_time_points_full.reshape(-1, 3)), axis=1)\n",
    "\n",
    "m_df = pd.DataFrame(data_m, columns=['id_hcw', 'days_after_first_dose', 'res_serology'])\n",
    "d_df = pd.DataFrame(data_d, columns=['id_hcw','day_1dose','day_2dose','day_3dose'], )\n",
    "\n",
    "print(m_df)\n",
    "print(d_df)\n",
    "m_df.to_csv('test_measurements.csv', index=False)\n",
    "d_df.to_csv('test_dosages.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced78d166b4868c3"
  },
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "if not load_real_data:\n",
    "    if model_name == 'fröhlich-small':\n",
    "        path = f'output/results_monolix/small_model/estimated_parameters_synthetic_{n_data}_cells.csv'\n",
    "        results_monolix = pd.read_csv(path, index_col=0, header=0)\n",
    "        results_to_compare = results_monolix[results_monolix.columns[0]].values[[0, 1, 2, 3, 4, 10, 5, 6, 7, 8, 9]]\n",
    "        results_to_compare[5] = np.log(results_to_compare[5])  # sigma to log\n",
    "        results_to_compare = np.concatenate((results_to_compare, [0]))[np.newaxis, :]\n",
    "    elif model_name == 'fröhlich-large':\n",
    "        path = f'output/results_monolix/large_model/synthetic_{n_data}_poppars.csv'\n",
    "        results_monolix = pd.read_csv(path, index_col=0, header=0)\n",
    "        results_to_compare = results_monolix[results_monolix.columns[0]].values[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20,\n",
    "                                                                                 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "        results_to_compare[10] = np.log(results_to_compare[10])  # sigma to log\n",
    "        results_to_compare = np.concatenate((results_to_compare, [0]))[np.newaxis, :]\n",
    "    elif model_name == 'fröhlich-sde':\n",
    "        pass\n",
    "\n",
    "if False: #model_name == 'pharmacokinetic_model':\n",
    "    raw_nonmem_data = pd.read_csv(f'output/results_nonmem/retries_sunitinib_lognor.csv', delimiter=',',\n",
    "                           index_col=0, header=0)\n",
    "    # remove uninformative columns and add missing columns\n",
    "    raw_nonmem_data = raw_nonmem_data[raw_nonmem_data.columns[[0,1,3,4,5,6,7,9,11,12]+[13,15,18,22]+[14,16,17,19,20,21]+[25,39,40]]]\n",
    "    raw_nonmem_data.sort_values(by=['ofv'], inplace=True)\n",
    "\n",
    "    # remove uninformative columns and add missing columns\n",
    "    corr_names_nonmem = ['eta_1_eta_0', 'eta_2_eta_0', 'eta_2_eta_1', 'eta_3_eta_0', 'eta_3_eta_1', 'eta_3_eta_2']\n",
    "    raw_nonmem_data.columns = full_param_names[:10] + full_param_names[25:29] + corr_names_nonmem + list(raw_nonmem_data.columns[-3:])\n",
    "    # log transform population parameters\n",
    "    raw_nonmem_data[full_param_names[:10]] = raw_nonmem_data[full_param_names[:10]].abs().apply(np.log)\n",
    "    # add variances\n",
    "    raw_nonmem_data[full_param_names[10:25]] = np.zeros(15)\n",
    "    raw_nonmem_data[full_param_names[29]] = 0\n",
    "    # get results to compare\n",
    "    results_to_compare = raw_nonmem_data[full_param_names[:30]+corr_names_nonmem].values\n",
    "\n",
    "if cov_type == 'cholesky':\n",
    "    n_corr = len(param_names) * (len(param_names)-1) // 2\n",
    "    if true_pop_parameters is not None:\n",
    "        # add 0 correlations to true population parameters\n",
    "        true_pop_parameters = np.concatenate((true_pop_parameters, np.zeros(n_corr)), axis=0)\n",
    "    if results_to_compare is not None:\n",
    "        # add 0 correlations to results to compare\n",
    "        # not true for pharmacokinetic model\n",
    "        if model_name != 'pharmacokinetic_model':\n",
    "           results_to_compare = np.concatenate((results_to_compare, np.nan*np.ones((results_to_compare.shape[0], n_corr))), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88458dd93f479995"
  },
  {
   "cell_type": "markdown",
   "id": "6e26e6a9",
   "metadata": {},
   "source": [
    "# Estimating Population Parameters\n",
    "\n",
    "Now we want to use the amortizer to generate samples such that we can minimize the negative log-likelihood of the data given the population parameters of the mixed effect model:\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx \n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\log\\left( \\frac1M \\sum_j^M \\frac{p(\\phi_j \\mid \\beta,\\Psi)}{p(\\phi_j)} \\right).\n",
    "$$\n",
    "\n",
    "Remark: the objective value is not the likelihood value since the sum over $\\log p(y_i)$ is missing.\n",
    "\n",
    "\n",
    "$\\beta$ is called ```theta_population``` in the code.\n",
    "\n",
    "\n",
    "$\\log \\phi$ cell specific parameters, sampled from $\\mathcal{N}(\\beta,\\Psi)$\n",
    "$$\n",
    "    p( \\phi \\mid \\beta,\\Psi) = (2\\pi)^{-k/2}\\vert \\Psi\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1} \\exp \\left(-\\frac12 (\\log \\phi-\\beta)^T \\Psi^{-1}  (\\log \\phi-\\beta) \\right)\n",
    "$$\n",
    "\n",
    "Assumptions to start with: $\\Psi$ is a diagonal matrix, need better parameterization for other types\n",
    "\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx\n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log \\frac1M \\sum_j^M \\frac{p( \\phi_j \\mid \\beta,\\Psi)}{p( \\phi_j)} \\right) \\\\\n",
    "     =  \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log\\left(\\vert \\Psi\\vert^{-1/2} \\right) -\\log M -\n",
    "    \\log\\left(\\vert \\Sigma\\vert^{-1/2}\\right) +\\log \\sum_j^M \\exp \\left(-\\frac12 (\\log\\phi_j-\\beta)^T \\Psi^{-1}  (\\log\\phi_j-\\beta) + \\frac12 (\\log\\phi_j-\\mu)^T \\Sigma^{-1}  (\\log\\phi_j-\\mu) \\right)\\right)\n",
    "$$\n",
    "\n",
    "if the prior is $p( \\phi) = (2\\pi)^{-k/2}\\vert \\Sigma\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1}\\exp \\left(-\\frac12 (\\log \\phi-\\mu)^T \\Sigma^{-1}  (\\log\\phi-\\mu) \\right)$.\n",
    "\n",
    "\n",
    "For purpose of optimization we also parametrize $\\Psi$ by a log-transformation since diagonal entries must be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee0f98",
   "metadata": {},
   "source": [
    "## Define Objective Function\n",
    "\n",
    "- you have to choose the covariance format (diag or cholesky)\n",
    "- if you want to use covariates, you have to specify the covariate mapping to the parameters of the log-normal distribution\n",
    "- a covariate mapping takes in parameter samples (n_indv, n_samples, n_params), covariates (n_indv, n_covariates) and parameter vector with parameters needed to map the covariates into the other parameter from the mixed effects model and returns transformed parameter samples (n_indv, n_samples, n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov_type = ['diag', 'cholesky'][0]\n",
    "use_covariates = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23617593538cd87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build covariate mapping if needed\n",
    "covariates_bounds = None\n",
    "covariate_mapping = None\n",
    "n_covariates_params = 0\n",
    "covariates = None\n",
    "covariates_names = []\n",
    "\n",
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    # experiment specific gamma\n",
    "    covariates_names = ['$factor-\\gamma_{d2eGFP}$', '$factor-var-\\gamma_{d2eGFP}$']\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-5, 5], [-2, 2]])\n",
    "elif use_covariates and 'clairon' in model_name:\n",
    "    covariates_names = ['c_age', 'c_gender']\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-1, 1], [-1, 1]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ef4562ceda1aab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    index_gamma = [i for i, x in enumerate(individual_model.param_names) if 'gamma' in x][0]\n",
    "    \n",
    "    # obs_data consists of two groups, first group is eGFP, second group is d2eGFP\n",
    "    if covariates is None:\n",
    "        assert len(obs_data) == 2, 'you should load two groups of data'\n",
    "        covariates = np.concatenate((np.zeros(len(obs_data[0])), np.ones(len(obs_data[1]))))[:, np.newaxis]\n",
    "        obs_data = np.concatenate((obs_data[0], obs_data[1]))\n",
    "    \n",
    "    \n",
    "    def multi_experiment_mapping(beta: np.ndarray,\n",
    "                                 psi_inverse: np.ndarray,\n",
    "                                 covariates: np.ndarray,\n",
    "                                 covariate_params: np.ndarray):\n",
    "        # add param_of_cov*covariates to parameter gamma\n",
    "        # covariate_params[0] < 0 expected since lifetime of d2eGFP is lower than eGFP\n",
    "        beta_transformed = np.repeat(beta[np.newaxis, :], covariates.shape[0], axis=0)\n",
    "        psi_inverse_transformed = np.repeat(psi_inverse[np.newaxis, :, :], covariates.shape[0], axis=0)\n",
    "        \n",
    "        shit_beta = covariate_params[0] * covariates.flatten()  # flatten since only one covariate\n",
    "        shift_var = covariate_params[1] * covariates.flatten()\n",
    "        \n",
    "        for s_id in range(covariates.shape[0]):\n",
    "            # individual_param_i = gamma_{eGFP} + gamma_{d2eGFP} * c + random_effect_{eGFP}, c in {0,1}\n",
    "            beta_transformed[s_id, index_gamma] += shit_beta[s_id]\n",
    "            # variance needs to be constrained\n",
    "            temp_var = 1. / psi_inverse_transformed[s_id, index_gamma, index_gamma] + shift_var[s_id]\n",
    "            if temp_var  <= 0.001:\n",
    "                temp_var = 0.001\n",
    "            psi_inverse_transformed[s_id, index_gamma, index_gamma] = 1. / temp_var\n",
    "        return beta_transformed, psi_inverse_transformed\n",
    "    \n",
    "    covariate_mapping = multi_experiment_mapping\n",
    "    \n",
    "    \n",
    "elif use_covariates and 'clairon' in model_name:\n",
    "    _, covariates = individual_model.load_data(n_data=n_data, load_covariates=True)\n",
    "    \n",
    "    # todo: this is still the old kind of mapping\n",
    "    def additive_covariate_mapping(param_samples: np.ndarray, \n",
    "                                   covariates: np.ndarray, \n",
    "                                   covariate_params: np.ndarray, \n",
    "                                   threshold: float = 0.001):\n",
    "        # add param_of_cov*covariates to parameters\n",
    "        additive_cov = np.sum(covariate_params*covariates, axis=1)\n",
    "        transformed_param_samples = np.exp(param_samples)\n",
    "        \n",
    "        for s_id in range(transformed_param_samples.shape[0]):\n",
    "            # estimating exp(pop_mean), param_cov, variance of random_effect with 0 mean\n",
    "            # exp(individual_param_i) = exp(pop_mean + random_effect) + param_cov * cov_i\n",
    "            transformed_param_samples[s_id, :, :] -= additive_cov[s_id]  # cov on one parameter\n",
    "        # if parameters are negative, set to threshold\n",
    "        transformed_param_samples[transformed_param_samples < 0] = threshold\n",
    "        param_samples_cov = np.log(transformed_param_samples)\n",
    "        return param_samples_cov\n",
    "    \n",
    "    \n",
    "    def multiplicative_covariate_mapping(param_samples: np.ndarray, \n",
    "                                         covariates: np.ndarray, \n",
    "                                         covariate_params: np.ndarray):\n",
    "        # add param_of_cov*covariates to parameters\n",
    "        additive_cov = np.sum(covariate_params*covariates, axis=1)\n",
    "        \n",
    "        for s_id in range(param_samples.shape[0]):\n",
    "            # estimating exp(pop_mean), param_cov, variance of random_effect with 0 mean\n",
    "            # individual_param_i = pop_mean + random_effect + param_cov * cov_i\n",
    "            # since parameters are log-normal distributed, results in a multiplicative effect\n",
    "            param_samples[s_id, :, :] -= additive_cov[s_id] \n",
    "        return param_samples\n",
    "    \n",
    "    covariate_mapping = [additive_covariate_mapping, multiplicative_covariate_mapping][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20e10a5c8a8d7ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mixed_effect_params_names = create_mixed_effect_model_param_names(individual_model.param_names, \n",
    "                                                                  cov_type=cov_type,\n",
    "                                                                  covariates_names=covariates_names)\n",
    "print(mixed_effect_params_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5417beb3c5989773"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse correlations between parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ebfa71aac1a925"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_correlation_pairs = analyse_correlation_in_posterior(model=individual_model, \n",
    "                                                          mixed_effect_params_names=mixed_effect_params_names, \n",
    "                                                          obs_data=obs_data,\n",
    "                                                          threshold_corr=0.3)\n",
    "print('Parameter pairs of high correlation in individual posterior:', np.array(mixed_effect_params_names)[high_correlation_pairs])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de47356800882bb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed and Random Effects\n",
    "\n",
    "Decide which parameters to fix\n",
    "- a fixed effect is modeled as a random effect with variance 0 (all parameters follow a normal distribution)\n",
    "- variance of error parameters in the individual model are usually supposed to be a fixed parameter in the population model\n",
    "- correlations with these error parameters are usually fixed to 0\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d1c49ce426eda8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'Froehlich' in individual_model.name:\n",
    "    # fix variance of error parameters and correlations with sigma if cholesky covariance is used\n",
    "    fix_names = ['var-$\\sigma$'] + [name for name in mixed_effect_params_names if '\\sigma' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "elif 'Pharmacokinetic' in individual_model.name:\n",
    "    fix_error_var = ['var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fix_error_var_val = [0] * len(fix_error_var)\n",
    "    # fix variance of fixed parameters\n",
    "    fixed_effects_var = ['var-$\\\\theta_1$', 'var-$\\\\theta_5$', 'var-$\\\\theta_7$', 'var-$\\\\theta_8$', \n",
    "                         'var-$\\\\theta_{10}$', 'var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fixed_effects_var_val = [0] * len(fixed_effects_var)\n",
    "    # fix mean of random effect\n",
    "    random_effect_mean = ['pop-$\\eta_4$']\n",
    "    random_effect_mean_val = [0]\n",
    "    \n",
    "    # put all fixed parameters together\n",
    "    fix_names = fix_error_var + fixed_effects_var + random_effect_mean\n",
    "    fixed_values = fix_error_var_val + fixed_effects_var_val + random_effect_mean_val\n",
    "    \n",
    "    # if correlations are used, only allow the same as in the original model\n",
    "    # hence correlations with the error parameter are fixed as well\n",
    "    if cov_type == 'cholesky':\n",
    "        non_fix_corr = ['corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$']\n",
    "        fixed_corr = [x for x in mixed_effect_params_names if 'corr_' in x and x not in non_fix_corr]\n",
    "        fix_names += fixed_corr\n",
    "        fixed_values += [0] * len(fixed_corr)\n",
    "    \n",
    "elif 'Clairon' in individual_model.name:\n",
    "    fix_names = ['var-error_constant', 'var-error_prop'] + [name for name in mixed_effect_params_names if \n",
    "                                                            'error' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "else:\n",
    "    raise NotImplementedError('model not yet implemented')\n",
    "    \n",
    "# \"fix\" is here in the context of parameters which are not optimized\n",
    "fixed_indices, fixed_values = create_fixed_params(fix_names=fix_names, \n",
    "                                                  fixed_values=fixed_values,\n",
    "                                                  params_list=mixed_effect_params_names, \n",
    "                                                  fix_low_correlation=True,  # only applies to cholesky covariance\n",
    "                                                  high_correlation_pairs=high_correlation_pairs)\n",
    "print(mixed_effect_params_names)\n",
    "# note: inf values in fixed_values will be set to upper or lower bound respectively"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7555718ecb980b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fix covariates parameters\n",
    "#fixed_indices = np.append(fixed_indices, 12)\n",
    "#fixed_values = np.append(fixed_values, -2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25776538ae4bdffc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Population Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f974f1d64fa036"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a717d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_optimization, obj_fun_amortized = run_population_optimization(\n",
    "    individual_model=individual_model,\n",
    "    data=obs_data,\n",
    "    param_names=mixed_effect_params_names,\n",
    "    cov_type=cov_type,\n",
    "    n_multi_starts=10,\n",
    "    n_samples_opt=50,\n",
    "    covariates_bounds=covariates_bounds,\n",
    "    covariates=covariates,\n",
    "    n_covariates_params=n_covariates_params,\n",
    "    covariate_mapping=covariate_mapping,\n",
    "    x_fixed_indices=fixed_indices,\n",
    "    x_fixed_vals=fixed_values,\n",
    "    file_name=None, # f'../output/{model_name}-{cov_type}-n_data_{n_data}.hdf5',\n",
    "    verbose=True,\n",
    "    trace_record=True,\n",
    "    pesto_multi_processes=10,\n",
    "    result=None #result_optimization\n",
    "    )\n",
    "\n",
    "result_optimization.optimize_result.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "from pypesto import store\n",
    "store.write_result(\n",
    "    result=result_optimization,\n",
    "    filename='../output/test-forehlich-simple-10000samples.hdf5',\n",
    "    problem=True,\n",
    "    optimize=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c38e83c22d425feb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d40875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_pesto_result(result_optimization, use_batch_coloring=True, obj_fun_amortized=obj_fun_amortized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show best result\n",
    "results = result_optimization.optimize_result.x\n",
    "estimated_beta = results[0][:individual_model.n_params]\n",
    "estimated_var = np.exp(-results[0][individual_model.n_params:individual_model.n_params*2])\n",
    "if n_covariates_params == 0:\n",
    "    estimated_psi = get_covariance(results[0][individual_model.n_params:], \n",
    "                                   covariance_format=cov_type, param_dim=individual_model.n_params)\n",
    "else:\n",
    "    estimated_psi = get_covariance(results[0][individual_model.n_params:-n_covariates_params],\n",
    "                                   covariance_format=cov_type, param_dim=individual_model.n_params)\n",
    "    estimated_covariates_params = results[0][-n_covariates_params:]\n",
    "\n",
    "display(pd.DataFrame(estimated_beta,\n",
    "                     index=mixed_effect_params_names[:individual_model.n_params],\n",
    "                     columns=['estimated population parameters']))\n",
    "display(pd.DataFrame(estimated_var,\n",
    "                     index=mixed_effect_params_names[individual_model.n_params:individual_model.n_params*2],\n",
    "                     columns=['estimated population parameters']))\n",
    "if cov_type == 'cholesky' or use_covariates:\n",
    "    display(pd.DataFrame(results[0][individual_model.n_params*2:],\n",
    "                         index=mixed_effect_params_names[individual_model.n_params*2:],\n",
    "                         columns=['estimated population parameters']))\n",
    "    \n",
    "display(pd.DataFrame(np.var([r for r in results], axis=0),\n",
    "                     index=mixed_effect_params_names,\n",
    "                     columns=['variance of multi-start results']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6441a2da84ce4968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_normal_distributions(estimated_beta, estimated_psi, \n",
    "                          title='Population Parameter Distribution',\n",
    "                          lb=result_optimization.problem.lb,\n",
    "                          ub=result_optimization.problem.ub,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "plot_normal_distributions(individual_model.prior_mean, individual_model.prior_cov, \n",
    "                          title='Prior Parameter Distribution with Individual Posterior Samples',\n",
    "                          posterior_samples=obj_fun_amortized.param_samples,\n",
    "                          lb=result_optimization.problem.lb,\n",
    "                          ub=result_optimization.problem.ub,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "if true_pop_parameters is not None:\n",
    "    if true_pop_parameters.ndim == 2:\n",
    "        true_mean = np.mean(true_pop_parameters, axis=0)\n",
    "        true_cov = np.diag(np.var(true_pop_parameters, axis=0))\n",
    "    else:\n",
    "        true_mean = true_pop_parameters[:individual_model.n_params]\n",
    "        true_cov = np.diag(true_pop_parameters[individual_model.n_params:])\n",
    "    true_cov[true_cov < 0.001] = 0.001  # smaller cannot be estimated\n",
    "    \n",
    "    plot_normal_distributions(true_mean, \n",
    "                              true_cov, \n",
    "                              title='True Population Parameter Distribution',\n",
    "                              #posterior_samples=obj_fun_amortized.param_samples,\n",
    "                              lb=result_optimization.problem.lb,\n",
    "                              ub=result_optimization.problem.ub,\n",
    "                              param_names_plot=individual_model.log_param_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdac67b65f2d7a97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fröhlich' in model_name:\n",
    "    plot_real_vs_synthetic(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           #save_fig='dif_ode', #model_name+'_eGFP_dif' if load_real_data else model_name+'_synthetic_dif',\n",
    "                           #estimation_function=np.median,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "    plot_real_and_estimated(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           #save_fig=model_name+'_eGFP_estimate' if load_real_data else model_name+'_synthetic_estimate',\n",
    "                           seed=0)\n",
    "    \n",
    "    if n_covariates_params > 0:\n",
    "        estimated_beta_d2, estimated_inv_psi_d2 = covariate_mapping(estimated_beta, \n",
    "                                                                    np.linalg.inv(estimated_psi), \n",
    "                                                                    covariates, \n",
    "                                                                    estimated_covariates_params)\n",
    "        estimated_beta_d2 = estimated_beta_d2[-1]  # only second group, mean is the same for the whole group\n",
    "        estimated_inv_psi_d2 = estimated_inv_psi_d2[-1]\n",
    "        estimated_psi_d2 = np.linalg.inv(estimated_inv_psi_d2)\n",
    "        \n",
    "        plot_real_vs_synthetic(estimated_mean=estimated_beta_d2,\n",
    "                           estimated_cov=estimated_psi_d2,\n",
    "                           data=obs_data[n_data//2:],\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "        plot_real_and_estimated(estimated_mean=estimated_beta_d2,\n",
    "                               estimated_cov=estimated_psi_d2,\n",
    "                               data=obs_data[n_data//2:],\n",
    "                               model_name=individual_model.name,\n",
    "                               n_trajectories=n_data//2,\n",
    "                               simulator=individual_model.simulator,\n",
    "                               seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70f2e8",
   "metadata": {},
   "source": [
    "# Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186fb11",
   "metadata": {},
   "source": [
    "Uncertainty based on profiles -> more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_options = profile.ProfileOptions(\n",
    "    min_step_size=0.0005, #0.001\n",
    "    step_size_factor=1.1, #1.25\n",
    "    delta_ratio_max=0.05, #0.1\n",
    "    default_step_size=0.005, #0.01\n",
    "    ratio_min=0.01, #0.145\n",
    ")\n",
    "\n",
    "result_optimization = profile.parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    "    optimizer=optimize.ScipyOptimizer(),\n",
    "    engine=engine.MultiProcessEngine(10),\n",
    "    #profile_options=profile_options,\n",
    "    #filename=f'output/uncertainty/{model.name}_cells_{n_data}_samples_{50}.hd5',\n",
    "    #overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(result_optimization, size=(16,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(result_optimization)\n",
    "ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac88c2",
   "metadata": {},
   "source": [
    "Uncertainty based on FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_optimization = profile.approximate_parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(result_optimization)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d4fffc09c3b1cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
