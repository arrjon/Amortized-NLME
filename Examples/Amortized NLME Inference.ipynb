{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import visualize, optimize, profile, engine\n",
    "\n",
    "from inference.helper_functions import (create_mixed_effect_model_param_names,\n",
    "                                        analyse_correlation_in_posterior,\n",
    "                                        create_fixed_params)\n",
    "from inference.inference_functions import run_population_optimization\n",
    "from inference.nlme_objective import ObjectiveFunctionNLME\n",
    "from inference.ploting_routines import (plot_real_vs_synthetic,\n",
    "                                        plot_real_and_estimated,\n",
    "                                        plot_estimated_distributions,\n",
    "                                        visualize_pesto_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "# Load individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    individual_model = ClaironSmallModel(load_best=True)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5004f8ac29b11a4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define how many data points are used for optimization\n",
    "n_data = 100\n",
    "load_real_data = True\n",
    "# load data\n",
    "true_pop_parameters = None\n",
    "results_to_compare = None\n",
    "if 'Froehlich' in individual_model.name:\n",
    "    obs_data = individual_model.load_data(n_data=n_data, load_egfp=load_real_data, load_d2egfp=False)\n",
    "    if not load_real_data:\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_data)\n",
    "    \n",
    "    # load SDE data for comparison\n",
    "    #from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    #model_sde = FroehlichModelSDE(load_best=True)\n",
    "    #obs_data = model_sde.load_data(n_data=n_data, synthetic=True)\n",
    "    #true_pop_parameters_sde = model_sde.load_synthetic_parameter(n_data=n_data)\n",
    "else:\n",
    "    obs_data = individual_model.load_data(n_data=n_data, synthetic=not load_real_data)\n",
    "\n",
    "print(len(obs_data), 'individuals')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b460a0b1044c110e"
  },
  {
   "cell_type": "raw",
   "source": [
    "if not load_real_data:\n",
    "    if model_name == 'fröhlich-small':\n",
    "        path = f'output/results_monolix/small_model/estimated_parameters_synthetic_{n_data}_cells.csv'\n",
    "        results_monolix = pd.read_csv(path, index_col=0, header=0)\n",
    "        results_to_compare = results_monolix[results_monolix.columns[0]].values[[0, 1, 2, 3, 4, 10, 5, 6, 7, 8, 9]]\n",
    "        results_to_compare[5] = np.log(results_to_compare[5])  # sigma to log\n",
    "        results_to_compare = np.concatenate((results_to_compare, [0]))[np.newaxis, :]\n",
    "    elif model_name == 'fröhlich-large':\n",
    "        path = f'output/results_monolix/large_model/synthetic_{n_data}_poppars.csv'\n",
    "        results_monolix = pd.read_csv(path, index_col=0, header=0)\n",
    "        results_to_compare = results_monolix[results_monolix.columns[0]].values[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20,\n",
    "                                                                                 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "        results_to_compare[10] = np.log(results_to_compare[10])  # sigma to log\n",
    "        results_to_compare = np.concatenate((results_to_compare, [0]))[np.newaxis, :]\n",
    "    elif model_name == 'fröhlich-sde':\n",
    "        pass\n",
    "\n",
    "if False: #model_name == 'pharmacokinetic_model':\n",
    "    raw_nonmem_data = pd.read_csv(f'output/results_nonmem/retries_sunitinib_lognor.csv', delimiter=',',\n",
    "                           index_col=0, header=0)\n",
    "    # remove uninformative columns and add missing columns\n",
    "    raw_nonmem_data = raw_nonmem_data[raw_nonmem_data.columns[[0,1,3,4,5,6,7,9,11,12]+[13,15,18,22]+[14,16,17,19,20,21]+[25,39,40]]]\n",
    "    raw_nonmem_data.sort_values(by=['ofv'], inplace=True)\n",
    "\n",
    "    # remove uninformative columns and add missing columns\n",
    "    corr_names_nonmem = ['eta_1_eta_0', 'eta_2_eta_0', 'eta_2_eta_1', 'eta_3_eta_0', 'eta_3_eta_1', 'eta_3_eta_2']\n",
    "    raw_nonmem_data.columns = full_param_names[:10] + full_param_names[25:29] + corr_names_nonmem + list(raw_nonmem_data.columns[-3:])\n",
    "    # log transform population parameters\n",
    "    raw_nonmem_data[full_param_names[:10]] = raw_nonmem_data[full_param_names[:10]].abs().apply(np.log)\n",
    "    # add variances\n",
    "    raw_nonmem_data[full_param_names[10:25]] = np.zeros(15)\n",
    "    raw_nonmem_data[full_param_names[29]] = 0\n",
    "    # get results to compare\n",
    "    results_to_compare = raw_nonmem_data[full_param_names[:30]+corr_names_nonmem].values\n",
    "\n",
    "if cov_type == 'cholesky':\n",
    "    n_corr = len(param_names) * (len(param_names)-1) // 2\n",
    "    if true_pop_parameters is not None:\n",
    "        # add 0 correlations to true population parameters\n",
    "        true_pop_parameters = np.concatenate((true_pop_parameters, np.zeros(n_corr)), axis=0)\n",
    "    if results_to_compare is not None:\n",
    "        # add 0 correlations to results to compare\n",
    "        # not true for pharmacokinetic model\n",
    "        if model_name != 'pharmacokinetic_model':\n",
    "           results_to_compare = np.concatenate((results_to_compare, np.nan*np.ones((results_to_compare.shape[0], n_corr))), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88458dd93f479995"
  },
  {
   "cell_type": "markdown",
   "id": "6e26e6a9",
   "metadata": {},
   "source": [
    "# Estimating Population Parameters\n",
    "\n",
    "Now we want to use the amortizer to generate samples such that we can minimize the negative log-likelihood of the data given the population parameters of the mixed effect model:\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx \n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\log\\left( \\frac1M \\sum_j^M \\frac{p(\\phi_j \\mid \\beta,\\Psi)}{p(\\phi_j)} \\right).\n",
    "$$\n",
    "\n",
    "Remark: the objective value is not the likelihood value since the sum over $\\log p(y_i)$ is missing.\n",
    "\n",
    "\n",
    "$\\beta$ is called ```theta_population``` in the code.\n",
    "\n",
    "\n",
    "$\\log \\phi$ cell specific parameters, sampled from $\\mathcal{N}(\\beta,\\Psi)$\n",
    "$$\n",
    "    p( \\phi \\mid \\beta,\\Psi) = (2\\pi)^{-k/2}\\vert \\Psi\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1} \\exp \\left(-\\frac12 (\\log \\phi-\\beta)^T \\Psi^{-1}  (\\log \\phi-\\beta) \\right)\n",
    "$$\n",
    "\n",
    "Assumptions to start with: $\\Psi$ is a diagonal matrix, need better parameterization for other types\n",
    "\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx\n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log \\frac1M \\sum_j^M \\frac{p( \\phi_j \\mid \\beta,\\Psi)}{p( \\phi_j)} \\right) \\\\\n",
    "     =  \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log\\left(\\vert \\Psi\\vert^{-1/2} \\right) -\\log M -\n",
    "    \\log\\left(\\vert \\Sigma\\vert^{-1/2}\\right) +\\log \\sum_j^M \\exp \\left(-\\frac12 (\\log\\phi_j-\\beta)^T \\Psi^{-1}  (\\log\\phi_j-\\beta) + \\frac12 (\\log\\phi_j-\\mu)^T \\Sigma^{-1}  (\\log\\phi_j-\\mu) \\right)\\right)\n",
    "$$\n",
    "\n",
    "if the prior is $p( \\phi) = (2\\pi)^{-k/2}\\vert \\Sigma\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1}\\exp \\left(-\\frac12 (\\log \\phi-\\mu)^T \\Sigma^{-1}  (\\log\\phi-\\mu) \\right)$.\n",
    "\n",
    "\n",
    "For purpose of optimization we also parametrize $\\Psi$ by a log-transformation since diagonal entries must be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee0f98",
   "metadata": {},
   "source": [
    "## Define Objective Function\n",
    "\n",
    "- you have to choose the covariance format (diag or cholesky)\n",
    "- if you want to use covariates, you have to specify the covariate mapping to the parameters of the log-normal distribution\n",
    "- a covariate mapping takes in parameter samples (n_indv, n_samples, n_params), covariates (n_indv, n_covariates) and parameter vector with parameters needed to map the covariates into the other parameter from the mixed effects model and returns transformed parameter samples (n_indv, n_samples, n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov_type = ['diag', 'cholesky'][1]\n",
    "use_covariates = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23617593538cd87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build covariate mapping if needed\n",
    "covariates_bounds = None\n",
    "covariates_names = []\n",
    "if 'clairon' in model_name and use_covariates:\n",
    "    covariates_names = ['c_age', 'c_gender']\n",
    "    covariates_bounds = np.array([[-1, 1], [-1, 1]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ef4562ceda1aab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_covariates and 'clairon' in model_name:\n",
    "    _, covariates = individual_model.load_data(n_data=n_data, load_covariates=True)\n",
    "    \n",
    "    def additive_covariate_mapping(param_samples: np.ndarray, \n",
    "                                   covariates: np.ndarray, \n",
    "                                   covariate_params: np.ndarray, \n",
    "                                   threshold: float = 0.001):\n",
    "        # add param_of_cov*covariates to parameters\n",
    "        additive_cov = np.sum(covariate_params*covariates, axis=1)\n",
    "        transformed_param_samples = np.exp(param_samples)\n",
    "        \n",
    "        for s_id in range(transformed_param_samples.shape[0]):\n",
    "            # estimating exp(pop_mean), param_cov, variance of random_effect with 0 mean\n",
    "            # exp(individual_param_i) = exp(pop_mean + random_effect) + param_cov * cov_i\n",
    "            transformed_param_samples[s_id, :, :] -= additive_cov[s_id]  # cov on one parameter\n",
    "        # if parameters are negative, set to threshold\n",
    "        transformed_param_samples[transformed_param_samples < 0] = threshold\n",
    "        param_samples_cov = np.log(transformed_param_samples)\n",
    "        return param_samples_cov\n",
    "    \n",
    "    def multiplicative_covariate_mapping(param_samples: np.ndarray, \n",
    "                                         covariates: np.ndarray, \n",
    "                                         covariate_params: np.ndarray):\n",
    "        # add param_of_cov*covariates to parameters\n",
    "        additive_cov = np.sum(covariate_params*covariates, axis=1)\n",
    "        \n",
    "        for s_id in range(param_samples.shape[0]):\n",
    "            # estimating exp(pop_mean), param_cov, variance of random_effect with 0 mean\n",
    "            # individual_param_i = pop_mean + random_effect + param_cov * cov_i\n",
    "            # since parameters are log-normal distributed, results in a multiplicative effect\n",
    "            param_samples[s_id, :, :] -= additive_cov[s_id] \n",
    "        return param_samples\n",
    "    \n",
    "    covariate_mapping = [additive_covariate_mapping, multiplicative_covariate_mapping][0]\n",
    "else:\n",
    "    covariate_mapping = None\n",
    "    covariates = None\n",
    "\n",
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=individual_model.name,\n",
    "                                          param_samples=np.empty((1,1,1)),\n",
    "                                          prior_mean=individual_model.prior_mean,\n",
    "                                          prior_std=individual_model.prior_std,\n",
    "                                          covariance_format=cov_type,\n",
    "                                          covariates=covariates,\n",
    "                                          covariate_mapping=covariate_mapping,\n",
    "                                          prior_type=individual_model.prior_type,\n",
    "                                          prior_bounds=individual_model.prior_bounds if hasattr(individual_model, 'prior_bounds') else None,  # for uniform prior\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20e10a5c8a8d7ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mixed_effect_params_names = create_mixed_effect_model_param_names(individual_model.param_names, \n",
    "                                                                  cov_type=cov_type,\n",
    "                                                                  covariates_names=covariates_names)\n",
    "print(mixed_effect_params_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5417beb3c5989773"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse correlations between parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ebfa71aac1a925"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_correlation_pairs = analyse_correlation_in_posterior(model=individual_model, \n",
    "                                                          mixed_effect_params_names=mixed_effect_params_names, \n",
    "                                                          obs_data=obs_data,\n",
    "                                                          threshold_corr=0.5)\n",
    "print('Parameter pairs of high correlation in individual posterior:', high_correlation_pairs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de47356800882bb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed and Random Effects\n",
    "\n",
    "Decide which parameters to fix\n",
    "- a fixed effect is modeled as a random effect with variance 0 (all parameters follow a normal distribution)\n",
    "- variance of error parameters in the individual model are usually supposed to be a fixed parameter in the population model\n",
    "- correlations with these error parameters are usually fixed to 0\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d1c49ce426eda8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'Froehlich' in individual_model.name:\n",
    "    # fix variance of error parameters and correlations with sigma if cholesky covariance is used\n",
    "    fix_names = ['var-$\\sigma$'] + [name for name in mixed_effect_params_names if '\\sigma' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "elif 'pharmacokinetic' in individual_model.name:\n",
    "    fix_error_var = ['var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fix_error_var_val = [0] * len(fix_error_var)\n",
    "    # fix variance of fixed parameters\n",
    "    fixed_effects_var = ['var-$\\\\theta_1$', 'var-$\\\\theta_5$', 'var-$\\\\theta_7$', 'var-$\\\\theta_8$', \n",
    "                         'var-$\\\\theta_{10}$', 'var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fixed_effects_var_val = [0] * len(fixed_effects_var)\n",
    "    # fix mean of random effect\n",
    "    random_effect_mean = ['pop-$\\eta_4$']\n",
    "    random_effect_mean_val = [0]\n",
    "    \n",
    "    # put all fixed parameters together\n",
    "    fix_names = fix_error_var + fixed_effects_var + random_effect_mean\n",
    "    fixed_values = fix_error_var_val + fixed_effects_var_val + random_effect_mean_val\n",
    "    \n",
    "    # if correlations are used, only allow the same as in the original model\n",
    "    # hence correlations with the error parameter are fixed as well\n",
    "    if cov_type == 'cholesky':\n",
    "        non_fix_corr = ['corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$']\n",
    "        fixed_corr = [x for x in mixed_effect_params_names if 'corr_' in x and x not in non_fix_corr]\n",
    "        fix_names += fixed_corr\n",
    "        fixed_values += [0] * len(fixed_corr)\n",
    "    \n",
    "elif 'Clairon' in individual_model.name:\n",
    "    fix_names = ['var-error_prop'] + [name for name in mixed_effect_params_names if 'error' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "else:\n",
    "    raise NotImplementedError('model not yet implemented')\n",
    "    \n",
    "fixed_indices, fixed_values = create_fixed_params(fix_names=fix_names, \n",
    "                                                  fixed_values=fixed_values,\n",
    "                                                  params_list=mixed_effect_params_names, \n",
    "                                                  fix_low_correlation=False,  # only applies to cholesky covariance\n",
    "                                                  high_correlation_pairs=high_correlation_pairs)\n",
    "print(mixed_effect_params_names)\n",
    "# note: inf values in fixed_values will be set to upper or lower bound respectively"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7555718ecb980b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Population Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f974f1d64fa036"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a717d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_optimization = run_population_optimization(\n",
    "    individual_model=individual_model,\n",
    "    data=obs_data,\n",
    "    param_names=mixed_effect_params_names,\n",
    "    objective_function=obj_fun_amortized,\n",
    "    n_multi_starts=20,\n",
    "    n_samples_opt=50,\n",
    "    covariates_bounds=covariates_bounds,\n",
    "    x_fixed_indices=fixed_indices,\n",
    "    x_fixed_vals=fixed_values,\n",
    "    file_name=None,\n",
    "    verbose=True,\n",
    "    trace_record=True,\n",
    "    pesto_multi_processes=10,\n",
    "    result=None #result_optimization\n",
    "    )\n",
    "\n",
    "results = result_optimization.optimize_result.as_dataframe()['x']"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "from inference.inference_functions import create_objective_with_samples\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac488067a013a1c3"
  },
  {
   "cell_type": "raw",
   "source": [
    "# estimate variance \n",
    "test_samples = [2, 10] #, 50, 100, 500, 1000]\n",
    "test_val = results[0]\n",
    "obj_values = np.zeros((len(test_samples), 20))\n",
    "for j, n_s in tqdm(enumerate(test_samples), total=len(test_samples)):\n",
    "    for i in range(obj_values.shape[1]):\n",
    "        objective_function = create_objective_with_samples(data=obs_data,\n",
    "                                                               objective_function=obj_fun_amortized,\n",
    "                                                               sample_posterior=model.draw_posterior_samples,\n",
    "                                                               n_samples_opt=n_s)\n",
    "        obj_values[j, i] = objective_function(test_val)\n",
    "#pesto_objective = FD(obj=Objective(fun=objective_function, x_names=param_names_opt))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "761de5849f23c11f"
  },
  {
   "cell_type": "raw",
   "source": [
    "mean_obj_value = obj_values.mean(axis=1)[:,np.newaxis]\n",
    "np.mean(np.abs(obj_values-mean_obj_value), axis=1)/np.min(obj_values), np.var(np.abs(obj_values-mean_obj_value)/np.min(obj_values), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca1222aee047968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from pypesto.store import OptimizationResultHDF5Writer\n",
    "#writer = OptimizationResultHDF5Writer(f'output/{model_name}_real_{n_data}_3.hdf5')\n",
    "#writer.write(result_optimization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df31875bcb4c3bc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from pypesto.store import OptimizationResultHDF5Reader\n",
    "#result_optimization2 = OptimizationResultHDF5Reader(f'output/scalability/{model.name}_cells_{n_data}_samples_{50}.hd5').read()\n",
    "#results = result_optimization.optimize_result.as_dataframe()['x']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33111933a42d448"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d40875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_pesto_result(result_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show best result\n",
    "estimated_beta = results[0][:individual_model.n_params]\n",
    "var = results[0][individual_model.n_params:individual_model.n_params*2]\n",
    "estimated_psi = obj_fun_amortized.get_covariance(results[0][individual_model.n_params:])\n",
    "\n",
    "display(pd.DataFrame(estimated_beta,\n",
    "                     index=mixed_effect_params_names[:individual_model.n_params],\n",
    "                     columns=['estimated population parameters']))\n",
    "display(pd.DataFrame(np.exp(-var),\n",
    "                     index=mixed_effect_params_names[individual_model.n_params:individual_model.n_params*2],\n",
    "                     columns=['estimated population parameters']))\n",
    "if cov_type == 'cholesky' or use_covariates:\n",
    "    display(pd.DataFrame(results[0][individual_model.n_params:],\n",
    "                         index=mixed_effect_params_names[individual_model.n_params:],\n",
    "                         columns=['estimated population parameters']))\n",
    "    \n",
    "display(pd.DataFrame(np.var([r for r in results], axis=0),\n",
    "                     index=mixed_effect_params_names,\n",
    "                     columns=['variance of multi-start results']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6441a2da84ce4968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if true_pop_parameters is not None:\n",
    "    print('true values of log-normal distribution')\n",
    "    df_param_sample = pd.DataFrame(true_pop_parameters[np.newaxis,:].round(4),\n",
    "                               columns=mixed_effect_params_names)\n",
    "    display(df_param_sample)\n",
    "\n",
    "if results_to_compare is not None:\n",
    "    print('values of baseline method of log-normal distribution')\n",
    "    df_param_sample = pd.DataFrame(results_to_compare, columns=mixed_effect_params_names)\n",
    "    display(df_param_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimated_psi_inv = obj_fun_amortized.get_inverse_covariance(results[0][individual_model.n_params:])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db8e9ba25a8e9372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7120412a7960bb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples_test = 1000\n",
    "n_patients = 10\n",
    "test_eval = np.zeros((n_patients, n_samples_test))\n",
    "\n",
    "for i in range(n_patients):\n",
    "    test_samples = individual_model.draw_posterior_samples(data=obs_data, n_samples=n_samples_test)[i]\n",
    "    test_function = lambda x: -0.5*(x-estimated_beta).dot(estimated_psi_inv).dot(x-estimated_beta)\n",
    "    test_eval[i] = np.array([test_function(x) for x in test_samples])\n",
    "    \n",
    "    \n",
    "test_expectation = np.exp(test_eval).sum(axis=1) / n_samples_test\n",
    "test_variance = 1/(n_samples_test-1) * np.sum((np.exp(test_eval) - test_expectation[:, np.newaxis])**2, axis=1)\n",
    "test_error = np.sqrt(test_variance/n_samples_test)\n",
    "print(f'E={test_expectation}')\n",
    "print(f'Var={test_variance}')\n",
    "print(f'Error={test_error}')\n",
    "   \n",
    "print('\\n')\n",
    "print('log-sum-exp', np.log(test_expectation))\n",
    "print('logsumexp', -np.log(n_samples_test)+logsumexp(test_eval, axis=1))\n",
    "print('sumlogsumexp', np.sum(-np.log(n_samples_test)+logsumexp(test_eval, axis=1)))\n",
    "print('error-order', (1/(n_samples_test-1)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d54c062e8a304cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from models.base_nlme_model import batch_gaussian_prior\n",
    "synthetic_params = batch_gaussian_prior(mean=model.prior_mean-1, cov=model.prior_cov/2, batch_size=n_data) - 1\n",
    "synthetic_params[:, -2:] = model.prior_mean[-2:]-1\n",
    "true_pop_parameters = np.concatenate((np.mean(synthetic_params, axis=0), np.var(synthetic_params, axis=0)))\n",
    "display(true_pop_parameters)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd1849915eb646dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display((estimated_beta-true_pop_parameters[:model.n_params])**2 / true_pop_parameters[:model.n_params]**2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5773f358a15668db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display((estimated_psi.diagonal()-true_pop_parameters[model.n_params:])**2 / true_pop_parameters[model.n_params:]**2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22cc62cc813fd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulator = model.build_simulator(with_noise=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29f49a68782130b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fröhlich' in model_name:\n",
    "    plot_real_vs_synthetic(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data,\n",
    "                           model_name=model.name,\n",
    "                           n_trajectories=len(obs_data),\n",
    "                           simulator=simulator,\n",
    "                           #save_fig='dif_ode', #model_name+'_eGFP_dif' if load_real_data else model_name+'_synthetic_dif',\n",
    "                           #estimation_function=np.median,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "    plot_real_and_estimated(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data,\n",
    "                           model_name=model.name,\n",
    "                           n_trajectories=len(obs_data),\n",
    "                           simulator=simulator,\n",
    "                           #save_fig=model_name+'_eGFP_estimate' if load_real_data else model_name+'_synthetic_estimate',\n",
    "                           seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_parameter_estimates(result_list: list[np.ndarray],\n",
    "                             param_names_plot: list[str],\n",
    "                             prior_mean: np.ndarray = None,\n",
    "                             prior_std: np.ndarray = None,\n",
    "                             true_parameters: np.ndarray = None,\n",
    "                             run_names: list[str] = None,  # None, if multi-starts are compared\n",
    "                             save_fig: bool = False) -> None:\n",
    "    # plot parameters\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))  # , dpi=600)\n",
    "    parameters_ind = list(range(1, result_list[0].shape[0] + 1))[::-1]\n",
    "\n",
    "    if prior_mean is not None and prior_std is not None:\n",
    "        n_pop_params = len(prior_mean)\n",
    "        prior_interval = np.array([prior_mean - 1.96 * prior_std, prior_mean + 1.96 * prior_std]).T\n",
    "        ax.fill_betweenx(parameters_ind[:n_pop_params], prior_interval[:, 0], prior_interval[:, 1],\n",
    "                         color='grey', alpha=0.2, label='95% prior region')\n",
    "\n",
    "    for j_x, x in reversed(list(enumerate(result_list))):\n",
    "        if run_names is None:\n",
    "            if j_x == 0:\n",
    "                pass\n",
    "                #tmp_legend = 'optimal run'\n",
    "            else:\n",
    "                tmp_legend = None\n",
    "        else:\n",
    "            tmp_legend = run_names[j_x]\n",
    "        ax.plot(\n",
    "            x,\n",
    "            parameters_ind,\n",
    "            linestyle='dashed',\n",
    "            color='blue',\n",
    "            marker='o',\n",
    "            label=tmp_legend,\n",
    "        )\n",
    "        \n",
    "    if true_parameters is not None:\n",
    "        ax.plot(true_parameters, parameters_ind, color='red', marker='x',\n",
    "                label='true parameters sample')\n",
    "        \n",
    "    ax.set_yticks(parameters_ind, param_names_plot)\n",
    "    ax.set_xlabel('Parameter value')\n",
    "    ax.set_ylabel('Parameter')\n",
    "    ax.set_title('Estimated Population Parameters (log-normal distribution)')\n",
    "    ax.legend(loc=2, bbox_to_anchor=(1, 1))\n",
    "    fig.tight_layout()\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c482b204949a96fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_estimates(results_transformed,\n",
    "                         param_names_plot=full_param_names,\n",
    "                         prior_mean=prior_mean,\n",
    "                         prior_std=prior_std,\n",
    "                         true_parameters=true_pop_parameters,\n",
    "                         save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfe5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_estimated_distributions(results_transformed[0],\n",
    "                             param_names_plot=param_names,\n",
    "                             prior_mean=prior_mean,\n",
    "                             prior_std=prior_std,\n",
    "                             true_parameters=true_pop_parameters,\n",
    "                             save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5521063",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_to_compare is not None:\n",
    "    compare_list = [results_transformed[0], results_to_compare[0]]\n",
    "    plot_parameter_estimates(compare_list, param_names_plot=full_param_names,\n",
    "                         prior_mean=model.prior_mean,\n",
    "                         prior_std=model.prior_std,\n",
    "                         true_parameters=true_pop_parameters,\n",
    "                         run_names=['BayesFlow', 'Baseline'],\n",
    "                         save_fig=False)\n",
    "\n",
    "    print('Baseline Estimated Parameters')\n",
    "    plot_parameter_estimates(results_to_compare, param_names_plot=full_param_names,\n",
    "                         prior_mean=model.prior_mean,\n",
    "                         prior_std=model.prior_std,\n",
    "                         save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70f2e8",
   "metadata": {},
   "source": [
    "# Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186fb11",
   "metadata": {},
   "source": [
    "Uncertainty based on profiles -> more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_options = profile.ProfileOptions(\n",
    "    min_step_size=0.0005, #0.001\n",
    "    step_size_factor=1.1, #1.25\n",
    "    delta_ratio_max=0.05, #0.1\n",
    "    default_step_size=0.005, #0.01\n",
    "    ratio_min=0.01, #0.145\n",
    ")\n",
    "\n",
    "result_optimization = profile.parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    "    optimizer=optimize.ScipyOptimizer(),\n",
    "    engine=engine.MultiProcessEngine(10),\n",
    "    #profile_index=np.array([0]),\n",
    "    #result_index=0, # index from which optimization result profiling should be started\n",
    "    #profile_options=profile_options,\n",
    "    #filename=f'output/uncertainty/{model.name}_cells_{n_data}_samples_{50}.hd5',\n",
    "    #overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcdefaults()  # for resetting to defaults\n",
    "plt.rcParams.update({'font.size': 14,\n",
    "                     #'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'xx-small', # todo: change back to small\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,12)}) #\n",
    "colors = ['#1f78b4', '#a6cee3', '#b2df8a','#33a02c','#fb9a99']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff1f595e405f9776"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profiles(result_optimization, size=(16,12))\n",
    "#plt.savefig('plots/synthetic_profiles_small_stochastic_data.pdf', bbox_inches='tight', dpi=600, format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(result_optimization) #,\n",
    "                                  #profile_indices=[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('plots/synthetic_FIM_profiles_cis.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "if model_name == 'pharmacokinetic_model':\n",
    "    plt.scatter(np.arange(1, len(raw_data['ofv'])+1-15), -raw_data['ofv'][:-15])\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3435c9c56bfb6b28"
  },
  {
   "cell_type": "raw",
   "source": [
    "# todo: outdated\n",
    "if model_name == 'pharmacokinetic_model':\n",
    "    x_names = [result_optimization.problem.x_names[ix] for ix in profile_indices]\n",
    "    x_names[11] = 'var $\\\\eta_0$'\n",
    "    x_names[12] = 'var $\\\\eta_1$'\n",
    "    x_names[13] = 'var $\\\\eta_2$'\n",
    "    x_names[14] = 'var $\\\\eta_3$'\n",
    "\n",
    "    n_results_compare = 100\n",
    "    results_compare_min = np.min(results_to_compare[:n_results_compare], axis=0)\n",
    "    results_compare_max = np.max(results_to_compare[:n_results_compare], axis=0)\n",
    "    intervals_compare = np.array([results_compare_min, results_compare_max]).T\n",
    "\n",
    "    baseline_params = [results_to_compare[0][ix] for ix in profile_indices]\n",
    "    intervals_compare_non_fixed = [intervals_compare[ix] for ix in profile_indices]\n",
    "\n",
    "    # wt and DOS are not removed from the prior\n",
    "    prior_mean_non_fixed = [model.prior_mean[ix] for ix in profile_indices if ix <= model.n_params]\n",
    "    prior_mean_non_fixed[-1] = model.prior_mean[14+2]\n",
    "    prior_std_non_fixed = np.array([model.prior_std[ix] for ix in profile_indices if ix <= model.n_params])\n",
    "    prior_std_non_fixed[-1] = model.prior_std[14+2]\n",
    "    prior_intervals = np.array([prior_mean_non_fixed - 1.96*prior_std_non_fixed,\n",
    "                                prior_mean_non_fixed + 1.96*prior_std_non_fixed]).T\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('\\\\bf{C}', loc='left')\n",
    "    for y, (ci_l, ci_u) in enumerate(prior_intervals):\n",
    "        plt.plot([ci_l, ci_u], [y, y], linestyle='--', color='g', label='95\\% Prior-Region' if y == 0 else None)\n",
    "\n",
    "    for y, (l, u) in enumerate(intervals_compare_non_fixed):\n",
    "        if y < 11:\n",
    "            plt.plot([l, u], [y, y], marker='|', color='b', label=f'Range of Best Fits Baseline' if y == 0 else None)\n",
    "            plt.plot(baseline_params[y], y, marker='x', color='y', label='Optimal Fit Baseline' if y == 0 else None)\n",
    "        else:\n",
    "            # convert variance params\n",
    "            plt.plot([np.exp(-u), np.exp(-l)], [y, y], marker='|', color='b')\n",
    "            plt.plot(np.exp(-baseline_params[y]), y, marker='x', color='y')\n",
    "\n",
    "    for y, (ci_l, ci_u) in enumerate(intervals):\n",
    "        if y < 11:\n",
    "            plt.plot([ci_l, ci_u], [y, y], marker='|', color='r', label='CI Amortized NLME' if y == 0 else None)\n",
    "        else:\n",
    "            # convert variance params\n",
    "            plt.plot([np.exp(-ci_u), np.exp(-ci_l)], [y, y], marker='|', color='r')\n",
    "\n",
    "    #plt.xscale('symlog')\n",
    "    plt.yticks(ticks=np.arange(len(x_names)), labels=x_names)\n",
    "    plt.xlabel('Parameter Value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea454315255f0a0"
  },
  {
   "cell_type": "markdown",
   "id": "35ac88c2",
   "metadata": {},
   "source": [
    "Uncertainty based on FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_optimization = profile.approximate_parameter_profile(\n",
    "    problem=result_optimization.problem,\n",
    "    result=result_optimization,\n",
    "    #profile_index=np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "    #result_index=0, # index from which optimization result profiling should be started\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(result_optimization)\n",
    "#plt.savefig('plots/synthetic_FIM_profiles.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_indv = obs_data.shape[0]\n",
    "confidence_ratio = profile.chi2_quantile_to_ratio(alpha=0.95, df=n_indv-(model.n_params*2))\n",
    "\n",
    "confidence_intervals = np.zeros((model.n_params*2, 2))\n",
    "\n",
    "for param_idx in range(model.n_params*2):\n",
    "    try:\n",
    "        xs = result_optimization.profile_result.list[0][param_idx]['x_path'][param_idx]\n",
    "        ratios = result_optimization.profile_result.list[0][0]['ratio_path']\n",
    "        confidence_intervals[param_idx] = profile.calculate_approximate_ci(xs, ratios,\n",
    "                                                                            confidence_ratio=confidence_ratio)\n",
    "    except TypeError:\n",
    "        print(f'for {full_param_names[param_idx]} confidence interval could not be estimated')\n",
    "\n",
    "confidence_intervals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c875c48b2d412283"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d4fffc09c3b1cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
