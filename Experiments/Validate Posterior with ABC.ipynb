{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Validate BayesFlow Posterior with ABC\n",
    "\n",
    "In this notebook we are going to validate the posterior from BayesFlow by comparing it to posteriors generated from ABC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyabc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', 'pharmacokinetic_model', 'clairon_small_model'][2]\n",
    "network_idx = 0\n",
    "load_best_network = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load individual model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f686177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator\n",
    "    individual_model = FroehlichModelSimple(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator\n",
    "    individual_model = FroehlichModelDetailed(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE, batch_simulator\n",
    "    individual_model = FroehlichModelSDE(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel, batch_simulator, convert_bf_to_observables\n",
    "    individual_model = PharmacokineticModel(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel, batch_simulator, convert_bf_to_observables\n",
    "    prior_type = ['normal', 'uniform'][0]\n",
    "    individual_model = ClaironSmallModel(network_idx=network_idx, load_best=load_best_network, prior_type=prior_type)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# load network\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652919f1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fedc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load synthetic data for specific model\n",
    "load_synthetic = False\n",
    "obs_data = individual_model.load_data(synthetic=load_synthetic)\n",
    "\n",
    "# chose 10 random individuals/cells\n",
    "np.random.seed(42)\n",
    "individual_ids = np.random.randint(0, len(obs_data), size=10)  # obs_data can be list or numpy array\n",
    "obs_data = [obs_data[i] for i in individual_ids]\n",
    "    \n",
    "\n",
    "if load_synthetic:\n",
    "    # for these model parameters are known\n",
    "    if model_name == 'fröhlich-sde':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_sde_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    elif model_name == 'fröhlich-detailed':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_detailed_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    else:\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params.csv',\n",
    "                                     index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042eda80",
   "metadata": {},
   "source": [
    "## Examine Posterior for a Single Individual/Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b686911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use observations to get a first look at the posterior\n",
    "n_bayesflow_samples = 1000\n",
    "obs_data_posterior_samples = individual_model.draw_posterior_samples(data=obs_data, n_samples=n_bayesflow_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = 4\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(obs_data) / rows)), tight_layout=True, figsize=(10, rows*3),\n",
    "                       sharex='row', sharey='all')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(len(obs_data))):\n",
    "    axis[p_id] = individual_model.prepare_plotting(obs_data[p_id], obs_data_posterior_samples[p_id, :100], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "    \n",
    "for _ax in axis[len(obs_data):]:\n",
    "    _ax.remove()\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9e9b2415a879e8"
  },
  {
   "cell_type": "markdown",
   "id": "b0e53a41",
   "metadata": {},
   "source": [
    "## Prepare ABC Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "individual_id = 1  # patient 5 for pharma, fro-detailed 0\n",
    "obs_data_indv = obs_data[individual_id]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797e14cfcb6d92a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare simulator accordingly to the model\n",
    "if 'Froehlich' in individual_model.name :\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    simulator = partial(batch_simulator, \n",
    "                                n_obs=180,\n",
    "                                with_noise=True)\n",
    "    obs_data_indv_prepared = obs_data_indv.flatten()  # just one measurement per time point, already on log-scale\n",
    "    observation = {\"data\": obs_data_indv_prepared}\n",
    "    \n",
    "    # pyABC \n",
    "    def abc_model(parameter: dict):\n",
    "        return {\"data\": simulator(np.fromiter(parameter.values(), dtype=float))}\n",
    "elif 'Pharma' in individual_model.name:\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    obs_data_indv_prepared, t_measurement, doses_time_points, dos, wt = convert_bf_to_observables(obs_data_indv)\n",
    "    simulator = partial(batch_simulator,\n",
    "                       t_measurement=t_measurement,\n",
    "                       t_doses=doses_time_points,\n",
    "                       wt=wt,\n",
    "                       dos=dos,\n",
    "                       with_noise=True,\n",
    "                       convert_to_bf_batch=False)\n",
    "    observation = {\"y1\": obs_data_indv_prepared[:, 0],\n",
    "                     \"y2\": obs_data_indv_prepared[:, 1]}\n",
    "    # pyABC \n",
    "    def abc_model(parameter: dict):\n",
    "        data = simulator(np.fromiter(parameter.values(), dtype=float))\n",
    "        return {\"y1\": data[:, 0],\n",
    "                \"y2\": data[:, 1]}\n",
    "elif 'Clairon' in individual_model.name:\n",
    "    # prepare simulator, data should be on linear scale\n",
    "    obs_data_indv_prepared, t_measurements, doses_time_points, dose_amount = convert_bf_to_observables(obs_data_indv)\n",
    "    simulator = partial(batch_simulator,\n",
    "                        t_measurements=t_measurements,\n",
    "                        t_doses=doses_time_points,\n",
    "                        with_noise=True,\n",
    "                        convert_to_bf_batch=False)    \n",
    "    observation = {\"data\": obs_data_indv_prepared}\n",
    "    # pyABC \n",
    "    def abc_model(parameter: dict):\n",
    "        return {\"data\": simulator(np.fromiter(parameter.values(), dtype=float))}\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "assert simulator(individual_model.prior_mean).shape == obs_data_indv_prepared.shape, 'simulator output shape does not match data shape' "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb680995588dcdd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build dict with name and mean adn std of parameters\n",
    "param_dict = {}\n",
    "for p_i, p in enumerate(individual_model.param_names):\n",
    "    param_dict[p] = pyabc.RV(\"norm\", loc=individual_model.prior_mean[p_i], scale=individual_model.prior_std[p_i])\n",
    "prior = pyabc.Distribution(param_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5607f9bfb5c8465"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abc = pyabc.ABCSMC(abc_model, prior,\n",
    "                   distance_function=pyabc.distance.AdaptivePNormDistance(p=1),\n",
    "                   population_size=10000,\n",
    "                   sampler=pyabc.sampler.SingleCoreSampler())\n",
    "db_path = os.path.join('sampling_results', f'abc_{individual_model.name}_individual_{individual_id}.db')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e4fa39c0cf011d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    history = abc.load(\"sqlite:///\" + db_path, 1)\n",
    "else:\n",
    "    abc.new(\"sqlite:///\" + db_path, observation)\n",
    "    max_walltime = timedelta(hours=0.1)\n",
    "    history = abc.run(min_acceptance_rate=1e-2, max_walltime=max_walltime)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1024b6c9b5aefd2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abc_samples_raw, abc_weights_raw = history.get_distribution()\n",
    "abc_samples_raw = abc_samples_raw.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3c8be3beea5be6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare BayesFlow and ABC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca40267bf1ff9280"
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.rcParams.update({'font.size': 25,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,                \n",
    "                     'figure.figsize': (16,12)}) #\n",
    "#colors = ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9646e73cef1d6a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce to same number of samples\n",
    "n_samples = min(obs_data_posterior_samples[individual_id].shape[0], abc_samples_raw.shape[0])\n",
    "bayes_flow_samples = obs_data_posterior_samples[individual_id, :n_samples]\n",
    "\n",
    "# thin abc samples to same number of samples\n",
    "abc_index = np.random.choice(range(abc_samples_raw.shape[0]), n_samples, replace=False)\n",
    "abc_samples = abc_samples_raw[abc_index]\n",
    "abc_weights = abc_weights_raw[abc_index]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9471049f70aa82b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(individual_model.n_params/2)), tight_layout=True, figsize=(16,12))\n",
    "axis = ax.flatten()\n",
    "bins = 40\n",
    "for i, name in enumerate(individual_model.param_names):\n",
    "    axis[i].set_title('log '+name)\n",
    "    axis[i].hist(bayes_flow_samples[:, i], bins=bins, density=True, label='BayesFlow', color='blue')\n",
    "\n",
    "    axis[i].hist(abc_samples[:, i], weights=abc_weights,\n",
    "                 bins=bins, density=True, label='ABC', alpha=0.6, color='red')\n",
    "    axis[i].legend()\n",
    "\n",
    "for _ax in axis[individual_model.n_params:]:\n",
    "    _ax.remove()\n",
    "#plt.savefig(f'../plots/abc/posterior_validation_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(individual_model.n_params/2)), tight_layout=True, figsize=(16,12))\n",
    "# axis = ax.flatten()\n",
    "# for i, name in enumerate(individual_model.param_names):\n",
    "#     axis[i].set_title(name)\n",
    "#     axis[i].hist(np.exp(bayes_flow_samples[:, i]), bins=bins, density=True, label='BayesFlow', color='blue')\n",
    "# \n",
    "#     axis[i].hist(np.exp(abc_samples[:, i]), weights=abc_weights,\n",
    "#                  bins=bins, density=True, label='ABC', alpha=0.6, color='red')\n",
    "#     axis[i].legend()\n",
    "# \n",
    "# for _ax in axis[individual_model.n_params:]:\n",
    "#     _ax.remove()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c37b8d685ad15411"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(16, 6),\n",
    "                       sharex='row', sharey='all')\n",
    "    \n",
    "ax[0] = individual_model.prepare_plotting(obs_data_indv, obs_data_posterior_samples[individual_id], ax[0])\n",
    "ax[1] = individual_model.prepare_plotting(obs_data_indv, abc_samples, ax[1])\n",
    "_, labels = ax[0].get_legend_handles_labels()\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.01))\n",
    "ax[0].set_title('BayesFlow Posterior Predictive')\n",
    "ax[1].set_title('MCMC Posterior Predictive')\n",
    "#plt.savefig(f'../plots/abc/posterior_simulation_{individual_model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb99718e76cd7d"
  },
  {
   "cell_type": "raw",
   "source": [
    "import ot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd169c81e7d2fdc"
  },
  {
   "cell_type": "raw",
   "source": [
    "# compute wasserstein distance on original samples\n",
    "m = ot.dist(bayes_flow_samples, abc_samples)\n",
    "sample_weights_bf = np.ones(bayes_flow_samples.shape[0]) / bayes_flow_samples.shape[0]  # uniform\n",
    "sample_weights_mcmc = np.ones(abc_samples.shape[0]) / abc_samples.shape[0]  # uniform\n",
    "w_dist = ot.emd2(sample_weights_bf, sample_weights_mcmc, m)\n",
    "\n",
    "print(f'Wasserstein distance between posteriors {w_dist}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4c30851eefc1bc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "To see visually if samples differ, we map the posterior samples in a two-dimensional space using a UMAP. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324d158dc82ee949"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34ad569f8d46d2f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalize samples\n",
    "all_samples = np.concatenate((bayes_flow_samples, abc_samples), axis=0)\n",
    "scaled_samples = StandardScaler().fit_transform(all_samples)\n",
    "\n",
    "# create umap\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1,   # for reproducibility \n",
    "                    #densmap=True,  # preserve local density\n",
    "                    ) \n",
    "umap_embedding = reducer.fit_transform(scaled_samples)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b5cb6f0d29610cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True, figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    umap_embedding[:n_samples, 0],\n",
    "    umap_embedding[:n_samples, 1], label='BayesFlow', alpha=0.7, color='blue')\n",
    "plt.scatter(\n",
    "    umap_embedding[n_samples:, 0],\n",
    "    umap_embedding[n_samples:, 1], label='MCMC', alpha=0.7, color='red')\n",
    "plt.legend()\n",
    "plt.title('Umap Based Representation of Posterior Distributions')\n",
    "\n",
    "#plt.savefig(f'../plots/abc/posterior_umap_{individual_model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eabb7eef19a8630"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc428bcca7d5aea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
