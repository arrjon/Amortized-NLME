{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model\n",
    "\n",
    "## Individual Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pypesto.optimize as pesto_opt\n",
    "from pypesto import FD, Objective, Problem, store\n",
    "from scipy.stats import normaltest\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for amortized inference\n",
    "from inference.inference_functions import create_boundaries_from_prior\n",
    "from inference.nlme_objective import get_covariance\n",
    "from inference.empirical_bayes import ObjectiveFunctionEmpiricalBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8adc6d89"
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load ODE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf260c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "    n_data = 500\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "    n_data = 500\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE, batch_simulator\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "    n_data = 500\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel, simulate_single_patient, convert_bf_to_observables\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "    n_data = 47\n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel, simulate_single_patient, convert_bf_to_observables\n",
    "    individual_model = ClaironSmallModel(load_best=True)\n",
    "    n_data = 742\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "individual_model.plot_example()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f5cc507fad985a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = individual_model.load_data(n_data=n_data)\n",
    "posterior_draws = individual_model.draw_posterior_samples(data=obs_data, n_samples=100)\n",
    "print(len(obs_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Cell / Patient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7727a4fcf2058c7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e0dbda7d95d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_idx = 0\n",
    "\n",
    "# simulate\n",
    "if 'fröhlich' in model_name:\n",
    "    t_measurements_full = np.linspace(start=1 / 6, stop=30, num=180, endpoint=True)\n",
    "    y_sim = batch_simulator(posterior_draws[individual_idx], \n",
    "                            with_noise=False).squeeze(axis=2)\n",
    "    t_measurements = t_measurements_full\n",
    "    y = obs_data[individual_idx]\n",
    "elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "    y_sim = simulate_single_patient(posterior_draws[individual_idx], \n",
    "                                    patient_data=obs_data[individual_idx], \n",
    "                                    full_trajectory=True,\n",
    "                                    with_noise=False)\n",
    "    observations = convert_bf_to_observables(obs_data[individual_idx])\n",
    "    # this is the same for the clairon and pharma model\n",
    "    y = observations[0]\n",
    "    t_measurements = observations[1]\n",
    "    doses_time_points = observations[2]\n",
    "    t_measurements_full = np.linspace(0, t_measurements[-1], 100)\n",
    "else:\n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute median and 95% percentiles\n",
    "if 'pharma' in model_name:\n",
    "    # pharma has two observables\n",
    "    y_median_1 = np.median(y_sim[:, :, 0], axis=0)\n",
    "    y_perc_1 = np.percentile(y_sim[:, :, 0], (2.5, 97.5), axis=0)\n",
    "    y_median_2 = np.median(y_sim[:, :, 1], axis=0)\n",
    "    y_perc_2 = np.percentile(y_sim[:, :, 1], (2.5, 97.5), axis=0)\n",
    "    plt.plot(t_measurements_full, y_median_1, color='orange', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc_1[0], y_perc_1[1], color='orange', alpha=0.2)\n",
    "    plt.plot(t_measurements_full, y_median_2, color='red', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc_2[0], y_perc_2[1], color='red', alpha=0.2)\n",
    "    \n",
    "    plt.scatter(t_measurements, y[:, 0], label='measurements', color='orange')\n",
    "    plt.scatter(t_measurements, y[:, 1], label='measurements', color='red')\n",
    "else:\n",
    "    y_median = np.median(y_sim, axis=0)\n",
    "    y_perc = np.percentile(y_sim, (2.5, 97.5), axis=0)\n",
    "    plt.plot(t_measurements_full, y_median, color='orange', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc[0], y_perc[1], color='orange', alpha=0.2)\n",
    "\n",
    "    plt.scatter(t_measurements, y, label='measurements')\n",
    "    \n",
    "if 'clairon' in model_name or 'pharma' in model_name:\n",
    "    plt.vlines(doses_time_points, 0, np.max(y), color='grey', alpha=0.2, label='doses')\n",
    "plt.legend()\n",
    "plt.title(f'Patient {individual_idx}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93713ed016dc4b16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Individuals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20c4039aedb4badf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load pypesto result\n",
    "covariance_format = ['diag', 'cholesky'][0]\n",
    "filename_result_population = f'../output/{model_name}-{covariance_format}-n_data_{n_data}.hdf5' \n",
    "result_optimization = store.read_result(filename_result_population)\n",
    "best_res = result_optimization.optimize_result.x[0]\n",
    "\n",
    "pop_mean = best_res[:individual_model.n_params]\n",
    "pop_cov = get_covariance(best_res[individual_model.n_params:], \n",
    "                         covariance_format=covariance_format, param_dim=individual_model.n_params)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d05535b5b3a6ee6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_bounds = create_boundaries_from_prior(\n",
    "            prior_mean=individual_model.prior_mean,\n",
    "            prior_std=individual_model.prior_std,\n",
    "            prior_type=individual_model.prior_type,\n",
    "            prior_bounds=individual_model.prior_bounds if hasattr(individual_model, 'prior_bounds') else None,\n",
    "            boundary_width_from_prior=5,\n",
    "            covariance_format=covariance_format)\n",
    "# we are only interested in the mean parameters\n",
    "lower_bound = param_bounds[0, :individual_model.n_params]\n",
    "upper_bound = param_bounds[1, :individual_model.n_params]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe84906ed0d5b225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fixed_indices = [i for i, name in enumerate(individual_model.param_names) if 'error' in name or 'sigma' in name]\n",
    "free_indices = [i for i in range(individual_model.n_params) if i not in fixed_indices]\n",
    "fixed_values = pop_mean[fixed_indices]\n",
    "guess_val = pop_mean[[i for i in range(individual_model.n_params) if i not in fixed_indices]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c44aa274027a28a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_empirical_bayes_helper(individual_idx: int, \n",
    "                                n_start: int,\n",
    "                                obs_data: np.ndarray,\n",
    "                                pop_mean: np.ndarray,\n",
    "                                pop_cov: np.ndarray,\n",
    "                                lower_bound: np.ndarray,\n",
    "                                upper_bound: np.ndarray,\n",
    "                                fixed_indices: np.ndarray,\n",
    "                                fixed_values: np.ndarray,\n",
    "                                verbose: bool = False,\n",
    "                               get_likelihood: bool = False) -> np.ndarray:\n",
    "    \n",
    "    # create objective function\n",
    "    # prepare batch simulator\n",
    "    noise_type = 'multiplicative'\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=False)  # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[individual_idx].flatten()\n",
    "        # error covariance\n",
    "        sigmas = np.exp(pop_mean[-1])\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          patient_data=obs_data[individual_idx], \n",
    "                                          with_noise=False)\n",
    "        observations = convert_bf_to_observables(obs_data[individual_idx])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "        \n",
    "        if 'clairon' in model_name:\n",
    "            sigmas = np.exp(pop_mean[-2]) + np.exp(pop_mean[-1])*y\n",
    "            noise_type = 'additive'  # with proportional variance\n",
    "        else:\n",
    "            sigmas = np.array([np.exp(pop_mean[8:10])**2] * y.shape[0])\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    \n",
    "    eb_obj_fun = ObjectiveFunctionEmpiricalBayes(\n",
    "        data=y,\n",
    "        pop_mean=pop_mean,\n",
    "        pop_cov=pop_cov,\n",
    "        sigmas=sigmas,\n",
    "        batch_simulator=partial_batch_simulator,\n",
    "        noise_type=noise_type,\n",
    "        ignore_conditional=get_likelihood\n",
    "    )\n",
    "        \n",
    "    pesto_objective = FD(obj=Objective(fun=eb_obj_fun,\n",
    "                                   x_names=individual_model.param_names))\n",
    "    pesto_problem = Problem(objective=pesto_objective,\n",
    "                            lb=lower_bound, ub=upper_bound,\n",
    "                            x_fixed_indices=fixed_indices,\n",
    "                            x_fixed_vals=fixed_values,\n",
    "                            x_names=individual_model.param_names,\n",
    "                            x_scales=['log']*individual_model.n_params,\n",
    "                            x_guesses=[guess_val]\n",
    "                            )\n",
    "    if verbose:\n",
    "        print(pesto_problem.print_parameter_summary())\n",
    "\n",
    "    result = pesto_opt.minimize(\n",
    "        problem=pesto_problem,\n",
    "        optimizer=pesto_opt.ScipyOptimizer(),\n",
    "        # engine=engine.MultiProcessEngine(10), # not working due to pickling issues\n",
    "        n_starts=n_start,\n",
    "        progress_bar=verbose)\n",
    "    return result.optimize_result.as_dataframe()\n",
    "\n",
    "get_empirical_bayes = partial(get_empirical_bayes_helper, n_start=10,\n",
    "                                    obs_data=obs_data,\n",
    "                                    pop_mean=pop_mean,\n",
    "                                    pop_cov=pop_cov,\n",
    "                                    lower_bound=lower_bound,\n",
    "                                    upper_bound=upper_bound,\n",
    "                                    fixed_indices=fixed_indices,\n",
    "                                    fixed_values=fixed_values)\n",
    "\n",
    "get_likelihoods = partial(get_empirical_bayes_helper, n_start=10,\n",
    "                                    obs_data=obs_data,\n",
    "                                    pop_mean=pop_mean,\n",
    "                                    pop_cov=pop_cov,\n",
    "                                    lower_bound=lower_bound,\n",
    "                                    upper_bound=upper_bound,\n",
    "                                    fixed_indices=fixed_indices,\n",
    "                                    fixed_values=fixed_values,\n",
    "                                    get_likelihood=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc2d33bd875c78a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "individual_idx = 10\n",
    "result = get_empirical_bayes(individual_idx, n_start=1, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a323cfc56145c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posterior_samples = individual_model.draw_posterior_samples(data=obs_data[individual_idx][np.newaxis, :], n_samples=50)\n",
    "posterior_median = np.median(posterior_samples, axis=0)\n",
    "\n",
    "print('empirical bayes ', result.x[0][free_indices])\n",
    "print('posterior       ', posterior_median[free_indices])\n",
    "print('population      ', pop_mean[free_indices])\n",
    "print('error population', pop_mean[fixed_indices])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad9a2d808eb7fb7"
  },
  {
   "cell_type": "raw",
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    with Pool(10) as mp_pool:\n",
    "        empirical_bayes_res_full = mp_pool.map(get_empirical_bayes_multi, range(len(obs_data[1:3])))\n",
    "    print('Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea11cd122f7e3cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "filename = f'../output/empirical_bayes-{model_name}-{covariance_format}-n_data_{n_data}.pkl' \n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    empirical_bayes_res_full = []\n",
    "    for i in range(2): #n_data):\n",
    "        empirical_bayes_res_full.append(get_empirical_bayes(i))\n",
    "       \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(empirical_bayes_res_full, f)\n",
    "     \n",
    "else:\n",
    "    with open(filename, 'rb') as f:\n",
    "        empirical_bayes_res_full = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcf9812533fd9ce4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "filename_l = f'../output/likelihoods-{model_name}-{covariance_format}-n_data_{n_data}.pkl' \n",
    "\n",
    "if not os.path.exists(filename_l):\n",
    "    likelihoods_res_full = []\n",
    "    for i in range(2): #n_data):\n",
    "        likelihoods_res_full.append(get_likelihoods(i))\n",
    "       \n",
    "    with open(filename_l, 'wb') as f:\n",
    "        pickle.dump(likelihoods_res_full, f)\n",
    "     \n",
    "else:\n",
    "    with open(filename_l, 'rb') as f:\n",
    "        likelihoods_res_full = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5db6f074da033956"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce dataframes to get only the estimates\n",
    "empirical_bayes_res = np.array([np.array([i for  i in entry['x']]) for entry in empirical_bayes_res_full])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d6eb9191f48306"
  },
  {
   "cell_type": "raw",
   "source": [
    "with open(monolix_file, 'rb') as f:\n",
    "    monolix_res_full = pickle.load(f)\n",
    "    monolix_res = np.array([entry['x'][0] for entry in monolix_res_full])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d35b30962220e9c"
  },
  {
   "cell_type": "raw",
   "source": [
    "# take median of starts\n",
    "#empirical_bayes_res = np.array([np.median(np.stack(entry['x']), axis=0) \n",
    "#                                for entry in empirical_bayes_res_full])\n",
    "# use only best result\n",
    "empirical_bayes_res = np.array([entry['x'][0] for entry in empirical_bayes_res_full])\n",
    "#np.save('output/empirical_bayes_res_likelihood_clairon_24_10'\n",
    "#                              f'{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr.npy', empirical_bayes_res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bebe49912ccafd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.array(individual_model.param_names)[free_indices])\n",
    "random_vars = empirical_bayes_res[:, 0, free_indices] - pop_mean[free_indices]\n",
    "print(np.mean(random_vars, axis=0))\n",
    "print(pop_cov[free_indices, :].diagonal())\n",
    "print(np.cov(random_vars.T).diagonal())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5cac65fc988d12a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normaltest(random_vars, axis=0).pvalue >= 0.05 # null hypothesis cannot be rejected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c55312d106574c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "with_noise = False\n",
    "obs = []\n",
    "pred_median = []\n",
    "posterior_median = []\n",
    "posterior_all_samples = []\n",
    "pred_empirical_bayes = []\n",
    "pred_likelihood = []\n",
    "pred_map = []\n",
    "pred_monolix = []\n",
    "pred_pop = []\n",
    "\n",
    "for i in tqdm(range(len(obs_data))):\n",
    "    y, t_measurements, dose_amount, doses_time_points = convert_to_observables(obs_data[i])    \n",
    "    obs.append(y)\n",
    "    \n",
    "    # compute individual posterior-median of simulations\n",
    "    posterior_samples_i = model.draw_posterior_samples(data=obs_data[i][np.newaxis, :],\n",
    "                                                       n_samples=n_samples)\n",
    "    posterior_median_i = np.median(posterior_samples_i, axis=0)\n",
    "    posterior_median.append(posterior_median_i)\n",
    "    posterior_all_samples.append(posterior_samples_i)\n",
    "    sim_data_i = batch_simulator(posterior_samples_i,\n",
    "                                 t_measurements=t_measurements,\n",
    "                                 t_doses=doses_time_points,\n",
    "                                 dose_amount=dose_amount,\n",
    "                                 with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_median.append(np.median(sim_data_i, axis=0))\n",
    "    \n",
    "    # simulate with the best empirical bayes\n",
    "    sim_data_eb = batch_simulator(empirical_bayes_res[i, 0][np.newaxis, :],\n",
    "                                t_measurements=t_measurements,\n",
    "                                t_doses=doses_time_points,\n",
    "                                dose_amount=dose_amount,\n",
    "                                with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_empirical_bayes.append(sim_data_eb)\n",
    "    \n",
    "    # simulate with likelihood estimate\n",
    "    sim_data_l = batch_simulator(likelihood_res[i][np.newaxis, :],\n",
    "                                t_measurements=t_measurements,\n",
    "                                t_doses=doses_time_points,\n",
    "                                dose_amount=dose_amount,\n",
    "                                with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_likelihood.append(sim_data_l)\n",
    "    \n",
    "    # simulate with map\n",
    "    sim_data_map = batch_simulator(map_res[i][np.newaxis, :],\n",
    "                                t_measurements=t_measurements,\n",
    "                                t_doses=doses_time_points,\n",
    "                                dose_amount=dose_amount,\n",
    "                                with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_map.append(sim_data_map)\n",
    "    \n",
    "    # simulate with monolix\n",
    "    sim_data_monolix = batch_simulator(monolix_res[i][np.newaxis, :],\n",
    "                                t_measurements=t_measurements,\n",
    "                                t_doses=doses_time_points,\n",
    "                                dose_amount=dose_amount,\n",
    "                                with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_monolix.append(sim_data_monolix)\n",
    "    \n",
    "    # simulate with covariates but no random effects (population)\n",
    "    sim_data_pop = batch_simulator(pop_params[np.newaxis, :],\n",
    "                                t_measurements=t_measurements,\n",
    "                                t_doses=doses_time_points,\n",
    "                                dose_amount=dose_amount,\n",
    "                                with_noise=with_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "    pred_pop.append(sim_data_pop)\n",
    "    \n",
    "posterior_median = np.array(posterior_median)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3232813e7b03821"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "rand_p_ids = np.random.choice(range(len(obs_data)), size=15, replace=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8d1a92061a0a3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chose random patients and plots\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(rand_p_ids) / rows)), sharex='all', sharey='all',\n",
    "                       tight_layout=True, figsize=(10, rows*3))\n",
    "axis = ax.flatten()\n",
    "\n",
    "for ax_i, p_id in tqdm(enumerate(rand_p_ids), total=len(rand_p_ids)):\n",
    "    y, t_measurements, dose_amount, doses_time_points = convert_to_observables(obs_data[p_id])\n",
    "    t_measurements_full = np.linspace(0, 700, 100)\n",
    "    for j_start in reversed(range(empirical_bayes_res.shape[1])):\n",
    "        sim_data = batch_simulator(empirical_bayes_res[p_id, j_start][np.newaxis, :],\n",
    "                                   t_measurements=t_measurements_full,\n",
    "                                   t_doses=doses_time_points,\n",
    "                                   dose_amount=dose_amount,\n",
    "                                   with_noise=False, \n",
    "                                   convert_to_bf_batch=False)\n",
    "        \n",
    "        eb_handle, = axis[ax_i].plot(t_measurements_full, sim_data, 'b', \n",
    "                                     linestyle='--' if j_start > 0 else '-',\n",
    "                                     alpha=0.2 if j_start > 0 else 1,\n",
    "                                     label='Empirical Bayes')\n",
    "    data_handle = axis[ax_i].scatter(t_measurements, y, color='g', label='data')\n",
    "    axis[ax_i].vlines(doses_time_points, 0, 2500, color='grey', linestyles='--', alpha=0.5)\n",
    "    \n",
    "    # empirical bayes based on monolix\n",
    "    sim_data = batch_simulator(monolix_res[p_id][np.newaxis, :],\n",
    "                               t_measurements=t_measurements_full,\n",
    "                               t_doses=doses_time_points,\n",
    "                               dose_amount=dose_amount,\n",
    "                               with_noise=False, \n",
    "                               convert_to_bf_batch=False)\n",
    "\n",
    "    monolix_handle, = axis[ax_i].plot(t_measurements_full, sim_data, 'r', label='EB - Monolix')\n",
    "fig.legend(handles=[data_handle, eb_handle, monolix_handle], loc='lower center',\n",
    "           bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "#plt.savefig(f'plots/comparison_fits_clairon.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35cb37386fa06e9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot individual fits\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15,5), sharey='all', sharex='all', tight_layout=True)\n",
    "ax[0].scatter(pred_median, obs, color='orange', label=f'Median of Individual Posterior')\n",
    "ax[1].scatter(pred_empirical_bayes, obs, color='orange', label=f'Empirical Bayes')\n",
    "ax[2].scatter(pred_pop, obs, color='orange', label=f'Population')\n",
    "\n",
    "ax[0].set_ylabel('Measurements')\n",
    "ax[0].set_xlabel('Simulation')\n",
    "ax[1].set_xlabel('Simulation')\n",
    "ax[2].set_xlabel('Simulation')\n",
    "ax[0].set_title('Median of Individual Posterior')\n",
    "ax[1].set_title('Empirical Bayes')\n",
    "ax[2].set_title('Population (no random effect)')\n",
    "ax[0].set_aspect('equal', 'box')\n",
    "ax[1].set_aspect('equal', 'box')\n",
    "ax[2].set_aspect('equal', 'box')\n",
    "#plt.savefig(f'plots/empirical_bayes_clairon{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b81d7f30eb0a9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute shrinkage for every parameter (1 - variance of eta / variance of population), i.e. 1 is full shrinkage\n",
    "shrinkage = []\n",
    "shrinkage_posterior = []\n",
    "shrinkage_monolix = []\n",
    "var_random_effects = pop_cov.diagonal()\n",
    "var_random_effects_monolix = pop_cov_monolix.diagonal()\n",
    "\n",
    "for p_i in range(model.n_params):\n",
    "    # from empirical bayes\n",
    "    eta_i = empirical_bayes_res[:, 0, p_i] - pop_params[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_i) / var_random_effects[p_i]\n",
    "    shrinkage.append(shrinkage_i)\n",
    "    \n",
    "    # from posterior\n",
    "    eta_pos_i = posterior_median[:, p_i] - pop_params[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_pos_i) / var_random_effects[p_i]\n",
    "    shrinkage_posterior.append(shrinkage_i)\n",
    "    \n",
    "    # for monolix\n",
    "    eta_monolix_i = monolix_res[:, p_i] - pop_mean_monolix[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_monolix_i) / var_random_effects_monolix[p_i]\n",
    "    shrinkage_monolix.append(shrinkage_i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9bb70793df67a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute correlation between random effects and covariates\n",
    "correlation_age = []\n",
    "correlation_gender = []\n",
    "correlation_age_posterior = []\n",
    "correlation_gender_posterior = []\n",
    "for p_i in range(model.n_params):\n",
    "    # from empirical bayes\n",
    "    eta_i = empirical_bayes_res[:, 0, p_i] - pop_params[p_i]\n",
    "    corr_i_age = np.corrcoef(eta_i, covariates[:, 0])[0, 1]\n",
    "    corr_i_gender = np.corrcoef(eta_i, covariates[:, 1])[0, 1]\n",
    "    correlation_age.append(corr_i_age)\n",
    "    correlation_gender.append(corr_i_gender)\n",
    "    \n",
    "    # from posterior\n",
    "    eta_pos_i = posterior_median[:, p_i] - pop_params[p_i]\n",
    "    corr_i_age = np.corrcoef(eta_pos_i, covariates[:, 0])[0, 1]\n",
    "    corr_i_gender = np.corrcoef(eta_pos_i, covariates[:, 1])[0, 1]\n",
    "    correlation_age_posterior.append(corr_i_age)\n",
    "    correlation_gender_posterior.append(corr_i_gender)\n",
    "    \n",
    "correlation = [correlation_age, correlation_gender]\n",
    "correlation_posterior = [correlation_age_posterior, correlation_gender_posterior]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41ce249afcd272aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, model.n_params-2, figsize=(15,20), sharex='col',  sharey='row', \n",
    "                       tight_layout=True)\n",
    "for p_id in range(model.n_params-2):\n",
    "    ax[0, p_id].hist(monolix_res[:, p_id], density=True, bins=20, color='red', alpha=0.5)\n",
    "    ax[0, p_id].set_title(f'$\\log$ {param_names[p_id]}\\nshrinkage {shrinkage_monolix[p_id]:.2f}')\n",
    "    \n",
    "    ax[1, p_id].hist(empirical_bayes_res[:, 0, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    ax[1, p_id].set_title(f'shrinkage {shrinkage[p_id]:.2f}')\n",
    "    \n",
    "    ax[2, p_id].hist(empirical_bayes_res[:, :, p_id].flatten(), \n",
    "                     density=True, bins=20, color='blue', alpha=0.5)\n",
    "    \n",
    "    ax[3, p_id].hist(likelihood_res[:, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    #ax[3, p_id].set_title(f'$\\log$ {param_names[p_id]}\\n{shrinkage[p_id]:.2f}')\n",
    "    \n",
    "    # ax[4, p_id].hist(map_res[:, p_id], density=True, bins=20, color='blue', alpha=0.5) # todo: still old prior\n",
    "    #ax[4, p_id].set_title(f'$\\log$ {param_names[p_id]}\\n{shrinkage[p_id]:.2f}')\n",
    "    \n",
    "    ax[5, p_id].hist(posterior_median[:, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    \n",
    "    temp = np.concatenate([s[:, p_id] for s in posterior_all_samples])\n",
    "    ax[6, p_id].hist(temp, density=True, bins=20, color='blue', alpha=0.5)\n",
    "    #ax[6, p_id].set_title(f'$\\log$ {param_names[p_id]}\\n{shrinkage[p_id]:.2f}')\n",
    "        \n",
    "    # plot expected distribution\n",
    "    x = np.linspace(pop_mean[p_id] - 2.58*pop_cov.diagonal()[p_id], \n",
    "                    pop_mean[p_id] + 2.58*pop_cov.diagonal()[p_id], 100)\n",
    "    for i in range(1, ax.shape[0]):\n",
    "        pop_handle, = ax[i, p_id].plot(x, stats.norm.pdf(x, pop_mean[p_id], np.sqrt(pop_cov.diagonal()[p_id])),\n",
    "                      color='blue', label='Estimated Population')\n",
    "    # plot pior\n",
    "    if model.prior_type == 'gaussian':\n",
    "        prior_handle, = ax[6, p_id].plot(x, stats.norm.pdf(x, prior_mean[p_id], prior_std[p_id]),\n",
    "                         color='orange', label='Individual Prior', linestyle='--')\n",
    "        prior_handle, = ax[4, p_id].plot(x, stats.norm.pdf(x, prior_mean[p_id], prior_std[p_id]),\n",
    "                         color='orange', label='Individual Prior', linestyle='--')\n",
    "    \n",
    "    # monolix\n",
    "    x = np.linspace(pop_mean_monolix[p_id] - 5*pop_cov_monolix.diagonal()[p_id], \n",
    "                    pop_mean_monolix[p_id] + 5*pop_cov_monolix.diagonal()[p_id], 100)\n",
    "    monolix_handle, = ax[0, p_id].plot(x, stats.norm.pdf(x, pop_mean_monolix[p_id], np.sqrt(pop_cov_monolix.diagonal()[p_id])),\n",
    "                     color='red', label='Monolix Population')\n",
    "    #ax[0, p_id].set_xlim(lower_bound[p_id], upper_bound[p_id])\n",
    "    \n",
    "# plot bounds for empirical bayes estimates\n",
    "ax0_ylim = ax[0, 0].get_ylim()\n",
    "ax1_ylim = ax[1, 0].get_ylim()\n",
    "ax5_ylim = ax[-1, 0].get_ylim()\n",
    "for p_id in range(model.n_params-2):\n",
    "    bound_handle = ax[0, p_id].vlines(lower_bound[p_id], ax0_ylim[0], ax0_ylim[1], color='green', linestyle='--', label='Bounds')\n",
    "    ax[0, p_id].vlines(upper_bound[p_id], ax0_ylim[0], ax0_ylim[1], color='green', linestyle='--')\n",
    "    ax[1, p_id].vlines(lower_bound[p_id], ax1_ylim[0], ax1_ylim[1], color='green', linestyle='--')\n",
    "    ax[1, p_id].vlines(upper_bound[p_id], ax1_ylim[0], ax1_ylim[1], color='green', linestyle='--')\n",
    "\n",
    "    if model.prior_type == 'uniform':\n",
    "        prior_handle = ax[6, p_id].vlines(model.prior_bounds[p_id, 0], ax5_ylim[0], ax5_ylim[1],\n",
    "                             color='orange', label='Individual Prior', linestyle='--')\n",
    "        prior_handle = ax[6, p_id].vlines(model.prior_bounds[p_id, 1], ax5_ylim[0], ax5_ylim[1],\n",
    "                             color='orange', label='Individual Prior', linestyle='--')\n",
    "    \n",
    "ax[0, 0].set_ylabel(f'EB - Monolix')\n",
    "ax[1, 0].set_ylabel(f'Empirical Bayes')\n",
    "ax[2, 0].set_ylabel(f'Empirical Bayes\\nAll Starts')\n",
    "ax[3, 0].set_ylabel(f'Individual Likelihood')\n",
    "ax[4, 0].set_ylabel(f'Individual Map')\n",
    "ax[5, 0].set_ylabel(f'Individual\\nPosterior Median')\n",
    "ax[6, 0].set_ylabel(f'Combined\\nIndividual Posterior\\nSamples')\n",
    "fig.legend(handles=[pop_handle, monolix_handle, prior_handle, bound_handle], \n",
    "           loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "\n",
    "#plt.savefig(f'plots/comparison_histograms_clairon.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8318475f374983"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, \n",
    "                       model.n_params-2, figsize=(15,10), sharex='col', sharey='row', \n",
    "                       tight_layout=True)\n",
    "for p_id in range(model.n_params-2):\n",
    "    ax[0, p_id].hist(monolix_res[:, p_id], density=True, bins=50, color='red', alpha=0.5)\n",
    "    ax[0, p_id].set_title(f'$\\log$ {param_names[p_id]}\\nshrinkage {shrinkage_monolix[p_id]:.2f}')\n",
    "    \n",
    "    ax[1, p_id].hist(empirical_bayes_res[:, :, p_id].flatten(), \n",
    "                     density=True, bins=50, color='blue', alpha=0.5)\n",
    "    ax[1, p_id].set_title(f'shrinkage {shrinkage[p_id]:.2f}')\n",
    "    \n",
    "    # plot expected distribution\n",
    "    x = np.linspace(pop_mean[p_id] - 2.58*pop_cov.diagonal()[p_id], \n",
    "                    pop_mean[p_id] + 2.58*pop_cov.diagonal()[p_id], 100)\n",
    "    for i in range(1, ax.shape[0]):\n",
    "        pop_handle, = ax[i, p_id].plot(x, stats.norm.pdf(x, pop_mean[p_id], np.sqrt(pop_cov.diagonal()[p_id])),\n",
    "                      color='blue', label='Estimated Population')\n",
    "\n",
    "    # monolix\n",
    "    x = np.linspace(pop_mean_monolix[p_id] - 5*pop_cov_monolix.diagonal()[p_id], \n",
    "                    pop_mean_monolix[p_id] + 5*pop_cov_monolix.diagonal()[p_id], 100)\n",
    "    monolix_handle, = ax[0, p_id].plot(x, stats.norm.pdf(x, pop_mean_monolix[p_id], np.sqrt(pop_cov_monolix.diagonal()[p_id])),\n",
    "                     color='red', label='Monolix Population')\n",
    "    \n",
    "ax[0, 0].set_ylabel(f'EB - Monolix')\n",
    "ax[1, 0].set_ylabel(f'Empirical Bayes')\n",
    "\n",
    "#fig.legend(handles=[pop_handle, monolix_handle, prior_handle, bound_handle], \n",
    "#           loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "\n",
    "#plt.savefig(f'plots/comparison_histograms_clairon.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4ab6f7a1ccae050"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting all samples\n",
    "test = np.concatenate(np.array(posterior_all_samples), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, model.n_params-2, figsize=(15,5), tight_layout=True)\n",
    "for p_id in range(model.n_params-2):\n",
    "    handle_pos = ax[p_id].hist(test[:, p_id], density=True, label='all individual posterior samples')\n",
    "    ax[p_id].set_title(f'$\\log$ {param_names[p_id]}')\n",
    "        \n",
    "    # plot expected distribution\n",
    "    x = np.linspace(pop_mean[p_id] - 1*pop_cov.diagonal()[p_id], \n",
    "                    pop_mean[p_id] + 1*pop_cov.diagonal()[p_id], 100)\n",
    "    handle_pop, = ax[p_id].plot(x, stats.norm.pdf(x, pop_mean[p_id], np.sqrt(pop_cov.diagonal()[p_id])),\n",
    "                  color='blue', label='Estimated Population')\n",
    "    \n",
    "    handle_prior = ax[p_id].vlines(model.prior_bounds[p_id, 0], ax5_ylim[0], ax5_ylim[1],\n",
    "                             color='orange', label='Individual Prior', linestyle='--')\n",
    "    ax[p_id].vlines(model.prior_bounds[p_id, 1], ax5_ylim[0], ax5_ylim[1],\n",
    "                             color='orange', label='Individual Prior', linestyle='--')\n",
    "        \n",
    "    #ax[p_id].set_xlim(lower_bound[p_id], upper_bound[p_id])\n",
    "ax[0].set_ylabel(f'Combined\\nIndividual Posterior\\nSamples')\n",
    "fig.legend(['all individual posterior samples', 'Estimated Population', 'Individual Prior'], loc='lower center', bbox_to_anchor=(0.5, -0.06), ncols=3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23d8f1b1b0bb632d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot covariates against individual parameters\n",
    "covariate_names = ['age', 'gender']\n",
    "\n",
    "for covariate_i, c in enumerate(covariate_names):\n",
    "    #y_axis_scale = lambda x: np.exp(x)\n",
    "    y_axis_scale = lambda x: x\n",
    "    \n",
    "    fig, ax = plt.subplots(model.n_params, 2, figsize=(15,15), sharey='all', sharex='all', tight_layout=True)\n",
    "    for p_id in range(model.n_params):\n",
    "        ax[p_id, 0].scatter(covariates[:, covariate_i], \n",
    "                            y_axis_scale(empirical_bayes_res[:, p_id])-y_axis_scale(pop_params[p_id]), \n",
    "                            color='orange')\n",
    "        ax[p_id, 1].scatter(covariates[:, covariate_i], \n",
    "                            y_axis_scale(posterior_median[:, p_id])-y_axis_scale(pop_params[p_id]), \n",
    "                            color='blue')\n",
    "        ax[p_id, 0].set_ylabel(f'$\\log$ {param_names[p_id]}')\n",
    "        # add text upper right corner\n",
    "        ax[p_id, 0].text(0.6, 0.5, f'shrinkage {shrinkage[p_id]:.2f}\\n'\n",
    "                                     f'correlation {correlation[covariate_i][p_id]:.2f}',\n",
    "                         transform=ax[p_id, 0].transAxes)\n",
    "        ax[p_id, 1].text(0.6, 0.5, f'shrinkage {shrinkage_posterior[p_id]:.2f}\\n'\n",
    "                                        f'correlation {correlation_posterior[covariate_i][p_id]:.2f}',\n",
    "                         transform=ax[p_id, 1].transAxes)\n",
    "        # ax[p_id, 0].hlines(y_axis_scale(lower_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 1].hlines(y_axis_scale(lower_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 0].hlines(y_axis_scale(upper_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 1].hlines(y_axis_scale(upper_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "    \n",
    "    ax[-1, 0].set_xlabel(f'{covariate_names[covariate_i]}')\n",
    "    ax[-1, 1].set_xlabel(f'{covariate_names[covariate_i]}')\n",
    "    ax[0, 0].set_title(f'Empirical Bayes')\n",
    "    ax[0, 1].set_title(f'Individual Posterior Median\\n(without population information)')\n",
    "    \n",
    "    #plt.savefig(f'plots/covariates_clairon{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr_{covariate_names[covariate_i]}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b47d226ac9e32cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e90c9f819193ef48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
