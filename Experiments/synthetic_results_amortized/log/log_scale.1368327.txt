2023-12-25 21:50:55.745800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-25 21:50:56.019765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-12-25 21:50:56.019814: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-12-25 21:50:57.146153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-12-25 21:50:57.146362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-12-25 21:50:57.146372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-12-25 21:51:24.627107: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-12-25 21:51:24.627401: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2023-12-25 21:51:24.627424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cn07): /proc/driver/nvidia/version does not exist
2023-12-25 21:51:24.627983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:root:Performing 2 pilot runs with the DetailedFroehlichModel model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 11)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 180, 1)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
INFO:root:Loaded loss history from networks/amortizer-detailed-fro-sequence-summary-Bi-LSTM-7layers-2coupling-spline-500epochs/history_335.pkl.
INFO:root:Networks loaded from networks/amortizer-detailed-fro-sequence-summary-Bi-LSTM-7layers-2coupling-spline-500epochs/ckpt-335
INFO:root:Performing a consistency check with provided components...
INFO:root:Done.
using 2 layers of MultiConv1D, a bidirectional LSTM with 256 units and a dense layer with output dimension 22 as summary network
using a 7-layer cINN as inference network with 2 layers of design spline
prior mean: [-1. -1. -1. 12. -1.  1. -1. -6.  0.  0. -1.]
prior covariance diagonal: [5. 5. 2. 1. 2. 2. 2. 5. 2. 5. 2.]
Using the model DetailedFroehlichModel
Model: "amortized_posterior"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 invertible_network (Inverti  multiple                 769265    
 bleNetwork)                                                     
                                                                 
 sequence_network (SequenceN  multiple                 610614    
 etwork)                                                         
                                                                 
=================================================================
Total params: 1,379,879
Trainable params: 1,379,725
Non-trainable params: 154
_________________________________________________________________
None
100 samples
5000 individuals
['pop-$\\delta_1 m_0$', 'pop-$\\delta_2$', 'pop-$e_0 m_0$', 'pop-$k_2 m_0 scale$', 'pop-$k_2$', 'pop-$k_1 m_0$', 'pop-$r_0 m_0$', 'pop-$\\gamma$', 'pop-$t_0$', 'pop-offset', 'pop-$\\sigma$', 'var-$\\delta_1 m_0$', 'var-$\\delta_2$', 'var-$e_0 m_0$', 'var-$k_2 m_0 scale$', 'var-$k_2$', 'var-$k_1 m_0$', 'var-$r_0 m_0$', 'var-$\\gamma$', 'var-$t_0$', 'var-offset', 'var-$\\sigma$']
## Optimization Result 

* number of starts: 100 
* best value: -50692.50665418349, id=batch_86_0
* worst value: -50618.19881104212, id=batch_65_0
* number of non-finite values: 0

* execution time summary:
	* Mean execution time: 322.468s
	* Maximum execution time: 404.560s,	id=batch_96_0
	* Minimum execution time: 248.475s,	id=batch_60_0
* summary of optimizer messages:

  |   Count | Message                                         |
  |--------:|:------------------------------------------------|
  |     100 | CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH |

* best value found (approximately) 1 time(s)
* number of plateaus found: 12

A summary of the best run:

### Optimizer Result

* optimizer used: <ScipyOptimizer method=L-BFGS-B options={'disp': False, 'maxfun': 1000}>
* message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH 
* number of evaluations: 178
* time taken to optimize: 325.662s
* startpoint: [ 5.65636574  4.57395662 -1.6270243   9.66299928  0.01210339  4.99423919
 -4.70690401 -8.73615974  1.87617097  5.3029789   2.36234937 -0.52725012
 -0.03893874 -2.71484901 -4.12203949 -5.12217386 -6.23230813 -3.75681887
 -7.15046714 -1.81543204  5.8780721 ]
* endpoint: [ 7.13108327e-01 -5.62762950e-01 -7.39711471e-01  1.24426405e+01
 -3.63455997e-04  1.30061112e+00 -2.38687335e+00 -6.85744897e+00
 -3.41372408e-01  2.08799260e+00 -3.44672144e+00 -3.50698185e-01
  3.01836897e-01  8.65115017e-01  8.01631719e-02  8.87112213e-01
 -1.36292764e-01 -4.15610881e-01 -1.67223150e+00  7.60673534e-01
  6.19214367e+00]
* final objective value: -50692.50665418349
* final gradient value: [ 4.38682036e-01  4.28262865e-02  1.61411299e+00 -2.54571205e-01
  3.56259989e-01 -4.04543243e-02 -5.79166226e-03 -5.09317033e-03
  2.90863682e-01 -1.05433719e+00  6.45604450e+00 -7.63247954e-03
 -5.82454959e-01  5.30526449e-01 -1.58288458e-01  2.70505552e-01
 -3.46997695e-01 -7.09296728e-01 -3.41482519e-01  1.48552499e+00
 -1.24320907e+03]

