{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import store\n",
    "\n",
    "from inference.nlme_objective import ObjectiveFunctionNLME\n",
    "from inference.helper_functions import compute_error_estimate, compute_variance_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde'][2]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e0c2ea767c3911"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    individual_model = ClaironSmallModel(load_best=True)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f45ab540474f210b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=individual_model.name,\n",
    "                                          param_samples=np.empty((1,1,1)),\n",
    "                                          prior_mean=individual_model.prior_mean,\n",
    "                                          prior_std=individual_model.prior_std,\n",
    "                                          covariance_format='diag',\n",
    "                                          covariates=None,\n",
    "                                          covariate_mapping=None,\n",
    "                                          prior_type=individual_model.prior_type,\n",
    "                                          prior_bounds=individual_model.prior_bounds if hasattr(individual_model, 'prior_bounds') else None,  # for uniform prior\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9be5ec22fcad780"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compute_relative_error = False  # relative to true parameter values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2c7455628976bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_n_cells = [50, 100, 500, 5000, 10000]\n",
    "n_samples_opt_list = [10, 50, 100, 500]\n",
    "n_runs = 104\n",
    "time_opt = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "amortized_error = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "amortized_var = np.ones((len(test_n_cells), len(n_samples_opt_list))) * np.nan\n",
    "    \n",
    "for nc, n_cells in enumerate(test_n_cells):\n",
    "    for ns, n_samples in enumerate(n_samples_opt_list):\n",
    "        # load results\n",
    "        filename = f'synthetic_results_amortized/{individual_model.name}_cells_{n_cells}_samples_{n_samples}.hd5'\n",
    "        result_optimization = store.read_result(filename)\n",
    "        results_params = np.array(result_optimization.optimize_result.x)\n",
    "        #assert results_params.shape[0] == n_runs, f'number of runs ({n_runs}) does not match number of results ({results_params.shape[0]})'\n",
    "                \n",
    "        # load true population parameters\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_cells)\n",
    "        # set very small variances to 0.001\n",
    "        true_pop_parameters[individual_model.n_params:][true_pop_parameters[individual_model.n_params:] < 0.001] = 0.001\n",
    "        \n",
    "        estimated_params_full = []\n",
    "        for i_r, res in enumerate(results_params):\n",
    "            # transform results\n",
    "            estimated_beta = res[:individual_model.n_params]\n",
    "            estimated_var = np.exp(-res[individual_model.n_params:individual_model.n_params*2])\n",
    "            estimated_params = np.concatenate((estimated_beta, estimated_var))\n",
    "                         \n",
    "            # compute relative error of parameter estimated as minimum over multi_starts\n",
    "            amortized_error[nc, ns, i_r] = compute_error_estimate(estimated_params,\n",
    "                                                            true_pop_parameters,\n",
    "                                                            bi_modal=True if 'Simple' in individual_model.name else False,\n",
    "                                                            relative_error=compute_relative_error)\n",
    "            estimated_params_full.append(estimated_params)\n",
    "            \n",
    "        amortized_var[nc, ns] = compute_variance_estimate(np.array(estimated_params_full))\n",
    "             \n",
    "        # get duration of optimization procedure (in seconds)\n",
    "        time_opt[nc, ns, :results_params.shape[0]] = np.array(result_optimization.optimize_result.time) / 60 / 60\n",
    "#amortized_error.sort(axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc145dd814e54bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read results from monolix\n",
    "if 'simple' in model_name:\n",
    "    reorder_monolix_params = [0,1,2,3,4,10,5,6,7,8,9]\n",
    "elif 'detailed' in model_name:\n",
    "    reorder_monolix_params = [0,1,2,3,4,5,6,7,8,9,20,10,11,12,13,14,15,16,17,18,19]\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "monolix_errors = np.ones(len(test_n_cells)) * np.nan\n",
    "monolix_var = np.ones(len(test_n_cells)) * np.nan\n",
    "timing_monolix = np.ones(len(test_n_cells)) * np.nan\n",
    "\n",
    "for cell_idx, n_cells in enumerate(test_n_cells):\n",
    "    if 'detailed' in model_name and n_cells == 200: continue \n",
    "    \n",
    "    estimates_monolix = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_poppars.csv',\n",
    "                                    index_col=0, header=0)\n",
    "    \n",
    "    true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_cells)\n",
    "    # set very small variances to 0.001\n",
    "    true_pop_parameters[individual_model.n_params:][true_pop_parameters[individual_model.n_params:] < 0.001] = 0.001\n",
    "\n",
    "    results_to_compare = []\n",
    "    for col in estimates_monolix.columns:\n",
    "        temp_res = estimates_monolix[col].values[reorder_monolix_params]\n",
    "        temp_res[individual_model.n_params-1] = np.log(temp_res[individual_model.n_params-1]) # standard deviation is not on log-scale\n",
    "        temp_res = np.concatenate((temp_res, [0.001]))  # add variance of noise\n",
    "        results_to_compare.append(temp_res)\n",
    "    error_mono = compute_error_estimate(np.array(results_to_compare), \n",
    "                                        true_pop_parameters, \n",
    "                                        bi_modal=True if 'Simple' in individual_model.name else False,\n",
    "                                        relative_error=compute_relative_error)\n",
    "    # take min over multi-starts\n",
    "    error_mono.sort()\n",
    "    monolix_errors[cell_idx] = np.median(error_mono)\n",
    "    monolix_var[cell_idx] = compute_variance_estimate(np.array(results_to_compare))\n",
    "\n",
    "    # get timing    \n",
    "    if 'detailed' in model_name:\n",
    "        # likelihood were not always available, results are sorted\n",
    "        best_runs = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_complete_likelihoods.csv', \n",
    "                                index_col=0, header=0)['run']#[:10]\n",
    "    else:\n",
    "        # results are sorted\n",
    "        best_runs = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_likelihoods.csv', \n",
    "                                index_col=0, header=0)['run']#[:10]\n",
    "        \n",
    "    timing_monolix_df = pd.read_csv(f'synthetic_results_monolix/{model_name}/optimization_times/synthetic_{n_cells}_timings.csv', \n",
    "                                 header=0)\n",
    "    timing_monolix[cell_idx] = np.median(timing_monolix_df.saem) / 60 / 60  # in hours\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0655c83a0509006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(nrows=1, ncols=len(n_samples_opt_list), tight_layout=True,\n",
    "                            sharex='col', sharey='row', figsize=(15, 5))\n",
    "\n",
    "for j, n_samples_opt in enumerate(n_samples_opt_list):\n",
    "    axis[j].errorbar(np.array(test_n_cells), np.median(amortized_error[:, j], axis=1), np.sqrt(amortized_var[:, j]), alpha=0.5,\n",
    "                  linestyle='None', marker='x', capsize=3, label=f'#posterior samples: {n_samples_opt}')\n",
    "\n",
    "    axis[j].errorbar(test_n_cells, monolix_errors, np.sqrt(monolix_var), label='Monolix',\n",
    "                     linestyle='None', marker='x', capsize=3)\n",
    "\n",
    "    axis[j].set_xscale('log')\n",
    "    axis[j].set_xlabel('#cells')\n",
    "    axis[j].set_xticks(ticks=test_n_cells, labels=test_n_cells, rotation=60)\n",
    "    axis[j].legend()\n",
    "axis[0].set_ylabel('Relative mean squared error' if compute_relative_error else 'Mean squared error')\n",
    "axis[len(n_samples_opt_list)//2].set_title('Error (compared to true population parameters)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1066f86f5368ca3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'simple' in model_name:\n",
    "    average_training_time = 6.11\n",
    "elif 'detailed' in model_name:\n",
    "    average_training_time = 5.83 + 10.56\n",
    "elif 'sde' in model_name:\n",
    "    average_training_time = 2.16 + 5.12\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebc73a0c7a210981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(nrows=1, ncols=len(n_samples_opt_list), sharey='row', figsize=(15, 5))\n",
    "\n",
    "for j, n_samples_opt in enumerate(n_samples_opt_list):\n",
    "    axis[j].hlines(average_training_time, xmin=test_n_cells[0], xmax=test_n_cells[-1], color='grey', linestyle='--',\n",
    "               label=f'average training time of BayesFlow')\n",
    "    axis[j].plot(test_n_cells, np.median(time_opt[:, j], axis=-1) / 60 / 60, label=f'#posterior samples: {n_samples_opt}')\n",
    "\n",
    "    axis[j].plot(test_n_cells, timing_monolix, label=f'baseline')\n",
    "    \n",
    "    axis[j].set_xscale('log')\n",
    "    axis[j].set_yscale('log')\n",
    "    axis[j].set_title('Optimization Time For a New Data Set')\n",
    "    axis[j].legend()\n",
    "    axis[j].set_xlabel('#cells')\n",
    "    axis[j].set_xticks(ticks=test_n_cells, labels=test_n_cells, rotation=60)\n",
    "axis[0].set_ylabel('$t\\,[h]$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e29b172e334503bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9321b30a5b481393"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b5ad15c7e8dac06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
