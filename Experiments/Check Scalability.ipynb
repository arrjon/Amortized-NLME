{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import store\n",
    "\n",
    "from inference.nlme_objective import ObjectiveFunctionNLME\n",
    "from inference.ploting_routines import visualize_pesto_result\n",
    "from inference.helper_functions import compute_error_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e0c2ea767c3911"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    individual_model = ClaironSmallModel(load_best=True)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f45ab540474f210b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=individual_model.name,\n",
    "                                          param_samples=np.empty((1,1,1)),\n",
    "                                          prior_mean=individual_model.prior_mean,\n",
    "                                          prior_std=individual_model.prior_std,\n",
    "                                          covariance_format='diag',\n",
    "                                          covariates=None,\n",
    "                                          covariate_mapping=None,\n",
    "                                          prior_type=individual_model.prior_type,\n",
    "                                          prior_bounds=individual_model.prior_bounds if hasattr(individual_model, 'prior_bounds') else None,  # for uniform prior\n",
    "                                          )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9be5ec22fcad780"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load results\n",
    "filename = '../output/test_results.hdf5'\n",
    "result_optimization = store.read_result(filename)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beca9a73f15bcd43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_pesto_result(result_optimization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "734da0a5e62c5f33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_n_cells = [50, 100, 200, 500, 5000, 10000]\n",
    "n_samples_opt_list = [10, 50, 100, 1000]\n",
    "n_runs = 20 #100\n",
    "time_opt = np.zeros((len(test_n_cells), len(n_samples_opt_list), n_runs))\n",
    "rel_error = np.zeros((len(test_n_cells), len(n_samples_opt_list), n_runs))\n",
    "\n",
    "    \n",
    "for nc, n_cells in enumerate(test_n_cells):\n",
    "    for ns, n_samples in enumerate(n_samples_opt_list):\n",
    "        # load results\n",
    "        #filename = f'output/scalability/{individual_model.name}_cells_{n_cells}_samples_{n_samples}.hd5'\n",
    "        filename =  '../output/test_results.hdf5'\n",
    "        result_optimization = store.read_result(filename)\n",
    "        results_params = np.array(result_optimization.optimize_result.x)\n",
    "        assert results_params.shape[0] == n_runs\n",
    "                \n",
    "        # load true population parameters\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_cells)\n",
    "        \n",
    "        for i_r, res in enumerate(results_params):\n",
    "            # transform results\n",
    "            estimated_beta = res[:individual_model.n_params]\n",
    "            estimated_var = np.exp(-res[individual_model.n_params:individual_model.n_params*2])\n",
    "            estimated_params = np.concatenate((estimated_beta, estimated_var))\n",
    "             \n",
    "            # compute relative error of parameter estimated as minimum over multi_starts\n",
    "            rel_error[nc, ns, i_r] = compute_error_estimate(estimated_params,\n",
    "                                                            true_pop_parameters,\n",
    "                                                            bi_modal=True if 'Simple' in individual_model.name else False)\n",
    "             \n",
    "        # get duration of optimization procedure (in seconds)\n",
    "        time_opt[nc, ns, :] = np.array(result_optimization.optimize_result.time) / 60 / 60\n",
    "        break\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc145dd814e54bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read results from monolix\n",
    "compute_relative_error = False  # relative to true parameter values\n",
    "epsilon = 1e-4\n",
    "\n",
    "if 'simple' in model_name:\n",
    "    reorder_monolix_params = [0,1,2,3,4,10,5,6,7,8,9]\n",
    "elif 'detailed' in model_name:\n",
    "    reorder_monolix_params = [0,1,2,3,4,5,6,7,8,9,20,10,11,12,13,14,15,16,17,18,19]\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "monolix_errors = np.ones(len(test_n_cells)) * np.nan\n",
    "timing_monolix = np.zeros(len(test_n_cells)) * np.nan\n",
    "\n",
    "for cell_idx, n_cells in enumerate(test_n_cells):\n",
    "    if 'detailed' in model_name and n_cells == 200: continue \n",
    "    \n",
    "    estimates_monolix = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_poppars.csv',\n",
    "                                    index_col=0, header=0)\n",
    "    true_sample_parameters = pd.read_csv(f'../data/synthetic/sample_pop_parameters.csv',\n",
    "                                      index_col=0, header=0).loc[f'{n_cells}'].values\n",
    "\n",
    "    results_to_compare = []\n",
    "    for col in estimates_monolix.columns:\n",
    "        temp_res = estimates_monolix[col].values[reorder_monolix_params]\n",
    "        temp_res[5] = np.log(temp_res[5]) # standard deviation is not on log-scale\n",
    "        temp_res = np.concatenate((temp_res, [0]))  # add variance of noise\n",
    "        results_to_compare.append(temp_res)\n",
    "    error_mono = compute_error_estimate(np.array(results_to_compare), \n",
    "                                        true_sample_parameters, \n",
    "                                        bi_modal=True if 'Simple' in individual_model.name else False,\n",
    "                                        relative_error=compute_relative_error)\n",
    "    # take min over multi-starts\n",
    "    error_mono.sort()\n",
    "    monolix_errors[cell_idx] = np.min(error_mono)\n",
    "\n",
    "    # get timing    \n",
    "    if 'detailed' in model_name:\n",
    "        # likelihood were not always available, results are sorted\n",
    "        best_runs = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_complete_likelihoods.csv', \n",
    "                                index_col=0, header=0)['run'][:10]\n",
    "    else:\n",
    "        # results are sorted\n",
    "        best_runs = pd.read_csv(f'synthetic_results_monolix/{model_name}/estimates/synthetic_{n_cells}_likelihoods.csv', \n",
    "                                index_col=0, header=0)['run'][:10]\n",
    "        \n",
    "    timing_monolix_df = pd.read_csv(f'synthetic_results_monolix/{model_name}/optimization_times/synthetic_{n_cells}_timings.csv', \n",
    "                                 header=0)\n",
    "    \n",
    "    timing_monolix[cell_idx] = 0\n",
    "    for run in timing_monolix_df.values:\n",
    "        if run[-1] in best_runs.values:\n",
    "            timing_monolix[cell_idx] += run[0]\n",
    "    # average over number of runs\n",
    "    timing_monolix[cell_idx] = timing_monolix[cell_idx] / best_runs.size / 60 / 60  # in hours"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0655c83a0509006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(nrows=1, ncols=2, sharex='col', sharey='row', figsize=(15, 5))\n",
    "\n",
    "#for j, n_samples_opt in enumerate(n_samples_opt_list):\n",
    "#    axis[0].plot(test_n_cells, rel_error[:, j], label=f'#posterior samples: {n_samples_opt}')\n",
    "#    axis[1].scatter(np.array(test_n_cells) * n_samples_opt, rel_error[:, j],\n",
    "#                    label=f'#posterior samples: {n_samples_opt}')\n",
    "\n",
    "axis[0].scatter(test_n_cells, monolix_errors, label=f'baseline')\n",
    "\n",
    "axis[0].set_ylabel('$t\\,[s]$')\n",
    "axis[0].set_ylabel('Relative mean squared error')\n",
    "axis[0].set_xscale('log')\n",
    "axis[1].set_xscale('log')\n",
    "#axis[0].set_yscale('log')\n",
    "axis[0].set_title('Error (compared to true population parameters)')\n",
    "axis[1].set_title('Error (compared to true population parameters)')\n",
    "axis[0].set_xlabel('#cells')\n",
    "axis[0].set_xticks(ticks=test_n_cells, rotation=60)\n",
    "axis[1].set_xlabel('#cells $\\cdot$ #posterior samples')\n",
    "axis[0].legend()\n",
    "axis[1].legend()\n",
    "#axis[1].set_ylim(0, 8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1066f86f5368ca3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(nrows=1, ncols=2, sharey='row', figsize=(15, 5))\n",
    "\n",
    "axis[0].hlines(4.2, xmin=test_n_cells[0], xmax=test_n_cells[-1], color='grey', linestyle='--',\n",
    "               label=f'average training time of BayesFlow')\n",
    "\n",
    "#for j, n_samples_opt in enumerate(n_samples_opt_list):\n",
    "#    axis[0].plot(test_n_cells, time_opt[:, j] / 60 / 60, label=f'#posterior samples: {n_samples_opt}')\n",
    "#axis[1].scatter(np.array(test_n_cells) * n_samples_opt, time_opt[:, j] / 60 / 60,\n",
    "#                    label=f'#posterior samples: {n_samples_opt}')\n",
    "\n",
    "axis[0].scatter(test_n_cells, timing_monolix, label=f'baseline')\n",
    "\n",
    "# joint settings\n",
    "axis[0].set_ylabel('$t\\,[h]$')\n",
    "#axis[0].set_yscale('log')\n",
    "#axis[1].set_yscale('log')\n",
    "axis[0].set_xscale('log')\n",
    "axis[1].set_xscale('log')\n",
    "axis[0].set_title('Optimization Time For a New Data Set')\n",
    "axis[1].set_title('Optimization Time For a New Data Set')\n",
    "axis[0].legend()\n",
    "axis[1].legend()\n",
    "\n",
    "# other settings\n",
    "axis[0].set_xlabel('#cells')\n",
    "axis[0].set_xticks(ticks=test_n_cells, rotation=60)\n",
    "axis[1].set_xlabel('#cells $\\cdot$ #posterior samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e29b172e334503bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9321b30a5b481393"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
