{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Validate BayesFlow Posterior with MCMC\n",
    "\n",
    "In this notebook we are going to validate the posterior from BayesFlow by comparing it to posteriors generated from MCMC."
   ]
  },
  {
   "cell_type": "code",
   "id": "6eb930b7",
   "metadata": {},
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from pypesto import sample, optimize, visualize, FD, Objective, Problem, store\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from inference.likelihoods import log_likelihood_additive_noise, log_likelihood_multiplicative_noise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fef8f8c",
   "metadata": {},
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'pharmacokinetic_model'][0]\n",
    "network_idx = 0\n",
    "load_best_network = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load individual model\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f686177",
   "metadata": {
    "scrolled": false,
    "is_executing": true
   },
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator\n",
    "    model = FroehlichModelSimple(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator\n",
    "    model = FroehlichModelDetailed(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel, batch_simulator, convert_bf_to_observables\n",
    "    model = PharmacokineticModel(network_idx=network_idx, load_best=load_best_network)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# load network\n",
    "trainer = model.build_trainer('../networks/' + model.network_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "652919f1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "63fedc5f",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "# load synthetic data for specific model\n",
    "load_synthetic = True\n",
    "obs_data = model.load_data(synthetic=load_synthetic)\n",
    "\n",
    "# chose 10 random individuals/cells\n",
    "np.random.seed(42)\n",
    "individual_ids = np.random.randint(0, len(obs_data), size=10)  # obs_data can be list or numpy array\n",
    "obs_data = [obs_data[i] for i in individual_ids]\n",
    "    \n",
    "\n",
    "if load_synthetic:\n",
    "    # for these model parameters are known\n",
    "    if model_name == 'fröhlich-sde':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_sde_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    elif model_name == 'fröhlich-detailed':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_detailed_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    else:\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params.csv',\n",
    "                                     index_col=0, header=0)\n",
    "        \n",
    "    cell_param_log = cell_param_log.iloc[individual_ids]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "042eda80",
   "metadata": {},
   "source": [
    "## Examine Posterior for a Single Individual/Cell"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b686911",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "# use observations to get a first look at the posterior\n",
    "n_bayesflow_samples = 10000\n",
    "obs_data_posterior_samples = model.draw_posterior_samples(data=obs_data, n_samples=n_bayesflow_samples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(obs_data) / rows)), tight_layout=True, figsize=(10, rows*3),\n",
    "                       sharex='row', sharey='all')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(len(obs_data))):\n",
    "    axis[p_id] = model.prepare_plotting(obs_data[p_id], obs_data_posterior_samples[p_id, :100], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "    \n",
    "for _ax in axis[len(obs_data):]:\n",
    "    _ax.remove()\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1d9e9b2415a879e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0e53a41",
   "metadata": {},
   "source": [
    "## Prepare MCMC Posterior\n",
    "\n",
    "First we need to define the likelihood and the prior we want to use for MCMC.\n",
    "Note: BayesFlow works without specifying a likelihood since it is a simulation-based method."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def log_prior_density_normal(log_param: np.ndarray, \n",
    "                             mean: np.ndarray,\n",
    "                             inv_cov_matrix: np.ndarray, \n",
    "                             prior_constant: float) -> float:\n",
    "    # compute the log normal density of the prior\n",
    "    dif = log_param - mean\n",
    "    return prior_constant - 0.5 * dif.dot(inv_cov_matrix).dot(dif.T) # - log_param.sum()  sum cancels with log-transformation\n",
    "\n",
    "@njit\n",
    "def log_prior_density_uniform(log_param: np.ndarray, \n",
    "                              prior_bounds: np.ndarray) -> float:\n",
    "    # check if parameters are within bounds\n",
    "    if np.any(log_param < prior_bounds[:, 0]) or np.any(log_param > prior_bounds[:, 1]):\n",
    "        return -np.inf\n",
    "    # compute the log uniform density of the prior\n",
    "    constant = -np.log(np.diff(prior_bounds).prod())\n",
    "    return constant\n",
    "\n",
    "if model.prior_type == 'normal':\n",
    "    _, logabsdet = np.linalg.slogdet(model.prior_cov)\n",
    "    log_prior_constant = -0.5 * model.n_params * np.log(2 * np.pi) -0.5* logabsdet\n",
    "    inv_cov = np.linalg.inv(model.prior_cov)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1d38505010595b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "individual_id = 0  # patient 5 for pharma, fro-detailed 0\n",
    "obs_data_indv = obs_data[individual_id]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "797e14cfcb6d92a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare simulator accordingly to the model\n",
    "if 'Froehlich' in model.name :\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    simulator = partial(batch_simulator, \n",
    "                                n_obs=180,\n",
    "                                with_noise=False)\n",
    "    noise_model = 'multiplicative'  # additive on log-scale \n",
    "    index_sigma = -1  # index of sigma in parameter vector\n",
    "    obs_data_indv_prepared = obs_data_indv.flatten()  # just one measurement per time point, already on log-scale\n",
    "elif 'Pharma' in model.name:\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    obs_data_indv_prepared, t_measurement, doses_time_points, dos, wt = convert_bf_to_observables(obs_data_indv)\n",
    "    simulator = partial(batch_simulator,\n",
    "                       t_measurement=t_measurement,\n",
    "                       t_doses=doses_time_points,\n",
    "                       wt=wt,\n",
    "                       dos=dos,\n",
    "                       with_noise=False,\n",
    "                       convert_to_bf_batch=False)\n",
    "    noise_model = 'multiplicative'  # additive on log-scale\n",
    "    index_sigma = [-3, -2]  # index of sigmas in parameter vector\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "assert simulator(model.prior_mean).shape == obs_data_indv_prepared.shape, 'simulator output shape does not match data shape' "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cb680995588dcdd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def neg_log_prop_posterior(log_param: np.ndarray):\n",
    "    y_sim = simulator(log_param)  \n",
    "    if noise_model == 'multiplicative':\n",
    "        llh = log_likelihood_multiplicative_noise(log_measurements=obs_data_indv_prepared,\n",
    "                                                  log_simulations=y_sim,\n",
    "                                                  sigmas=np.exp(log_param[index_sigma]))\n",
    "    else:  # noise_model == 'proportional':\n",
    "        prop_sigma =  np.exp(log_param[index_sigma[0]]) + obs_data_indv_prepared * np.exp(log_param[index_sigma[1]])\n",
    "        llh = log_likelihood_additive_noise(measurements=obs_data_indv_prepared,\n",
    "                                            simulations=y_sim,\n",
    "                                            sigmas=prop_sigma)\n",
    "        \n",
    "    if model.prior_type == 'normal':\n",
    "        log_prior = log_prior_density_normal(log_param=log_param, mean=model.prior_mean, inv_cov_matrix=inv_cov,\n",
    "                                             prior_constant=log_prior_constant)\n",
    "    else:\n",
    "        log_prior = log_prior_density_uniform(log_param=log_param, prior_bounds=model.prior_bounds)\n",
    "    return -(llh + log_prior)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8c448a545f61e5d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run MCMC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "485d32ab9e6c31f9"
  },
  {
   "cell_type": "code",
   "id": "51fce3ef",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "from pypesto.objective import NegLogParameterPriors\n",
    "\n",
    "n_chains = 10\n",
    "n_samples = 1e5\n",
    "filename = f'sampling_results/mcmc_{model.name}_individual_{individual_id}_synthetic.hdf5'\n",
    "\n",
    "# create objective function\n",
    "pesto_objective = FD(obj=Objective(fun=neg_log_prop_posterior),\n",
    "                     x_names=model.log_param_names)\n",
    "\n",
    "lb = model.prior_mean - 5 * model.prior_std\n",
    "ub = model.prior_mean + 5 * model.prior_std\n",
    "\n",
    "x_priors_defs = NegLogParameterPriors(\n",
    "    [{'index': i, 'density_fun': lambda x: -stats.norm.logpdf(x, loc=model.prior_mean[i], scale=np.sqrt(model.prior_cov.diagonal()[i]))}\n",
    "     for i in range(model.n_params)])\n",
    "\n",
    "# create pypesto problem\n",
    "pesto_problem = Problem(objective=pesto_objective,\n",
    "                        lb=lb, ub=ub,\n",
    "                        x_names=model.log_param_names,\n",
    "                        x_priors_defs=x_priors_defs,\n",
    "                        x_scales=['log']*len(model.log_param_names))\n",
    "pesto_problem.print_parameter_summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# check if file exists, if not run optimization\n",
    "if os.path.exists(filename):\n",
    "    result = store.read_result(filename)\n",
    "else:\n",
    "    result = optimize.minimize(problem=pesto_problem,\n",
    "                           optimizer=optimize.ScipyOptimizer(),\n",
    "                           n_starts=n_chains)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f53963b22c3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52af894b",
   "metadata": {},
   "source": [
    "visualize.parameters(result)\n",
    "visualize.waterfall(result)\n",
    "print(neg_log_prop_posterior(result.optimize_result.x[0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2, 3, tight_layout=True, figsize=(10, 5),\n",
    "                       sharex='row', sharey='all')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(axis.size)):\n",
    "    axis[p_id] = model.prepare_plotting(obs_data_indv, result.optimize_result.x[p_id], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "axis[0].set_title(f'best {axis.size} fits')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1034daf9bb56ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def llh(log_param: np.ndarray):\n",
    "    y_sim = simulator(log_param)  \n",
    "    return log_likelihood_multiplicative_noise(log_measurements=obs_data_indv_prepared,\n",
    "                                                  log_simulations=y_sim,\n",
    "                                                  sigmas=np.exp(log_param[index_sigma]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b1a0126e5ac09",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# rejection sampling\n",
    "n_samples = 1000\n",
    "accepted_samples = []\n",
    "max_iter = 100000\n",
    "i = 0\n",
    "log_M = llh(result.optimize_result.x[0]) #+ 100\n",
    "\n",
    "while len(accepted_samples) < n_samples:\n",
    "    i += 1\n",
    "    #sample = model.draw_posterior_samples(data=obs_data_indv, n_samples=1).flatten()\n",
    "    samples = model.prior(1)['prior_draws'].flatten()\n",
    "    log_prop = llh(samples)  # posterior / prior\n",
    "    \n",
    "    log_uni = np.log(np.random.uniform(0, 1))\n",
    "    if log_uni <= log_prop - log_M:\n",
    "        accepted_samples.append(samples)\n",
    "        print(f'accepted {len(accepted_samples)/i*100} % of samples')   \n",
    "    \n",
    "    if i > max_iter:\n",
    "        print('max iterations reached')\n",
    "        break\n",
    "print(f'Final: accepted {len(accepted_samples)/i} % of samples')  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a75453ae64de22c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sampler = sample.AdaptiveParallelTemperingSampler(\n",
    "    internal_sampler=sample.AdaptiveMetropolisSampler(), n_chains=n_chains,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3d56d64cd8e29ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "sampler = sample.AdaptiveMetropolisSampler()\n",
    "x0 = list(result.optimize_result.x)[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b21883ea477d5b5"
  },
  {
   "cell_type": "code",
   "source": [
    "x0 = list(result.optimize_result.x)[:n_chains]\n",
    "if model_name == 'fröhlich-simple':\n",
    "    x1 = x0[0].copy()\n",
    "    x2 = x0[0].copy()\n",
    "    \n",
    "    x2[0] = x1[1]\n",
    "    x2[1] = x1[0]\n",
    "    \n",
    "    x0 = [x1, x2] * (n_chains //2 )\n",
    "    \n",
    "    print(pesto_problem.objective(x1)-pesto_problem.objective(x2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4a36b3b529df48b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# sample uniform from prior\n",
    "#x0 = list(model.prior(n_chains)['prior_draws'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2dc1f5fc87ca3cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65df331f",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "if not os.path.exists(filename):\n",
    "    result = sample.sample(\n",
    "            pesto_problem, n_samples=n_samples, sampler=sampler,\n",
    "            filename=filename,\n",
    "            x0=x0,\n",
    "            result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "874098e0",
   "metadata": {},
   "source": [
    "geweke_test = sample.geweke_test(result)\n",
    "auto_correlation = sample.auto_correlation(result)\n",
    "effective_sample_size = sample.effective_sample_size(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6a156ae",
   "metadata": {},
   "source": [
    "visualize.sampling_parameter_traces(result, use_problem_bounds=True);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05de1ba7",
   "metadata": {},
   "source": [
    "visualize.sampling_fval_traces(result);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(filename):\n",
    "    store.write_result(\n",
    "            result=result,\n",
    "            filename=filename,\n",
    "            problem=True,\n",
    "            optimize=True,\n",
    "            sample=True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1098df28b1747cc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "452e9adf",
   "metadata": {},
   "source": [
    "pesto_samples = result.sample_result.trace_x[0]\n",
    "print(pesto_samples.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "964c8eb1",
   "metadata": {},
   "source": [
    "burn_in = result.sample_result.burn_in\n",
    "pesto_samples_adjusted = pesto_samples[burn_in:, :]\n",
    "print(pesto_samples_adjusted.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd739561",
   "metadata": {},
   "source": [
    "MAP_idx = np.argmin(result.sample_result.trace_neglogpost[0,burn_in:])\n",
    "MAP = result.sample_result.trace_x[0,burn_in+MAP_idx,:]\n",
    "print('MAP (optimizing)', neg_log_prop_posterior(result.optimize_result.x[0]))\n",
    "print('MAP (sampling)', neg_log_prop_posterior(MAP))\n",
    "\n",
    "if model_name == 'fröhlich-simple':\n",
    "    # it is known, that this model's posterior should have two modes (in the first two parameters)\n",
    "    other_MAP = MAP.copy()\n",
    "    other_MAP[[0,1]] = other_MAP[[1,0]]\n",
    "    print('MAP-2 (sampling)', neg_log_prop_posterior(other_MAP))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(10, 5))\n",
    "\n",
    "ax = model.prepare_plotting(obs_data_indv, MAP, ax)\n",
    "_, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(labels, ncol=4, loc='lower center', bbox_to_anchor=(0.5, 1))\n",
    "\n",
    "ax.set_title(f'MAP fit')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "973d460a21dc7c62",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare BayesFlow and MCMC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca40267bf1ff9280"
  },
  {
   "cell_type": "code",
   "source": [
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,9)}) #\n",
    "colors = ['#1f78b4', '#a6cee3', '#b2df8a','#33a02c','#fb9a99']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecf31c16e4f9a127",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# reduce to same number of samples\n",
    "n_samples = min(obs_data_posterior_samples[individual_id].shape[0], pesto_samples_adjusted.shape[0])\n",
    "bayes_flow_samples = obs_data_posterior_samples[individual_id]\n",
    "mcmc_smaples = pesto_samples_adjusted#[np.random.choice(range(pesto_samples_adjusted.shape[0]),\n",
    "                                      #                 n_samples, replace=False)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9471049f70aa82b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(model.n_params/2)), tight_layout=True, figsize=(12,6))\n",
    "axis = ax.flatten()\n",
    "bins = 20\n",
    "binwidth = 0.5\n",
    "if model.name == 'DetailedFroehlichModel':\n",
    "    xlim = [[0,10], [0,5], [0,5], [0,2*1e+6], [0,5], [0,10], [0,2], [0,0.005], [0.25,0.35], [5,10], [0,0.1]]\n",
    "else:\n",
    "    xlim = [[-0.1,0.5], [-0.1,0.5], [300,600], [0, 2], [5,10], [0,0.1]]\n",
    "    \n",
    "for i, name in enumerate(model.param_names):\n",
    "    axis[i].set_title(name) #'log '+name)\n",
    "    axis[i].hist(np.exp(bayes_flow_samples[:, i]), \n",
    "                 bins=np.linspace(xlim[i][0], xlim[i][1], bins), #bins,\n",
    "                 density=True, label='BayesFlow', color='#d7191c') #\n",
    "    ylim = axis[i].get_ylim()\n",
    "    #xlim = axis[i].get_xlim()\n",
    "\n",
    "    axis[i].hist(np.exp(mcmc_smaples[:, i]), \n",
    "                 bins=np.linspace(xlim[i][0], xlim[i][1], bins),\n",
    "                 #bins=np.arange(min(np.exp(mcmc_smaples[:, i])), max(np.exp(mcmc_smaples[:, i])) + binwidth, binwidth),\n",
    "                 density=True, label='MCMC', alpha=0.6, color='#2c7bb6')\n",
    "    axis[i].set_ylim(ylim)\n",
    "    \n",
    "    \n",
    "    if model.prior_type == 'normal':\n",
    "        #x_prior = np.linspace(model.prior_mean[i] - 0.1*model.prior_std[i], \n",
    "         #           model.prior_mean[i] + 0.1*model.prior_std[i], 1000)\n",
    "        #prior_density = stats.norm.pdf(x_prior, model.prior_mean[i], model.prior_std[i])\n",
    "        #prior_handle, = axis[i].plot(np.exp(x_prior), prior_density, color='orange', label='Prior',\n",
    "        #                             linestyle='-')\n",
    "        # set axis to lim without prior \n",
    "        pass #axis[i].set_xlim(xlim)\n",
    "    elif model.prior_type == 'uniform':\n",
    "        axis[i].set_xlim(np.exp(model.prior_bounds[i]))\n",
    "     \n",
    "    true_value = axis[i].axvline(np.exp(cell_param_log.values[individual_id][i]), linestyle='--', color='black',\n",
    "                                 label='true parameter') \n",
    "    \n",
    "    true_param = np.exp(cell_param_log.values[individual_id][i])\n",
    "    #xlim = true_param -0.5*true_param, true_param+0.5*true_param\n",
    "    #xlim = -1, np.exp(cell_param_log.values[individual_id][i])+1\n",
    "    axis[i].set_xlim(xlim[i])\n",
    "    \n",
    "bf_handle = mpatches.Patch(color='#d7191c', label='BayesFlow')\n",
    "mcmc_handle = mpatches.Patch(color='#2c7bb6', label='MCMC')\n",
    "lgd = fig.legend(handles=[bf_handle, mcmc_handle, true_value], ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "for _ax in axis[model.n_params:]:\n",
    "    _ax.remove()\n",
    "#plt.savefig(f'../plots/posterior_validation_{model.name}_individual_{individual_id}_synthetic.pdf', format='pdf',\n",
    "#            bbox_inches='tight', bbox_extra_artists=(lgd,))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd6aded093c4140a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "  fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(model.n_params/2)), tight_layout=True, figsize=(16,12))\n",
    "axis = ax.flatten()\n",
    "for i, name in enumerate(model.param_names):\n",
    "    axis[i].set_title(name)\n",
    "    axis[i].hist(np.exp(bayes_flow_samples[:, i]), bins=bins, density=True, label='BayesFlow', color='blue')\n",
    "\n",
    "    axis[i].hist(np.exp(mcmc_smaples[:, i]), bins=bins, density=True, label='MCMC', alpha=0.6, color='red')\n",
    "    axis[i].legend()\n",
    "\n",
    "for _ax in axis[model.n_params:]:\n",
    "    _ax.remove()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60dd1280a830312"
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_plotting(data: np.ndarray, params: np.ndarray, ax: plt.Axes = None,\n",
    "                         with_noise: bool = False) -> plt.Axes:\n",
    "        # simulate data\n",
    "        sim_data = batch_simulator(param_batch=params, n_obs=180, with_noise=with_noise)\n",
    "        t_measurement = np.linspace(start=1 / 6, stop=30, num=180, endpoint=True)\n",
    "\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1, figsize=(10, 5), tight_layout=True)\n",
    "\n",
    "        if len(params.shape) == 1:  # so not (batch_size, params)\n",
    "            # just a single parameter set\n",
    "            # plot simulated data\n",
    "            ax.plot(t_measurement, sim_data, 'b', label='simulated cell')\n",
    "        else:\n",
    "            # remove channel dimension of bayesflow\n",
    "            sim_data = sim_data[:, :, 0]\n",
    "            # calculate median and quantiles\n",
    "            y_median = np.median(sim_data, axis=0)\n",
    "            y_quantiles = np.percentile(sim_data, [2.5, 97.5], axis=0)\n",
    "\n",
    "            # plot simulated data\n",
    "            ax.fill_between(t_measurement, y_quantiles[0], y_quantiles[1],\n",
    "                            alpha=0.2, color='b', label='$95\\\\%$ quantiles')\n",
    "            ax.plot(t_measurement, y_median, 'b', label='median')\n",
    "\n",
    "        # plot observed data\n",
    "        ax.scatter(t_measurement, data, color='b', label='measurements')\n",
    "        ax.set_xlabel('$t\\, [h]$')\n",
    "        ax.set_ylabel('log fluorescence intensity [a.u.]')\n",
    "        return ax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6cc05966bac0259",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sim_data = batch_simulator(param_batch=obs_data_posterior_samples[individual_id], n_obs=180, with_noise=True)\n",
    "sim_data_MCMC = batch_simulator(param_batch=mcmc_smaples, n_obs=180, with_noise=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8429482e5f025e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sim_data = np.median(sim_data, axis=0)\n",
    "sim_data.sort()\n",
    "sim_data_MCMC = np.median(sim_data_MCMC, axis=0)\n",
    "sim_data_MCMC.sort()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24575ddb8af23cd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4f16e0cd84e4250"
  },
  {
   "cell_type": "code",
   "source": [
    "sim_data_MCMC.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b9a22557f2021",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "obs_data_indv_repeat = np.repeat(obs_data_indv.flatten(), n_bayesflow_samples)\n",
    "obs_data_indv_repeat.sort()\n",
    "\n",
    "obs_data_indv_repeat_2 = np.repeat(obs_data_indv.flatten(), mcmc_smaples.shape[0])\n",
    "obs_data_indv_repeat_2.sort()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a812e4ceebce5d3"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Q-Q plot\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, figsize=(12, 6), sharey=True)\n",
    "ax[0].scatter(sim_data, obs_data_indv, marker='o', color='blue', label='SBI')\n",
    "ax[1].scatter(sim_data_MCMC, obs_data_indv, marker='o', color='orange', label='MCMC')\n",
    "\n",
    "#plt.scatter(sim_a3, real_data_a3, color='green', edgecolors='black', alpha=0.6)\n",
    "ax[0].plot(obs_data_indv, obs_data_indv, color='red', linestyle='--')\n",
    "ax[1].plot(obs_data_indv, obs_data_indv, color='red', linestyle='--')\n",
    "#ax[0].set_title('Q-Q Plot - A2')\n",
    "ax[0].set_ylabel('Synthetic Data')\n",
    "ax[0].set_xlabel('Simulations from Posterior')\n",
    "ax[1].set_xlabel('Simulations from Posterior')\n",
    "\n",
    "for a in ax:\n",
    "    a.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fe4f9b5eb6793f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(16, 6),\n",
    "                       sharex='row', sharey='all')\n",
    "    \n",
    "ax[0] = prepare_plotting(obs_data_indv, obs_data_posterior_samples[individual_id], ax[0], with_noise=False)\n",
    "ax[1] = prepare_plotting(obs_data_indv, mcmc_smaples, ax[1], with_noise=True)\n",
    "_, labels = ax[0].get_legend_handles_labels()\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.01))\n",
    "ax[0].set_title('BayesFlow Posterior Predictive')\n",
    "ax[1].set_title('MCMC Posterior Predictive')\n",
    "#plt.savefig(f'../plots/mcmc/posterior_simulation_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "#plt.savefig(f'../plots/posterior_simulation_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb99718e76cd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# estimate noise\n",
    "if 'Froehlich' in model.name:\n",
    "    var_bayes = 1/(obs_data_indv.shape[0]-1)*np.sum((np.median(batch_simulator(obs_data_posterior_samples[individual_id], with_noise=False), axis=0).flatten()-obs_data_indv.T)**2)\n",
    "    print(var_bayes, np.exp(np.median(obs_data_posterior_samples[individual_id, :, -1]))**2)\n",
    "    \n",
    "    var_bayes = 1/(obs_data_indv.shape[0]-1)*np.sum((np.median(batch_simulator(mcmc_smaples, with_noise=False), axis=0).flatten()-obs_data_indv.T)**2)\n",
    "    print(var_bayes, np.exp(np.median(mcmc_smaples[:, -1]))**2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51eaf4fbbc611a20",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "To see visually if samples differ, we map the posterior samples in a two-dimensional space using a UMAP. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324d158dc82ee949"
  },
  {
   "cell_type": "code",
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34ad569f8d46d2f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "prior_samples = model.prior(n_samples)['prior_draws']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc51e08f373c67c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# normalize samples\n",
    "all_samples = np.concatenate((bayes_flow_samples, mcmc_smaples, prior_samples), axis=0)\n",
    "scaled_samples = StandardScaler().fit_transform(all_samples)\n",
    "\n",
    "# create umap\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1,   # for reproducibility \n",
    "                    densmap=True,  # preserve local density\n",
    "                    ) \n",
    "umap_embedding = reducer.fit_transform(scaled_samples)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b5cb6f0d29610cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig = plt.figure(tight_layout=True, figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    umap_embedding[bayes_flow_samples.shape[0]+mcmc_smaples.shape[0]:, 0],\n",
    "    umap_embedding[bayes_flow_samples.shape[0]+mcmc_smaples.shape[0]:, 1], \n",
    "    label='Prior', alpha=0.3, color='orange')\n",
    "plt.scatter(\n",
    "    umap_embedding[:bayes_flow_samples.shape[0], 0],\n",
    "    umap_embedding[:bayes_flow_samples.shape[0], 1], \n",
    "    label='BayesFlow', alpha=1, color='blue')\n",
    "plt.scatter(\n",
    "    umap_embedding[bayes_flow_samples.shape[0]:bayes_flow_samples.shape[0]+mcmc_smaples.shape[0], 0],\n",
    "    umap_embedding[bayes_flow_samples.shape[0]:bayes_flow_samples.shape[0]+mcmc_smaples.shape[0], 1], \n",
    "    label='MCMC', alpha=0.3, color='red')\n",
    "plt.legend()\n",
    "plt.title('Umap Based Representation of Posterior Distributions')\n",
    "\n",
    "#plt.savefig(f'../plots/mcmc/posterior_umap_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eabb7eef19a8630",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# normalize samples without sigma\n",
    "all_samples = np.concatenate((bayes_flow_samples[:, :-2], mcmc_smaples[:, :-2], prior_samples[:, :-2]), axis=0)\n",
    "scaled_samples = StandardScaler().fit_transform(all_samples)\n",
    "\n",
    "# create umap\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1,  # for reproducibility \n",
    "                    densmap=True,  # preserve local density\n",
    "                    )\n",
    "umap_embedding = reducer.fit_transform(scaled_samples)\n",
    "\n",
    "fig = plt.figure(tight_layout=True, figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    umap_embedding[bayes_flow_samples.shape[0]+mcmc_smaples.shape[0]:, 0],\n",
    "    umap_embedding[bayes_flow_samples.shape[0]+mcmc_smaples.shape[0]:, 1], \n",
    "    label='Prior', alpha=0.3, color='orange')\n",
    "plt.scatter(\n",
    "    umap_embedding[:bayes_flow_samples.shape[0], 0],\n",
    "    umap_embedding[:bayes_flow_samples.shape[0], 1], \n",
    "    label='BayesFlow', alpha=1, color='blue')\n",
    "plt.scatter(\n",
    "    umap_embedding[bayes_flow_samples.shape[0]:bayes_flow_samples.shape[0]+mcmc_smaples.shape[0], 0],\n",
    "    umap_embedding[bayes_flow_samples.shape[0]:bayes_flow_samples.shape[0]+mcmc_smaples.shape[0], 1], \n",
    "    label='MCMC', alpha=0.3, color='red')\n",
    "plt.legend()\n",
    "plt.title('Umap Based Representation of Posterior Distributions')\n",
    "\n",
    "plt.savefig(f'../plots/mcmc/posterior_umap_reduced_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ff260f2d109f794",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8f65f2ee3a23f6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
