{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Validate BayesFlow Posterior with MCMC\n",
    "\n",
    "In this notebook we are going to validate the posterior from BayesFlow by comparing it to posteriors generated from MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from pypesto import sample, optimize, visualize, FD, Objective, Problem, store\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'pharmacokinetic_model', 'clairon_small_model'][-1]\n",
    "network_idx = 0\n",
    "load_best_network = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load individual model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f686177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator\n",
    "    model = FroehlichModelSimple(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator\n",
    "    model = FroehlichModelDetailed(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel, batch_simulator, convert_bf_to_observables\n",
    "    model = PharmacokineticModel(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel, batch_simulator, convert_bf_to_observables\n",
    "    prior_type = ['normal', 'uniform'][0]\n",
    "    model = ClaironSmallModel(network_idx=network_idx, load_best=load_best_network, prior_type=prior_type)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# load network\n",
    "trainer = model.build_trainer('../networks/' + model.network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652919f1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fedc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load synthetic data for specific model\n",
    "load_synthetic = False\n",
    "obs_data = model.load_data(synthetic=load_synthetic)\n",
    "\n",
    "# chose 10 random individuals/cells\n",
    "np.random.seed(42)\n",
    "individual_ids = np.random.randint(0, len(obs_data), size=10)  # obs_data can be list or numpy array\n",
    "obs_data = [obs_data[i] for i in individual_ids]\n",
    "    \n",
    "\n",
    "if load_synthetic:\n",
    "    # for these model parameters are known\n",
    "    if model_name == 'fröhlich-sde':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_sde_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    elif model_name == 'fröhlich-detailed':\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params_detailed_model.csv',\n",
    "                                     index_col=0, header=0)\n",
    "    else:\n",
    "        cell_param_log = pd.read_csv(f'../data/synthetic/synthetic_individual_cell_params.csv',\n",
    "                                     index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042eda80",
   "metadata": {},
   "source": [
    "## Examine Posterior for a Single Individual/Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b686911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use observations to get a first look at the posterior\n",
    "n_bayesflow_samples = 1000\n",
    "obs_data_posterior_samples = model.draw_posterior_samples(data=obs_data, n_samples=n_bayesflow_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = 4\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(obs_data) / rows)), tight_layout=True, figsize=(10, rows*3),\n",
    "                       sharex='row', sharey='all')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(len(obs_data))):\n",
    "    axis[p_id] = model.prepare_plotting(obs_data[p_id], obs_data_posterior_samples[p_id, :100], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "    \n",
    "for _ax in axis[len(obs_data):]:\n",
    "    _ax.remove()\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9e9b2415a879e8"
  },
  {
   "cell_type": "markdown",
   "id": "b0e53a41",
   "metadata": {},
   "source": [
    "## Prepare MCMC Posterior\n",
    "\n",
    "First we need to define the likelihood and the prior we want to use for MCMC.\n",
    "Note: BayesFlow works without specifying a likelihood since it is a simulation-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@njit\n",
    "def log_likelihood_multiplicative_noise(log_measurements: np.ndarray, \n",
    "                                        log_simulations: np.ndarray, \n",
    "                                        sigmas: Union[float, np.ndarray]) -> float:\n",
    "    # compute the log-likelihood for multiplicative normal noise (log-normal distribution)\n",
    "    dif_sum = np.sum(((log_measurements - log_simulations) / sigmas)**2)\n",
    "    if isinstance(sigmas, float):\n",
    "        # needed for njit, cannot sum over float\n",
    "        log_det_sigma = np.log(sigmas**2)\n",
    "    else:\n",
    "        log_det_sigma = np.sum(np.log(sigmas**2))\n",
    "    # log_measurement.size = n_measurements + n_observables, len(log_measurement) = n_measurements\n",
    "    llh = (-0.5 * log_measurements.size * np.log(2 * np.pi) - 0.5 * len(log_measurements) * log_det_sigma \n",
    "           - log_measurements.sum() - 0.5 * dif_sum)\n",
    "    return llh\n",
    "\n",
    "\n",
    "@njit\n",
    "def log_likelihood_additive_noise(measurements: np.ndarray, \n",
    "                                  simulations: np.ndarray, \n",
    "                                  sigmas: Union[float, np.ndarray]) -> float:\n",
    "    # compute the log-likelihood for additive normal noise, proportionality might be captured in sigma already\n",
    "    # normal distribution\n",
    "    dif_sum = np.sum(((measurements - simulations) / sigmas)**2)\n",
    "    log_det_sigma = np.sum(np.log(sigmas**2))\n",
    "    llh = -0.5 * measurements.size * np.log(2 * np.pi) - 0.5*len(measurements)*log_det_sigma  - 0.5 * dif_sum\n",
    "    return llh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd59b8d7c4fbd1d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@njit\n",
    "def log_prior_density_normal(log_param: np.ndarray, \n",
    "                             mean: np.ndarray,\n",
    "                             inv_cov_matrix: np.ndarray, \n",
    "                             prior_constant: float) -> float:\n",
    "    # compute the log normal density of the prior\n",
    "    dif = log_param - mean\n",
    "    return prior_constant - 0.5 * dif.dot(inv_cov_matrix).dot(dif.T) - log_param.sum()\n",
    "\n",
    "\n",
    "@njit\n",
    "def log_prior_density_uniform(log_param: np.ndarray, \n",
    "                              prior_constant: float) -> float:\n",
    "    # compute the log uniform density of the prior\n",
    "    return prior_constant - log_param.sum()\n",
    "\n",
    "\n",
    "if model.prior_type == 'normal':\n",
    "    log_prior_constant = -0.5 * model.n_params * np.log(2 * np.pi) -0.5* np.linalg.slogdet(model.prior_cov).logabsdet\n",
    "    inv_cov = np.linalg.inv(model.prior_cov)\n",
    "if model.prior_type == 'uniform':\n",
    "    log_prior_constant =  -np.log(np.diff(model.prior_bounds).prod())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d38505010595b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "individual_id = 1  # patient 5 for pharma, fro-detailed 0\n",
    "obs_data_indv = obs_data[individual_id]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797e14cfcb6d92a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare simulator accordingly to the model\n",
    "if 'Froehlich' in model.name :\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    simulator = partial(batch_simulator, \n",
    "                                n_obs=180,\n",
    "                                with_noise=False)\n",
    "    noise_model = 'multiplicative'  # additive on log-scale \n",
    "    index_sigma = -1  # index of sigma in parameter vector\n",
    "    obs_data_indv_prepared = obs_data_indv.flatten()  # just one measurement per time point, already on log-scale\n",
    "elif 'Pharma' in model.name:\n",
    "    # prepare simulator, data should be on log-scale\n",
    "    obs_data_indv_prepared, t_measurement, doses_time_points, dos, wt = convert_bf_to_observables(obs_data_indv)\n",
    "    simulator = partial(batch_simulator,\n",
    "                       t_measurement=t_measurement,\n",
    "                       t_doses=doses_time_points,\n",
    "                       wt=wt,\n",
    "                       dos=dos,\n",
    "                       with_noise=False,\n",
    "                       convert_to_bf_batch=False)\n",
    "    noise_model = 'multiplicative'  # additive on log-scale\n",
    "    index_sigma = [-3, -2]  # index of sigmas in parameter vector\n",
    "elif 'Clairon' in model.name:\n",
    "    # prepare simulator, data should be on linear scale\n",
    "    obs_data_indv_prepared, t_measurements, dose_amount, doses_time_points = convert_bf_to_observables(obs_data_indv)\n",
    "    simulator = partial(batch_simulator,\n",
    "                        t_measurements=t_measurements,\n",
    "                        t_doses=doses_time_points,\n",
    "                        with_noise=False,\n",
    "                        convert_to_bf_batch=False)    \n",
    "    noise_model = 'proportional'   # additive on linear scale\n",
    "    index_sigma = [-2, -1]  # index of a, b in parameter vector of y+(a+by)*e\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "assert simulator(model.prior_mean).shape == obs_data_indv_prepared.shape, 'simulator output shape does not match data shape' "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb680995588dcdd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neg_log_prop_posterior(log_param: np.ndarray):\n",
    "    y_sim = simulator(log_param)  \n",
    "    if noise_model == 'multiplicative':\n",
    "        llh = log_likelihood_multiplicative_noise(log_measurements=obs_data_indv_prepared,\n",
    "                                                  log_simulations=y_sim,\n",
    "                                                  sigmas=np.exp(log_param[index_sigma]))\n",
    "    else:  # noise_model == 'proportional':\n",
    "        prop_sigma =  np.exp(log_param[index_sigma[0]]) + obs_data_indv_prepared * np.exp(log_param[index_sigma[1]])\n",
    "        llh = log_likelihood_additive_noise(measurements=obs_data_indv_prepared,\n",
    "                                            simulations=y_sim,\n",
    "                                            sigmas=prop_sigma)\n",
    "        \n",
    "    if model.prior_type == 'normal':\n",
    "        log_prior = log_prior_density_normal(log_param=log_param, mean=model.prior_mean, inv_cov_matrix=inv_cov,\n",
    "                                             prior_constant=log_prior_constant)\n",
    "    else:\n",
    "        log_prior = log_prior_density_uniform(log_param=log_param, prior_constant=log_prior_constant)\n",
    "    return -(llh + log_prior)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c448a545f61e5d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg_log_prop_posterior(model.prior_mean)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4481fa0b2de27f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run MCMC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "485d32ab9e6c31f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fce3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 10\n",
    "n_samples = 1e6\n",
    "filename = f'sampling_results/mcmc_{model.name}_individual_{individual_id}.hdf5'\n",
    "\n",
    "# create objective function\n",
    "pesto_objective = FD(obj=Objective(fun=neg_log_prop_posterior),\n",
    "                     x_names=model.log_param_names)\n",
    "\n",
    "lb = model.prior_mean - 5 * model.prior_std\n",
    "ub = model.prior_mean + 5 * model.prior_std\n",
    "\n",
    "# create pypesto problem\n",
    "pesto_problem = Problem(objective=pesto_objective,\n",
    "                        lb=lb, ub=ub,\n",
    "                        x_names=model.log_param_names,\n",
    "                        x_scales=['log']*len(model.log_param_names))\n",
    "pesto_problem.print_parameter_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if file exists, if not run optimization\n",
    "if os.path.exists(filename):\n",
    "    result = store.read_result(filename)\n",
    "else:\n",
    "    result = optimize.minimize(problem=pesto_problem,\n",
    "                           optimizer=optimize.ScipyOptimizer(),\n",
    "                           n_starts=n_chains*10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f53963b22c3cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parameters(result)\n",
    "visualize.waterfall(result)\n",
    "print(neg_log_prop_posterior(result.optimize_result.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, tight_layout=True, figsize=(10, 5),\n",
    "                       sharex='row', sharey='all')\n",
    "axis = ax.flatten()\n",
    "    \n",
    "for p_id in tqdm(range(axis.size)):\n",
    "    axis[p_id] = model.prepare_plotting(obs_data_indv, result.optimize_result.x[p_id], axis[p_id])\n",
    "    _, labels = axis[p_id].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "axis[0].set_title(f'best {axis.size} fits')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1034daf9bb56ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampler = sample.AdaptiveParallelTemperingSampler(\n",
    "    internal_sampler=sample.AdaptiveMetropolisSampler(), n_chains=n_chains,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3d56d64cd8e29ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df331f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(filename):\n",
    "    result = sample.sample(\n",
    "            pesto_problem, n_samples=n_samples, sampler=sampler,\n",
    "            x0=list(result.optimize_result.x)[:n_chains],\n",
    "            result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geweke_test = sample.geweke_test(result)\n",
    "print('geweke_test', geweke_test)\n",
    "\n",
    "auto_correlation = sample.auto_correlation(result)\n",
    "print('auto_correlation', auto_correlation)\n",
    "\n",
    "effective_sample_size = sample.effective_sample_size(result)\n",
    "print('effective_sample_size', effective_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a156ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.sampling_parameter_traces(result, use_problem_bounds=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.sampling_fval_traces(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(filename):\n",
    "    store.write_result(\n",
    "            result=result,\n",
    "            filename=filename,\n",
    "            problem=True,\n",
    "            optimize=True,\n",
    "            sample=True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1098df28b1747cc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesto_samples = result.sample_result.trace_x[0]\n",
    "print(pesto_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = result.sample_result.burn_in\n",
    "pesto_samples_adjusted = pesto_samples[burn_in:, :]\n",
    "thinned_samples = pesto_samples_adjusted[::int(auto_correlation), :]\n",
    "print(pesto_samples_adjusted.shape)\n",
    "print(thinned_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd739561",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_idx = np.argmin(result.sample_result.trace_neglogpost[0,burn_in:])\n",
    "MAP = result.sample_result.trace_x[0,burn_in+MAP_idx,:]\n",
    "print('MAP (optimizing)', neg_log_prop_posterior(result.optimize_result.x[0]))\n",
    "print('MAP (sampling)', neg_log_prop_posterior(MAP))\n",
    "\n",
    "if model_name == 'fröhlich-simple':\n",
    "    # it is known, that this model's posterior should have two modes (in the first two parameters)\n",
    "    other_MAP = MAP.copy()\n",
    "    other_MAP[[0,1]] = other_MAP[[1,0]]\n",
    "    print('MAP-2 (sampling)', neg_log_prop_posterior(other_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(10, 5))\n",
    "\n",
    "ax = model.prepare_plotting(obs_data_indv, MAP, ax)\n",
    "_, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(labels, ncol=4, loc='lower center', bbox_to_anchor=(0.5, 1))\n",
    "\n",
    "ax.set_title(f'MAP fit')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "973d460a21dc7c62"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare BayesFlow and MCMC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca40267bf1ff9280"
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.rcParams.update({'font.size': 25,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,12)}) #\n",
    "#colors = ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9646e73cef1d6a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce to same number of samples\n",
    "n_samples_umap = min(obs_data_posterior_samples[individual_id].shape[0], pesto_samples_adjusted.shape[0])\n",
    "bayes_flow_samples = obs_data_posterior_samples[individual_id, :n_samples_umap]\n",
    "mcmc_smaples = pesto_samples_adjusted[np.random.choice(range(pesto_samples_adjusted.shape[0]),\n",
    "                                                       n_samples_umap, replace=False)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9471049f70aa82b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(model.n_params/2)), tight_layout=True, figsize=(16,12))\n",
    "axis = ax.flatten()\n",
    "bins = 40\n",
    "for i, name in enumerate(model.param_names):\n",
    "    axis[i].set_title('log '+name)\n",
    "    #axis[i].hist(bayes_flow_samples[:, i], bins=bins, density=True, label='BayesFlow', color='blue')\n",
    "\n",
    "    axis[i].hist(mcmc_smaples[:, i], bins=bins, density=True, label='MCMC', alpha=0.6, color='red')\n",
    "    axis[i].legend()\n",
    "\n",
    "for _ax in axis[model.n_params:]:\n",
    "    _ax.remove()\n",
    "#plt.savefig(f'../plots/mcmc/posterior_validation_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(model.n_params/2)), tight_layout=True, figsize=(16,12))\n",
    "axis = ax.flatten()\n",
    "for i, name in enumerate(model.param_names):\n",
    "    axis[i].set_title(name)\n",
    "    axis[i].hist(np.exp(bayes_flow_samples[:, i]), bins=bins, density=True, label='BayesFlow', color='blue')\n",
    "\n",
    "    axis[i].hist(np.exp(mcmc_smaples[:, i]), bins=bins, density=True, label='MCMC', alpha=0.6, color='red')\n",
    "    axis[i].legend()\n",
    "\n",
    "for _ax in axis[model.n_params:]:\n",
    "    _ax.remove()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c37b8d685ad15411"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(16, 6),\n",
    "                       sharex='row', sharey='all')\n",
    "    \n",
    "ax[0] = model.prepare_plotting(obs_data_indv, obs_data_posterior_samples[individual_id], ax[0])\n",
    "ax[1] = model.prepare_plotting(obs_data_indv, thinned_samples[:n_bayesflow_samples], ax[1])\n",
    "_, labels = ax[0].get_legend_handles_labels()\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "fig.legend(labels, ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.01))\n",
    "ax[0].set_title('BayesFlow Posterior Predictive')\n",
    "ax[1].set_title('MCMC Posterior Predictive')\n",
    "#plt.savefig(f'../plots/mcmc/posterior_simulation_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb99718e76cd7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be49d0aeab980b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute wasserstein distance on original samples\n",
    "m = ot.dist(bayes_flow_samples, mcmc_smaples)\n",
    "sample_weights_bf = np.ones(bayes_flow_samples.shape[0]) / bayes_flow_samples.shape[0]  # uniform\n",
    "sample_weights_mcmc = np.ones(mcmc_smaples.shape[0]) / mcmc_smaples.shape[0]  # uniform\n",
    "w_dist = ot.emd2(sample_weights_bf, sample_weights_mcmc, m)\n",
    "\n",
    "print(f'Wasserstein distance between posteriors {w_dist}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfa8a3a5cf69d7c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "To see visually if samples differ, we map the posterior samples in a two-dimensional space using a UMAP. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324d158dc82ee949"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34ad569f8d46d2f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalize samples\n",
    "all_samples = np.concatenate((bayes_flow_samples, mcmc_smaples), axis=0)\n",
    "scaled_samples = StandardScaler().fit_transform(all_samples)\n",
    "\n",
    "# create umap\n",
    "reducer = umap.UMAP(random_state=42, n_jobs=1,   # for reproducibility \n",
    "                    #densmap=True,  # preserve local density\n",
    "                    ) \n",
    "umap_embedding = reducer.fit_transform(scaled_samples)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b5cb6f0d29610cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True, figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    umap_embedding[:n_samples_umap, 0],\n",
    "    umap_embedding[:n_samples_umap, 1], label='BayesFlow', alpha=0.7, color='blue')\n",
    "plt.scatter(\n",
    "    umap_embedding[n_samples_umap:, 0],\n",
    "    umap_embedding[n_samples_umap:, 1], label='MCMC', alpha=0.7, color='red')\n",
    "plt.legend()\n",
    "plt.title('Umap Based Representation of Posterior Distributions')\n",
    "\n",
    "#plt.savefig(f'../plots/mcmc/posterior_umap_{model.name}_individual_{individual_id}.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eabb7eef19a8630"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc428bcca7d5aea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
