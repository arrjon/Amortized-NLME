{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model\n",
    "\n",
    "## Individual Fit - Empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pypesto.optimize as pesto_opt\n",
    "from pypesto import FD, Objective, Problem, store\n",
    "from scipy.stats import normaltest\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for amortized inference  # todo: something with this imports is not working, kills jupyter\n",
    "from inference.inference_functions import create_boundaries_from_prior\n",
    "from inference.nlme_objective import get_covariance\n",
    "from inference.empirical_bayes import ObjectiveFunctionEmpiricalBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8adc6d89"
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load ODE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf260c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator\n",
    "    individual_model = FroehlichModelSimple(load_best=True)\n",
    "    n_data = 500\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator\n",
    "    individual_model = FroehlichModelDetailed(load_best=True)\n",
    "    n_data = 500\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel, simulate_single_patient, convert_bf_to_observables\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "    n_data = 47\n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel, simulate_single_patient, convert_bf_to_observables\n",
    "    prior_type = ['normal', 'uniform'][0]\n",
    "    individual_model = ClaironSmallModel(load_best=True, prior_type=prior_type)\n",
    "    n_data = 742\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clairon' in model_name:\n",
    "    obs_data, covariates = individual_model.load_data(n_data=n_data, load_covariates=True)\n",
    "else:\n",
    "    obs_data = individual_model.load_data(n_data=n_data)\n",
    "posterior_draws = individual_model.draw_posterior_samples(data=obs_data, n_samples=100)\n",
    "print(len(obs_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obs_data = obs_data[:200]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e029e27dc6a9c7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Cell / Patient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7727a4fcf2058c7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e0dbda7d95d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_idx = 0\n",
    "\n",
    "# simulate\n",
    "if 'fröhlich' in model_name:\n",
    "    t_measurements_full = np.linspace(start=1 / 6, stop=30, num=180, endpoint=True)\n",
    "    y_sim = batch_simulator(posterior_draws[individual_idx], \n",
    "                            with_noise=False).squeeze(axis=2)\n",
    "    t_measurements = t_measurements_full\n",
    "    y = obs_data[individual_idx]\n",
    "elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "    y_sim = simulate_single_patient(posterior_draws[individual_idx], \n",
    "                                    patient_data=obs_data[individual_idx], \n",
    "                                    full_trajectory=True,\n",
    "                                    with_noise=False)\n",
    "    observations = convert_bf_to_observables(obs_data[individual_idx])\n",
    "    # this is the same for the clairon and pharma model\n",
    "    y = observations[0]\n",
    "    t_measurements = observations[1]\n",
    "    doses_time_points = observations[2]\n",
    "    t_measurements_full = np.linspace(0, t_measurements[-1], 100)\n",
    "else:\n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute median and 95% percentiles\n",
    "if 'pharma' in model_name:\n",
    "    # pharma has two observables\n",
    "    y_median_1 = np.median(y_sim[:, :, 0], axis=0)\n",
    "    y_perc_1 = np.percentile(y_sim[:, :, 0], (2.5, 97.5), axis=0)\n",
    "    y_median_2 = np.median(y_sim[:, :, 1], axis=0)\n",
    "    y_perc_2 = np.percentile(y_sim[:, :, 1], (2.5, 97.5), axis=0)\n",
    "    plt.plot(t_measurements_full, y_median_1, color='orange', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc_1[0], y_perc_1[1], color='orange', alpha=0.2)\n",
    "    plt.plot(t_measurements_full, y_median_2, color='red', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc_2[0], y_perc_2[1], color='red', alpha=0.2)\n",
    "    \n",
    "    plt.scatter(t_measurements, y[:, 0], label='measurements', color='orange')\n",
    "    plt.scatter(t_measurements, y[:, 1], label='measurements', color='red')\n",
    "else:\n",
    "    y_median = np.median(y_sim, axis=0)\n",
    "    y_perc = np.percentile(y_sim, (2.5, 97.5), axis=0)\n",
    "    plt.plot(t_measurements_full, y_median, color='orange', alpha=0.2)\n",
    "    plt.fill_between(t_measurements_full, y_perc[0], y_perc[1], color='orange', alpha=0.2)\n",
    "\n",
    "    plt.scatter(t_measurements, y, label='measurements')\n",
    "    \n",
    "if 'clairon' in model_name or 'pharma' in model_name:\n",
    "    plt.vlines(doses_time_points, 0, np.max(y), color='grey', alpha=0.2, label='doses')\n",
    "plt.legend()\n",
    "plt.title(f'Patient {individual_idx}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93713ed016dc4b16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Individuals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20c4039aedb4badf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load pypesto result from population optimization\n",
    "covariance_format = ['diag', 'cholesky'][0]\n",
    "filename_result_population = f'../output/{model_name}-{covariance_format}-n_data_{n_data}.hdf5'\n",
    "if individual_model.prior_type == 'uniform':\n",
    "    filename_result_population = filename_result_population.replace('.hdf5', '-uniform.hdf5')\n",
    "if os.path.exists(filename_result_population):\n",
    "    result_optimization = store.read_result(filename_result_population)\n",
    "    best_res = result_optimization.optimize_result.x[0]\n",
    "    pop_mean = best_res[:individual_model.n_params]\n",
    "    pop_cov = get_covariance(best_res[individual_model.n_params:], \n",
    "                         covariance_format=covariance_format, param_dim=individual_model.n_params)  \n",
    "else:\n",
    "    raise FileNotFoundError('population optimization result not found, you need to define the population parameters '\n",
    "                            'manually')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d05535b5b3a6ee6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_bounds = create_boundaries_from_prior(\n",
    "            prior_mean=individual_model.prior_mean,\n",
    "            prior_std=individual_model.prior_std,\n",
    "            prior_type=individual_model.prior_type,\n",
    "            prior_bounds=individual_model.prior_bounds if hasattr(individual_model, 'prior_bounds') else None,\n",
    "            boundary_width_from_prior=5,\n",
    "            covariance_format=covariance_format)\n",
    "# we are only interested in the mean parameters\n",
    "lower_bound = param_bounds[0, :individual_model.n_params]\n",
    "upper_bound = param_bounds[1, :individual_model.n_params]\n",
    "\n",
    "# create fixed indices and values for parameters which are fixed\n",
    "# exactly those parameters which had a fixed variance in the population model\n",
    "fixed_indices = [i for i, name in enumerate(individual_model.param_names) if 'error' in name or 'sigma' in name]\n",
    "if 'pharma' in model_name:\n",
    "    fixed_effects_pharma = ['$\\\\theta_1$', '$\\\\theta_5$', '$\\\\theta_7$', '$\\\\theta_8$', \n",
    "                         '$\\\\theta_{10}$', '$\\\\theta_{12}$', '$\\\\theta_{13}$']\n",
    "    fixed_indices = fixed_indices + [i for i, name in enumerate(individual_model.param_names) if name in fixed_effects_pharma]\n",
    "free_indices = [i for i in range(individual_model.n_params) if i not in fixed_indices]\n",
    "fixed_values = pop_mean[fixed_indices]\n",
    "guess_val = pop_mean[[i for i in range(individual_model.n_params) if i not in fixed_indices]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe84906ed0d5b225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_empirical_bayes_helper(individual_idx: int, \n",
    "                                n_start: int,\n",
    "                                obs_data: np.ndarray,\n",
    "                                pop_mean: np.ndarray,\n",
    "                                pop_cov: np.ndarray,\n",
    "                                lower_bound: np.ndarray,\n",
    "                                upper_bound: np.ndarray,\n",
    "                                fixed_indices: np.ndarray,\n",
    "                                fixed_values: np.ndarray,\n",
    "                                verbose: bool = False,\n",
    "                               get_likelihood: bool = False) -> np.ndarray:\n",
    "    \n",
    "    # create objective function\n",
    "    # prepare batch simulator\n",
    "    noise_type = 'multiplicative'\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=False)  # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[individual_idx].flatten()\n",
    "        # error covariance\n",
    "        sigmas = np.exp(pop_mean[-1])\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          patient_data=obs_data[individual_idx], \n",
    "                                          with_noise=False)\n",
    "        observations = convert_bf_to_observables(obs_data[individual_idx])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "        \n",
    "        if 'clairon' in model_name:\n",
    "            sigmas = np.exp(pop_mean[-2]) + np.exp(pop_mean[-1])*y\n",
    "            noise_type = 'additive'  # with proportional variance\n",
    "        else:\n",
    "            sigmas = np.array([np.exp(pop_mean[8:10])**2] * y.shape[0])\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    \n",
    "    eb_obj_fun = ObjectiveFunctionEmpiricalBayes(\n",
    "        data=y,\n",
    "        pop_mean=pop_mean,\n",
    "        pop_cov=pop_cov,\n",
    "        sigmas=sigmas,\n",
    "        batch_simulator=partial_batch_simulator,\n",
    "        noise_type=noise_type,\n",
    "        ignore_conditional=get_likelihood,\n",
    "        huber_loss_delta=3.1398\n",
    "    )\n",
    "        \n",
    "    pesto_objective = FD(obj=Objective(fun=eb_obj_fun,\n",
    "                                   x_names=individual_model.param_names))\n",
    "    pesto_problem = Problem(objective=pesto_objective,\n",
    "                            lb=lower_bound, ub=upper_bound,\n",
    "                            x_fixed_indices=fixed_indices,\n",
    "                            x_fixed_vals=fixed_values,\n",
    "                            x_names=individual_model.param_names,\n",
    "                            x_scales=['log']*individual_model.n_params,\n",
    "                            x_guesses=[guess_val]\n",
    "                            )\n",
    "    if verbose:\n",
    "        print(pesto_problem.print_parameter_summary())\n",
    "\n",
    "    result = pesto_opt.minimize(\n",
    "        problem=pesto_problem,\n",
    "        optimizer=pesto_opt.ScipyOptimizer(),\n",
    "        # engine=engine.MultiProcessEngine(10), # not working due to pickling issues\n",
    "        n_starts=n_start,\n",
    "        progress_bar=verbose)\n",
    "    return result.optimize_result.as_dataframe()\n",
    "\n",
    "get_empirical_bayes = partial(get_empirical_bayes_helper, n_start=10,\n",
    "                                    obs_data=obs_data,\n",
    "                                    pop_mean=pop_mean,\n",
    "                                    pop_cov=pop_cov,\n",
    "                                    lower_bound=lower_bound,\n",
    "                                    upper_bound=upper_bound,\n",
    "                                    fixed_indices=fixed_indices,\n",
    "                                    fixed_values=fixed_values)\n",
    "\n",
    "get_likelihoods = partial(get_empirical_bayes_helper, n_start=10,\n",
    "                                    obs_data=obs_data,\n",
    "                                    pop_mean=pop_mean,\n",
    "                                    pop_cov=pop_cov,\n",
    "                                    lower_bound=lower_bound,\n",
    "                                    upper_bound=upper_bound,\n",
    "                                    fixed_indices=fixed_indices,\n",
    "                                    fixed_values=fixed_values,\n",
    "                                    get_likelihood=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc2d33bd875c78a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "individual_idx = 10\n",
    "result = get_empirical_bayes(individual_idx, n_start=2, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a323cfc56145c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posterior_samples = individual_model.draw_posterior_samples(data=obs_data[individual_idx][np.newaxis, :], n_samples=50)\n",
    "posterior_median = np.median(posterior_samples, axis=0)\n",
    "\n",
    "print('empirical bayes ', result.x[0][free_indices])\n",
    "print('posterior       ', posterior_median[free_indices])\n",
    "print('population      ', pop_mean[free_indices])\n",
    "print('error population', pop_mean[fixed_indices])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad9a2d808eb7fb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chose random patients and plots\n",
    "colors = ['orange', 'red']\n",
    "with_noise = False\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(result.shape[0] / rows)), sharex='all', sharey='all',\n",
    "                       tight_layout=True, figsize=(10, rows*3))\n",
    "axis = ax.flatten()\n",
    "\n",
    "for ax_i, p_id in tqdm(enumerate(range(result.shape[0])), total=result.shape[0]):\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=with_noise)  \n",
    "        # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[p_id].flatten()\n",
    "        t_measurements = np.linspace(1/6, 30, 180)\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = t_measurements\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          full_trajectory=True,\n",
    "                                          patient_data=obs_data[individual_idx], \n",
    "                                          with_noise=with_noise)\n",
    "        observations = convert_bf_to_observables(obs_data[individual_idx])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "        t_measurements = observations[1]\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = np.linspace(0, t_measurements_last, 100)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    sim_data_eb = partial_batch_simulator(result['x'][p_id])\n",
    "    if sim_data_eb.ndim == 1:\n",
    "        sim_data_eb = sim_data_eb[:, np.newaxis]\n",
    "        y = y[:, np.newaxis]\n",
    "    for i in range(sim_data_eb.shape[1]):\n",
    "        eb_handle, = axis[ax_i].plot(t_measurements_full, sim_data_eb[:, i], color=colors[i], label='Empirical Bayes')\n",
    "        data_handle = axis[ax_i].scatter(t_measurements, y[:, i], color=colors[i], label='data')\n",
    "    \n",
    "    if 'clairon' in model_name or 'pharma' in model_name:\n",
    "        axis[ax_i].vlines(doses_time_points, 0, np.max(y), color='grey', linestyles='--', alpha=0.5)\n",
    "        \n",
    "fig.legend(handles=[data_handle, eb_handle], loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7170ed322b4b567"
  },
  {
   "cell_type": "raw",
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    with Pool(10) as mp_pool:\n",
    "        empirical_bayes_res_full = mp_pool.map(get_empirical_bayes_multi, range(len(obs_data[1:3])))\n",
    "    print('Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea11cd122f7e3cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "filename = f'empirical_bayes_results/empirical_bayes-{model_name}-{covariance_format}-n_data_{n_data}.pkl'\n",
    "if individual_model.prior_type == 'uniform':\n",
    "    filename = filename.replace('.pkl', '-uniform.pkl')\n",
    "    \n",
    "if not os.path.exists(filename):\n",
    "    print('running optimization')\n",
    "    empirical_bayes_res_full = []\n",
    "    for i in tqdm(range(n_data)):\n",
    "        empirical_bayes_res_full.append(get_empirical_bayes(i))\n",
    "       \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(empirical_bayes_res_full, f)\n",
    "     \n",
    "else:\n",
    "    with open(filename, 'rb') as f:\n",
    "        empirical_bayes_res_full = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcf9812533fd9ce4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "filename_l = f'empirical_bayes_results/likelihoods-{model_name}-{covariance_format}-n_data_{n_data}.pkl'\n",
    "if individual_model.prior_type == 'uniform':\n",
    "    filename_l = filename_l.replace('.pkl', '-uniform.pkl')\n",
    "\n",
    "if not os.path.exists(filename_l):\n",
    "    print('running optimization')\n",
    "    likelihoods_res_full = []\n",
    "    for i in tqdm(range(n_data)):\n",
    "        likelihoods_res_full.append(get_likelihoods(i))\n",
    "       \n",
    "    with open(filename_l, 'wb') as f:\n",
    "        pickle.dump(likelihoods_res_full, f)\n",
    "     \n",
    "else:\n",
    "    with open(filename_l, 'rb') as f:\n",
    "        likelihoods_res_full = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5db6f074da033956"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce dataframes to get only the estimates\n",
    "empirical_bayes_res = np.array([np.array([i for  i in entry['x']]) for entry in empirical_bayes_res_full])\n",
    "likelihoods_res = np.array([np.array([i for  i in entry['x']]) for entry in likelihoods_res_full])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d6eb9191f48306"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "monolix_file = f'empirical_bayes_results/monolix_empirical_bayes-{model_name}-{covariance_format}-n_data_{n_data}.pkl'\n",
    "if os.path.exists(monolix_file):\n",
    "    with open(monolix_file, 'rb') as f:\n",
    "        monolix_res_full = pickle.load(f)\n",
    "        monolix_res = np.array([entry['x'][0] for entry in monolix_res_full])\n",
    "       \n",
    "    # monolix returns the standard deviation, not the variance\n",
    "    # error variance is 0.0198533 = 0 (fixed parameters)  \n",
    "    pop_mean_monolix = np.array([-2.93353166411073, 6.31425341363383, 0.964473501759479, -13.7105711552498,\n",
    "                         -4.47952481537895, np.log(0.00476513494336853), np.log(0.233158512113676)])\n",
    "    pop_cov_monolix = np.diag(np.array([0.632526977232295, 2.72768175190726, 0.825820609367505, \n",
    "                                        4.23649341947715, 0.423019422206937, \n",
    "                                        np.sqrt(0.0198533), np.sqrt(0.0198533)])**2)\n",
    "else:\n",
    "    monolix_res = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bbae5fc8c609e88"
  },
  {
   "cell_type": "raw",
   "source": [
    "# take median of starts\n",
    "#empirical_bayes_res = np.array([np.median(np.stack(entry['x']), axis=0) \n",
    "#                                for entry in empirical_bayes_res_full])\n",
    "# use only best result\n",
    "empirical_bayes_res = np.array([entry['x'][0] for entry in empirical_bayes_res_full])\n",
    "#np.save('output/empirical_bayes_res_likelihood_clairon_24_10'\n",
    "#                              f'{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr.npy', empirical_bayes_res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bebe49912ccafd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.array(individual_model.param_names)[free_indices])\n",
    "random_vars = empirical_bayes_res[:, 0, free_indices] - pop_mean[free_indices]\n",
    "print(np.mean(random_vars, axis=0))\n",
    "print(pop_cov[free_indices, :].diagonal())\n",
    "print(np.cov(random_vars.T).diagonal())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5cac65fc988d12a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normaltest(random_vars, axis=0).pvalue >= 0.05 # null hypothesis (sample is normal) cannot be rejected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c55312d106574c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "with_noise = False\n",
    "obs = []\n",
    "pred_median = []\n",
    "posterior_median = []\n",
    "posterior_all_samples = []\n",
    "pred_empirical_bayes = []\n",
    "pred_likelihood = []\n",
    "pred_map = []\n",
    "pred_monolix = []\n",
    "pred_pop = []\n",
    "\n",
    "for i in tqdm(range(len(obs_data))):\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=with_noise)  \n",
    "        # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[i].flatten()\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          patient_data=obs_data[i], \n",
    "                                          with_noise=with_noise)\n",
    "        observations = convert_bf_to_observables(obs_data[i])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    obs.append(y)\n",
    "    \n",
    "    # compute individual posterior-median of simulations\n",
    "    posterior_samples_i = individual_model.draw_posterior_samples(data=obs_data[i][np.newaxis, :],\n",
    "                                                                  n_samples=n_samples)\n",
    "    posterior_median_i = np.median(posterior_samples_i, axis=0)\n",
    "    posterior_median.append(posterior_median_i)\n",
    "    posterior_all_samples.append(posterior_samples_i)\n",
    "    \n",
    "    sim_data_i = partial_batch_simulator(posterior_samples_i)\n",
    "    pred_median.append(np.median(sim_data_i, axis=0))\n",
    "    \n",
    "    # simulate with the best empirical bayes\n",
    "    sim_data_eb = partial_batch_simulator(empirical_bayes_res[i, 0])\n",
    "    pred_empirical_bayes.append(sim_data_eb)\n",
    "    \n",
    "    # simulate with likelihood estimate\n",
    "    sim_data_l = partial_batch_simulator(likelihoods_res[i, 0])\n",
    "    pred_likelihood.append(sim_data_l)\n",
    "    \n",
    "    # simulate with map\n",
    "    sim_data_map = partial_batch_simulator(posterior_median_i)\n",
    "    pred_map.append(sim_data_map)\n",
    "    \n",
    "    # simulate with monolix\n",
    "    if monolix_res is not None:\n",
    "        sim_data_monolix = partial_batch_simulator(monolix_res[i])\n",
    "        pred_monolix.append(sim_data_monolix)\n",
    "    \n",
    "posterior_median = np.array(posterior_median)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3232813e7b03821"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chose random patients and plots\n",
    "np.random.seed(42)\n",
    "rand_p_ids = np.random.choice(range(len(obs_data)), size=15, replace=False)\n",
    "\n",
    "colors = ['orange', 'red']\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(rand_p_ids) / rows)), sharex='all', sharey='all',\n",
    "                       tight_layout=True, figsize=(10, rows*3))\n",
    "axis = ax.flatten()\n",
    "\n",
    "for ax_i, p_id in tqdm(enumerate(rand_p_ids), total=len(rand_p_ids)):\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=with_noise)  \n",
    "        # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[p_id].flatten()\n",
    "        t_measurements = np.linspace(1/6, 30, 180)\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = t_measurements\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          full_trajectory=True,\n",
    "                                          patient_data=obs_data[p_id], \n",
    "                                          with_noise=with_noise)\n",
    "        observations = convert_bf_to_observables(obs_data[p_id])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "        t_measurements = observations[1]\n",
    "        doses_time_points = observations[2]\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = np.linspace(0, t_measurements_last, 100)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    sim_data_eb = partial_batch_simulator(empirical_bayes_res[p_id, 0])\n",
    "    if sim_data_eb.ndim == 1:\n",
    "        sim_data_eb = sim_data_eb[:, np.newaxis]\n",
    "        y = y[:, np.newaxis]\n",
    "    for i in range(sim_data_eb.shape[1]):\n",
    "        eb_handle, = axis[ax_i].plot(t_measurements_full, sim_data_eb[:, i], color=colors[i], label='Empirical Bayes')\n",
    "        data_handle = axis[ax_i].scatter(t_measurements, y[:, i], color=colors[i], label='data')\n",
    "    \n",
    "    if 'clairon' in model_name or 'pharma' in model_name:\n",
    "        axis[ax_i].vlines(doses_time_points, 0, np.max(y), color='grey', linestyles='--', alpha=0.5)\n",
    "    \n",
    "    # empirical bayes based on monolix\n",
    "    if monolix_res is not None:\n",
    "        sim_data_monolix = partial_batch_simulator(monolix_res[p_id])\n",
    "        monolix_handle, = axis[ax_i].plot(t_measurements_full, sim_data_monolix, 'r', label='EB - Monolix')\n",
    "    else: \n",
    "        monolix_handle = None\n",
    "        \n",
    "if monolix_handle is not None:\n",
    "    fig.legend(handles=[data_handle, eb_handle, monolix_handle], loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "else:\n",
    "    fig.legend(handles=[data_handle, eb_handle], loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "#plt.savefig(f'plots/comparison_fits_clairon.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35cb37386fa06e9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot individual fits\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5), sharey='all', sharex='all', tight_layout=True)\n",
    "if obs[0].ndim == 2:\n",
    "    obs_1 = np.concatenate([o[:, 0] for o in obs])\n",
    "    obs_2 = np.concatenate([o[:, 1] for o in obs])\n",
    "    pred_median_1 = np.concatenate([p[:, 0] for p in pred_median])\n",
    "    pred_median_2 = np.concatenate([p[:, 1] for p in pred_median])\n",
    "    pred_empirical_bayes_1 = np.concatenate([p[:, 0] for p in pred_empirical_bayes])\n",
    "    pred_empirical_bayes_2 = np.concatenate([p[:, 1] for p in pred_empirical_bayes])\n",
    "    ax[0].scatter(x=pred_median_1, y=obs_1, color=colors[0], label=f'Median of Individual Posterior')\n",
    "    ax[1].scatter(x=pred_empirical_bayes_1, y=obs_1, color=colors[0], label=f'Empirical Bayes')\n",
    "    ax[0].scatter(x=pred_median_2, y=obs_2, color=colors[1], label=f'Median of Individual Posterior')\n",
    "    ax[1].scatter(x=pred_empirical_bayes_2, y=obs_2, color=colors[1], label=f'Empirical Bayes')\n",
    "else:\n",
    "    ax[0].scatter(x=pred_median, y=obs, color='orange', label=f'Median of Individual Posterior')\n",
    "    ax[1].scatter(x=pred_empirical_bayes, y=obs, color='orange', label=f'Empirical Bayes')\n",
    "\n",
    "ax[0].set_ylabel('Measurements')\n",
    "ax[0].set_xlabel('Simulation')\n",
    "ax[1].set_xlabel('Simulation')\n",
    "ax[0].set_title('Medians of Individual Posteriors')\n",
    "ax[1].set_title('Empirical Bayes')\n",
    "ax[0].set_aspect('equal', 'box')\n",
    "ax[1].set_aspect('equal', 'box')\n",
    "#plt.savefig(f'plots/empirical_bayes_clairon{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b81d7f30eb0a9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute shrinkage for every parameter (1 - variance of eta / variance of population), i.e. 1 is full shrinkage\n",
    "shrinkage = []\n",
    "shrinkage_posterior = []\n",
    "shrinkage_monolix = []\n",
    "var_random_effects = pop_cov.diagonal()\n",
    "if monolix_res is not None:\n",
    "    var_random_effects_monolix = pop_cov_monolix.diagonal()\n",
    "\n",
    "for p_i in range(individual_model.n_params):\n",
    "    # from empirical bayes\n",
    "    eta_i = empirical_bayes_res[:, 0, p_i] - pop_mean[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_i) / var_random_effects[p_i]\n",
    "    shrinkage.append(shrinkage_i)\n",
    "    \n",
    "    # from posterior\n",
    "    eta_pos_i = posterior_median[:, p_i] - pop_mean[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_pos_i) / var_random_effects[p_i]\n",
    "    shrinkage_posterior.append(shrinkage_i)\n",
    "    \n",
    "    # for monolix\n",
    "    if monolix_res is not None:\n",
    "        eta_monolix_i = monolix_res[:, p_i] - pop_mean_monolix[p_i]\n",
    "        shrinkage_i = 1 - np.var(eta_monolix_i) / var_random_effects_monolix[p_i]\n",
    "        shrinkage_monolix.append(shrinkage_i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9bb70793df67a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute correlation between random effects and covariates\n",
    "if 'clairon' in model_name:\n",
    "    correlation_age = []\n",
    "    correlation_gender = []\n",
    "    correlation_age_posterior = []\n",
    "    correlation_gender_posterior = []\n",
    "    for p_i in range(individual_model.n_params):\n",
    "        # from empirical bayes\n",
    "        eta_i = empirical_bayes_res[:, 0, p_i] - pop_mean[p_i]\n",
    "        corr_i_age = np.corrcoef(eta_i, covariates[:, 0])[0, 1]\n",
    "        corr_i_gender = np.corrcoef(eta_i, covariates[:, 1])[0, 1]\n",
    "        correlation_age.append(corr_i_age)\n",
    "        correlation_gender.append(corr_i_gender)\n",
    "        \n",
    "        # from posterior\n",
    "        eta_pos_i = posterior_median[:, p_i] - pop_mean[p_i]\n",
    "        corr_i_age = np.corrcoef(eta_pos_i, covariates[:, 0])[0, 1]\n",
    "        corr_i_gender = np.corrcoef(eta_pos_i, covariates[:, 1])[0, 1]\n",
    "        correlation_age_posterior.append(corr_i_age)\n",
    "        correlation_gender_posterior.append(corr_i_gender)\n",
    "        \n",
    "    correlation = [correlation_age, correlation_gender]\n",
    "    correlation_posterior = [correlation_age_posterior, correlation_gender_posterior]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41ce249afcd272aa"
  },
  {
   "cell_type": "raw",
   "source": [
    "precompute_mvn = -0.5 * (pop_mean.size * np.log(2 * np.pi) +\n",
    "                                      np.linalg.slogdet(pop_cov).logabsdet)\n",
    "inv_pop_cov = np.linalg.inv(pop_cov)\n",
    "precompute_mvn_prior = -0.5 * (pop_mean.size * np.log(2 * np.pi) +\n",
    "                                      np.linalg.slogdet(individual_model.prior_cov).logabsdet)\n",
    "inv_prior_cov = np.linalg.inv(individual_model.prior_cov)\n",
    "\n",
    "def expectation(individual_params: np.ndarray):\n",
    "    dif = individual_params - pop_mean\n",
    "    temp = dif.T.dot(inv_pop_cov).dot(dif)\n",
    "    conditional = precompute_mvn - 0.5 * temp\n",
    "    \n",
    "    dif = individual_params - individual_model.prior_mean\n",
    "    temp = dif.T.dot(inv_prior_cov).dot(dif)\n",
    "    prior = precompute_mvn_prior - 0.5 * temp\n",
    "    return np.exp(conditional - prior)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79f9e64c590a26f7"
  },
  {
   "cell_type": "raw",
   "source": [
    "empirical_bayes_samples_weights = []\n",
    "posterior_draws_eb = individual_model.draw_posterior_samples(data=obs_data, n_samples=1000)\n",
    "for i in range(n_data):\n",
    "    sample_weights = np.array([expectation(s) for s in posterior_draws_eb[i]])\n",
    "    #accepted = sample_weights >= 0.001\n",
    "    empirical_bayes_samples_weights.append(sample_weights)\n",
    "empirical_bayes_samples_weights = np.array(empirical_bayes_samples_weights)\n",
    "\n",
    "# compute shrinkage for every parameter (1 - variance of eta / variance of population), i.e. 1 is full shrinkage\n",
    "shrinkage_samples = []\n",
    "for p_i in range(individual_model.n_params):\n",
    "    eta_i = posterior_draws_eb[:, :, p_i].flatten()[empirical_bayes_samples_weights.flatten()>0.001] - pop_mean[p_i]\n",
    "    shrinkage_i = 1 - np.var(eta_i) / var_random_effects[p_i]\n",
    "    shrinkage_samples.append(shrinkage_i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b7403ae2635df15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = 4 if monolix_res is None else 5\n",
    "fig, ax = plt.subplots(rows, len(free_indices), figsize=(15,10), sharex='col',  #sharey='row', \n",
    "                       tight_layout=True)\n",
    "ax_i = 0\n",
    "for p_id in range(individual_model.n_params):\n",
    "    if p_id not in free_indices:\n",
    "        continue\n",
    "    ax[0, ax_i].hist(empirical_bayes_res[:, 0, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    ax[0, ax_i].set_title(f'Empirical Bayes Point Estimates\\nshrinkage {shrinkage[p_id]:.2f}')\n",
    "    ax[0, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "    \n",
    "    #ax[1, ax_i].hist(posterior_draws_eb[:, :, p_id].flatten(), weights=empirical_bayes_samples_weights.flatten(),\n",
    "    #                 density=True, bins=20, color='blue', alpha=0.5)\n",
    "    #ax[1, ax_i].set_title(f'Empirical Bayes Samples\\nshrinkage {shrinkage_samples[p_id]:.2f}')\n",
    "    #ax[1, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "    \n",
    "    #ax[1, p_id].hist(empirical_bayes_res[:, :, p_id].flatten(), \n",
    "    #                 density=True, bins=20, color='blue', alpha=0.5)\n",
    "    \n",
    "    ax[1, ax_i].hist(likelihoods_res[:, 0, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    ax[1, ax_i].set_title(f'Individual Likelihood')\n",
    "    ax[1, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "    \n",
    "    ax[2, ax_i].hist(posterior_median[:, p_id], density=True, bins=20, color='blue', alpha=0.5)\n",
    "    ax[2, ax_i].set_title(f'Combined\\nIndv. Posterior Medians\\nshrinkage {shrinkage_posterior[p_id]:.2f}')\n",
    "    ax[2, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "    \n",
    "    temp = np.concatenate([s[:, p_id] for s in posterior_all_samples])\n",
    "    ax[3, ax_i].hist(temp, density=True, bins=20, color='blue', alpha=0.5)\n",
    "    ax[3, ax_i].set_title(f'Combined\\nIndv. Posteriors')\n",
    "    ax[3, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "\n",
    "        \n",
    "    # plot expected distribution\n",
    "    x = np.linspace(pop_mean[p_id] - 3*np.sqrt(pop_cov.diagonal())[p_id], \n",
    "                    pop_mean[p_id] + 3*np.sqrt(pop_cov.diagonal())[p_id], 100)\n",
    "    pop_density = stats.norm.pdf(x, pop_mean[p_id], np.sqrt(pop_cov.diagonal()[p_id]))\n",
    "    for i in range(0, 4):\n",
    "        pop_handle, = ax[i, ax_i].plot(x, pop_density,\n",
    "                      color='black', label='Estimated Population')\n",
    "    # plot pior\n",
    "    if individual_model.prior_type == 'normal':\n",
    "        x_prior = np.linspace(individual_model.prior_mean[p_id] - 2.58*individual_model.prior_std[p_id], \n",
    "                    individual_model.prior_mean[p_id] + 2.58*individual_model.prior_std[p_id], 100)\n",
    "        prior_density = stats.norm.pdf(x_prior, individual_model.prior_mean[p_id], individual_model.prior_std[p_id])\n",
    "        prior_handle, = ax[2, ax_i].plot(x_prior, prior_density, color='orange', label='Individual Prior', linestyle='--')\n",
    "        prior_handle, = ax[3, ax_i].plot(x_prior, prior_density,\n",
    "                                         color='orange', label='Individual Prior', linestyle='--')\n",
    "    else:\n",
    "        for i in range(0, ax.shape[0]):\n",
    "            ax[i, ax_i].set_xlim(individual_model.prior_bounds[p_id])\n",
    "    \n",
    "    # monolix\n",
    "    if monolix_res is not None:\n",
    "        ax[4, ax_i].hist(monolix_res[:, p_id], density=True, bins=20, color='red', alpha=0.5)\n",
    "        ax[4, ax_i].set_title(f'Empirical Bayes Point Estimates\\nshrinkage {shrinkage_monolix[p_id]:.2f}')\n",
    "        ax[4, ax_i].set_xlabel(individual_model.log_param_names[p_id])\n",
    "    \n",
    "        x = np.linspace(pop_mean_monolix[p_id] - 3*np.sqrt(pop_cov_monolix.diagonal())[p_id], \n",
    "                        pop_mean_monolix[p_id] + 3*np.sqrt(pop_cov_monolix.diagonal())[p_id], 100)\n",
    "        pop_density_m = stats.norm.pdf(x, pop_mean_monolix[p_id], np.sqrt(pop_cov_monolix.diagonal()[p_id]))\n",
    "        monolix_handle, = ax[4, ax_i].plot(x, pop_density_m, color='red', label='Monolix Population')\n",
    "        \n",
    "    ax_i += 1\n",
    "    \n",
    "# plot bounds for empirical bayes estimates\n",
    "#ax0_ylim = ax[0, 0].get_ylim()\n",
    "#ax1_ylim = ax[1, 0].get_ylim()\n",
    "#ax5_ylim = ax[-1, 0].get_ylim()\n",
    "\n",
    "#for p_id in range(individual_model.n_params):\n",
    "    #bound_handle = ax[0, p_id].vlines(lower_bound[p_id], ax0_ylim[0], ax0_ylim[1], color='green', linestyle='--', label='Bounds')\n",
    "    #ax[0, p_id].vlines(upper_bound[p_id], ax0_ylim[0], ax0_ylim[1], color='green', linestyle='--')\n",
    "    #ax[1, p_id].vlines(lower_bound[p_id], ax1_ylim[0], ax1_ylim[1], color='green', linestyle='--')\n",
    "    #ax[1, p_id].vlines(upper_bound[p_id], ax1_ylim[0], ax1_ylim[1], color='green', linestyle='--')\n",
    "\n",
    "    \n",
    "\n",
    "if monolix_res is not None:\n",
    "    if individual_model.prior_type == 'uniform': \n",
    "        fig.legend(handles=[pop_handle, monolix_handle], \n",
    "                   loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "    else:\n",
    "        fig.legend(handles=[pop_handle, monolix_handle, prior_handle], \n",
    "                   loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "else:\n",
    "    if individual_model.prior_type == 'uniform': \n",
    "        fig.legend(handles=[pop_handle], \n",
    "                   loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "    else:\n",
    "        fig.legend(handles=[pop_handle, prior_handle], \n",
    "               loc='lower center', bbox_to_anchor=(0.5, -0.02), ncols=4)\n",
    "\n",
    "#plt.savefig(f'plots/comparison_histograms_clairon.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8318475f374983"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot covariates against individual parameters\n",
    "covariate_names = ['age', 'gender']\n",
    "\n",
    "col = 2 if monolix_res is None else 3\n",
    "\n",
    "for covariate_i, c in enumerate(covariate_names):\n",
    "    #y_axis_scale = lambda x: np.exp(x)\n",
    "    y_axis_scale = lambda x: x\n",
    "    \n",
    "    fig, ax = plt.subplots(individual_model.n_params, col, figsize=(15,15), sharey='row', sharex='all', tight_layout=True)\n",
    "    for p_id in range(individual_model.n_params):\n",
    "        ax[p_id, 0].set_ylabel(individual_model.log_param_names[p_id])\n",
    "        \n",
    "        ax[p_id, 0].scatter(covariates[:, covariate_i], \n",
    "                            y_axis_scale(empirical_bayes_res[:, 0, p_id])-y_axis_scale(pop_mean[p_id]), \n",
    "                            color='orange')\n",
    "        ax[p_id, 1].scatter(covariates[:, covariate_i], \n",
    "                            y_axis_scale(posterior_median[:, p_id])-y_axis_scale(pop_mean[p_id]), \n",
    "                            color='blue')\n",
    "        if monolix_res is not None:\n",
    "             ax[p_id, 2].scatter(covariates[:, covariate_i], \n",
    "                            y_axis_scale(monolix_res[:, p_id])-y_axis_scale(pop_mean[p_id]),\n",
    "                                 #y_axis_scale(np.mean(monolix_res[:, p_id])),\n",
    "                            color='red')\n",
    "        # add text upper right corner\n",
    "        ax[p_id, 0].text(0.7, 0.7, f'shrinkage {shrinkage[p_id]:.2f}\\n'\n",
    "                                     f'correlation {correlation[covariate_i][p_id]:.2f}',\n",
    "                         transform=ax[p_id, 0].transAxes)\n",
    "        ax[p_id, 1].text(0.7, 0.7, f'shrinkage {shrinkage_posterior[p_id]:.2f}\\n'\n",
    "                                        f'correlation {correlation_posterior[covariate_i][p_id]:.2f}',\n",
    "                         transform=ax[p_id, 1].transAxes)\n",
    "        if monolix_res is not None:\n",
    "            ax[p_id, 2].text(0.7, 0.7, f'shrinkage {shrinkage_monolix[p_id]:.2f}',\n",
    "                         transform=ax[p_id, 2].transAxes)\n",
    "        # ax[p_id, 0].hlines(y_axis_scale(lower_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 1].hlines(y_axis_scale(lower_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 0].hlines(y_axis_scale(upper_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "        # ax[p_id, 1].hlines(y_axis_scale(upper_bound[p_id])-y_axis_scale(pop_params[p_id]), \n",
    "        #                   np.min(covariates[:, covariate_i]), np.max(covariates[:, covariate_i]),\n",
    "        #                   color='red', linestyles='--')\n",
    "    \n",
    "    ax[-1, 0].set_xlabel(f'{covariate_names[covariate_i]}')\n",
    "    ax[-1, 1].set_xlabel(f'{covariate_names[covariate_i]}')\n",
    "    ax[0, 0].set_title(f'Empirical Bayes')\n",
    "    ax[0, 1].set_title(f'Individual Posterior Median\\n(without population information)')\n",
    "    if monolix_res is not None:\n",
    "        ax[0, 2].set_title(f'Monolix Empirical Bayes')\n",
    "        ax[-1, 2].set_xlabel(f'{covariate_names[covariate_i]}')\n",
    "    \n",
    "    #plt.savefig(f'plots/covariates_clairon{\"_no\" if obj_fun_amortized.covariance_format == \"diag\" else \"\"}_corr_{covariate_names[covariate_i]}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b47d226ac9e32cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Outlier detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbfe040763063cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# outlier detection\n",
    "deviation = 2\n",
    "outliers = np.zeros((len(obs_data), individual_model.n_params))\n",
    "for p_id in range(individual_model.n_params):\n",
    "    if p_id not in free_indices:\n",
    "        continue\n",
    "    \n",
    "    # compute outlier detection\n",
    "    # compute mean and std of empirical bayes estimates\n",
    "    median_eb = np.median(empirical_bayes_res[:, 0, p_id])\n",
    "    std_eb = np.std(empirical_bayes_res[:, 0, p_id])\n",
    "    \n",
    "    # 3 stds away from mean\n",
    "    outliers[:, p_id] = np.abs(empirical_bayes_res[:, 0, p_id] - median_eb) > deviation*std_eb\n",
    "    print(f'Outliers for {individual_model.log_param_names[p_id]}: {np.sum(outliers[:, p_id])}')\n",
    "    \n",
    "# get index of individuals which are outliers for at least one parameter\n",
    "outlier_idx = np.arange(len(obs_data))[np.any(outliers, axis=1)]\n",
    "print(f'Outliers for at least one parameter: {len(outlier_idx)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5215c3de4937ab33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = ['orange', 'red']\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, int(np.ceil(len(outlier_idx) / rows)), sharex='all', sharey='all',\n",
    "                       tight_layout=True, figsize=(10, rows*3))\n",
    "axis = ax.flatten()\n",
    "\n",
    "for ax_i, p_id in tqdm(enumerate(outlier_idx)):\n",
    "    axis[ax_i].set_title(f'Patient {p_id}')\n",
    "    if 'fröhlich' in model_name:\n",
    "        partial_batch_simulator = partial(batch_simulator, \n",
    "                                          with_noise=with_noise)  \n",
    "        # only one simulation, so format should be (#imulations)\n",
    "        y = obs_data[p_id].flatten()\n",
    "        t_measurements = np.linspace(1/6, 30, 180)\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = t_measurements\n",
    "    elif 'clairon' in model_name or 'pharma' in model_name:\n",
    "        partial_batch_simulator = partial(simulate_single_patient, \n",
    "                                          full_trajectory=True,\n",
    "                                          patient_data=obs_data[p_id], \n",
    "                                          with_noise=with_noise)\n",
    "        observations = convert_bf_to_observables(obs_data[p_id])\n",
    "        # this is the same for the clairon and pharma model\n",
    "        y = observations[0]\n",
    "        t_measurements = observations[1]\n",
    "        doses_time_points = observations[2]\n",
    "        t_measurements_last = t_measurements[-1]\n",
    "        t_measurements_full = np.linspace(0, t_measurements_last, 100)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    sim_data_eb = partial_batch_simulator(empirical_bayes_res[p_id, 0])\n",
    "    if sim_data_eb.ndim == 1:\n",
    "        sim_data_eb = sim_data_eb[:, np.newaxis]\n",
    "        y = y[:, np.newaxis]\n",
    "    for i in range(sim_data_eb.shape[1]):\n",
    "        eb_handle, = axis[ax_i].plot(t_measurements_full, sim_data_eb[:, i], color=colors[i], label='Empirical Bayes')\n",
    "        data_handle = axis[ax_i].scatter(t_measurements, y[:, i], color=colors[i], label='data')\n",
    "    \n",
    "    if 'clairon' in model_name or 'pharma' in model_name:\n",
    "        axis[ax_i].vlines(doses_time_points, 0, np.max(y), color='grey', linestyles='--', alpha=0.5)\n",
    "    \n",
    "    # empirical bayes based on monolix\n",
    "    if monolix_res is not None:\n",
    "        sim_data_monolix = partial_batch_simulator(monolix_res[p_id])\n",
    "        monolix_handle, = axis[ax_i].plot(t_measurements_full, sim_data_monolix, 'r', label='EB - Monolix')\n",
    "    else: \n",
    "        monolix_handle = None\n",
    "        \n",
    "if monolix_handle is not None:\n",
    "    fig.legend(handles=[data_handle, eb_handle, monolix_handle], loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "else:\n",
    "    fig.legend(handles=[data_handle, eb_handle], loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "#plt.savefig(f'plots/comparison_fits_clairon.png')\n",
    "for _ax in fig.axes[len(outlier_idx):]:  \n",
    "    _ax.remove()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd02d4f7ebdc17f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "576e88f7a4d486c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
