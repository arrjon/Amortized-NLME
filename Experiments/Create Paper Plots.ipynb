{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from pypesto import profile, store\n",
    "from pypesto.store import read_from_hdf5\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t as t_dist\n",
    "from inference.helper_functions import compute_error_estimate\n",
    "from inference.inference_functions import create_boundaries_from_prior\n",
    "from inference.nlme_objective import ObjectiveFunctionNLME, get_covariance\n",
    "from inference.ploting_routines import corrplot"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcdefaults()  # for resetting to defaults"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,9)}) #\n",
    "colors = ['#1f78b4', '#a6cee3', '#b2df8a','#33a02c','#fb9a99']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load models\n",
    "from models.froehlich_model_simple import FroehlichModelSimple, batch_simulator as simulator_simple\n",
    "simple_model = FroehlichModelSimple(load_best=True)\n",
    "_ = simple_model.build_trainer('../networks/' +  simple_model.network_name)\n",
    "\n",
    "from models.froehlich_model_detailed import FroehlichModelDetailed, batch_simulator as simulator_detailed\n",
    "detailed_model = FroehlichModelDetailed(load_best=True)\n",
    "_ = detailed_model.build_trainer('../networks/' +  detailed_model.network_name)\n",
    "\n",
    "from models.froehlich_model_sde import FroehlichModelSDE, batch_simulator as simulator_sde\n",
    "sde_model = FroehlichModelSDE(load_best=True)\n",
    "_ = sde_model.build_trainer('../networks/' +  sde_model.network_name)\n",
    "\n",
    "from models.pharmacokinetic_model import PharmacokineticModel\n",
    "\n",
    "pharma_model = PharmacokineticModel(load_best=True)\n",
    "_ = pharma_model.build_trainer('../networks/' +  pharma_model.network_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load synthetic data for specific model\n",
    "single_real_data = simple_model.load_data(load_egfp=True, load_d2egfp=False)\n",
    "n_bayesflow_samples = 1000\n",
    "\n",
    "np.random.seed(42)\n",
    "random_index = np.random.randint(0, single_real_data[0].shape[0])\n",
    "\n",
    "# simulate data from different posterior samples for a real cell\n",
    "real_single_cell = single_real_data[random_index][np.newaxis, :]\n",
    "param_samples_real =  simple_model.draw_posterior_samples(data=real_single_cell, n_samples=n_bayesflow_samples)\n",
    "real_sim = simulator_simple(param_samples_real)\n",
    "real_median = np.median(real_sim, axis=0)\n",
    "real_perc = np.percentile(real_sim.reshape(n_bayesflow_samples, 180), (2.75, 97.5), axis=0)\n",
    "\n",
    "real_single_cell2 = single_real_data[single_real_data.shape[0]-random_index][np.newaxis, :]\n",
    "param_samples_real2 = simple_model.draw_posterior_samples(data=real_single_cell2, n_samples=n_bayesflow_samples)\n",
    "real_sim2 = simulator_simple(param_samples_real2)\n",
    "real_median2 = np.median(real_sim2, axis=0)\n",
    "real_perc2 = np.percentile(real_sim2.reshape(n_bayesflow_samples, 180), (2.75, 97.5), axis=0)\n",
    "\n",
    "# simulated data\n",
    "t_points = np.linspace(start=1 / 6, stop=30, num=180, endpoint=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scalability & Error Analysis\n",
    "test_n_cells = [50, 100, 500, 5000, 10000]\n",
    "compute_relative_error = False  # relative to true parameter values\n",
    "epsilon = 1e-4\n",
    "\n",
    "# load results\n",
    "n_samples_opt_list = [10, 50, 100, 250]\n",
    "n_runs = 100\n",
    "simple_model_time_opt = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "simple_model_amortized_error = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "simple_model_amortized_var = np.ones((len(test_n_cells), len(n_samples_opt_list))) * np.nan\n",
    "    \n",
    "for nc, n_cells in enumerate(test_n_cells):\n",
    "    for ns, n_samples in enumerate(n_samples_opt_list):\n",
    "        # load results\n",
    "        filename = f'synthetic_results_amortized/{simple_model.name}_cells_{n_cells}_samples_{n_samples}.hd5'\n",
    "        result_optimization = store.read_result(filename)\n",
    "        results_params = np.array(result_optimization.optimize_result.x)\n",
    "                \n",
    "        # load true population parameters\n",
    "        true_pop_parameters = simple_model.load_synthetic_parameter(n_data=n_cells)\n",
    "        # set very small variances to 0.001\n",
    "        true_pop_parameters[simple_model.n_params:][true_pop_parameters[simple_model.n_params:] < 0.001] = 0.001\n",
    "        \n",
    "        estimated_params_full = []\n",
    "        for i_r, res in enumerate(results_params):\n",
    "            # transform results\n",
    "            estimated_beta = res[:simple_model.n_params]\n",
    "            estimated_var = np.exp(-res[simple_model.n_params:simple_model.n_params*2])\n",
    "            estimated_params = np.concatenate((estimated_beta, estimated_var))\n",
    "                         \n",
    "            # compute relative error of parameter estimated as minimum over multi_starts\n",
    "            simple_model_amortized_error[nc, ns, i_r] = compute_error_estimate(estimated_params,\n",
    "                                                            true_pop_parameters,\n",
    "                                                            bi_modal=True if 'Simple' in simple_model.name else False,\n",
    "                                                            relative_error=compute_relative_error)\n",
    "            estimated_params_full.append(estimated_params)\n",
    "            \n",
    "        simple_model_amortized_var[nc, ns] = np.var(simple_model_amortized_error[nc, ns])\n",
    "             \n",
    "        # get duration of optimization procedure (in seconds)\n",
    "        simple_model_time_opt[nc, ns] = np.array(result_optimization.optimize_result.time) / 60 / 60\n",
    "\n",
    "detailed_model_time_opt = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "detailed_model_amortized_error = np.ones((len(test_n_cells), len(n_samples_opt_list), n_runs)) * np.nan\n",
    "detailed_model_amortized_var = np.ones((len(test_n_cells), len(n_samples_opt_list))) * np.nan\n",
    "for nc, n_cells in enumerate(test_n_cells):\n",
    "    for ns, n_samples in enumerate(n_samples_opt_list):\n",
    "        # load results\n",
    "        filename = f'synthetic_results_amortized/{detailed_model.name}_cells_{n_cells}_samples_{n_samples}.hd5'\n",
    "        result_optimization = store.read_result(filename)\n",
    "        results_params = np.array(result_optimization.optimize_result.x)\n",
    "                \n",
    "        # load true population parameters\n",
    "        true_pop_parameters = detailed_model.load_synthetic_parameter(n_data=n_cells)\n",
    "        # set very small variances to 0.001\n",
    "        true_pop_parameters[detailed_model.n_params:][true_pop_parameters[detailed_model.n_params:] < 0.001] = 0.001\n",
    "        \n",
    "        estimated_params_full = []\n",
    "        for i_r, res in enumerate(results_params):\n",
    "            # transform results\n",
    "            estimated_beta = res[:detailed_model.n_params]\n",
    "            estimated_var = np.exp(-res[detailed_model.n_params:detailed_model.n_params*2])\n",
    "            estimated_params = np.concatenate((estimated_beta, estimated_var))\n",
    "                         \n",
    "            # compute relative error of parameter estimated as minimum over multi_starts\n",
    "            detailed_model_amortized_error[nc, ns, i_r] = compute_error_estimate(estimated_params,\n",
    "                                                            true_pop_parameters,\n",
    "                                                            relative_error=compute_relative_error)\n",
    "            estimated_params_full.append(estimated_params)\n",
    "            \n",
    "        detailed_model_amortized_var[nc, ns] = np.var(detailed_model_amortized_error[nc, ns])\n",
    "             \n",
    "        # get duration of optimization procedure (in seconds)\n",
    "        detailed_model_time_opt[nc, ns] = np.array(result_optimization.optimize_result.time) / 60 / 60\n",
    "\n",
    "\n",
    "# read results from monolix\n",
    "simple_model_monolix_errors = np.ones(len(test_n_cells)) * np.nan\n",
    "simple_model_monolix_var = np.ones(len(test_n_cells)) * np.nan\n",
    "simple_model_timing_monolix = np.ones(len(test_n_cells)) * np.nan\n",
    "simple_model_timing_monolix_std = np.ones(len(test_n_cells)) * np.nan\n",
    "\n",
    "monolix_names = {\"a\": 5, \"delta_pop\": 0,\"gamma_pop\": 1,\"km0scale_pop\": 2,\"offset_pop\": 4,\"omega_delta\": 6,\n",
    "                 \"omega_gamma\": 7, \"omega_km0scale\": 8, \"omega_offset\": 10, \"omega_tBegin\": 9, \"tBegin_pop\": 3}\n",
    "reorder_monolix_params = sorted(monolix_names, key=monolix_names.get)\n",
    "for cell_idx, n_cells in enumerate(test_n_cells):    \n",
    "    estimates_monolix = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                        f'simple/synthetic_{n_cells}/other/synthetic_{n_cells}_population_parameters.csv', \n",
    "                                        index_col=0, header=0)\n",
    "    estimates_monolix = estimates_monolix[reorder_monolix_params]\n",
    "    \n",
    "    true_pop_parameters = simple_model.load_synthetic_parameter(n_data=n_cells)\n",
    "    # set very small variances to 0.001\n",
    "    true_pop_parameters[simple_model.n_params:][true_pop_parameters[simple_model.n_params:] < 0.001] = 0.001\n",
    "\n",
    "    results_to_compare = []\n",
    "    for row_id, row in estimates_monolix.iterrows():\n",
    "        temp_res = row.values\n",
    "        # standard deviation is not on log-scale\n",
    "        temp_res[simple_model.n_params-1] = np.log(np.abs(temp_res[simple_model.n_params-1]))\n",
    "        temp_res = np.concatenate((temp_res, [0.001]))  # add variance of noise\n",
    "        results_to_compare.append(temp_res)\n",
    "    results_to_compare = results_to_compare[:n_runs]\n",
    "\n",
    "    error_mono = compute_error_estimate(np.array(results_to_compare),\n",
    "                                        true_pop_parameters,\n",
    "                                        bi_modal=False if 'Detailed' in simple_model.name else True,\n",
    "                                        relative_error=compute_relative_error)\n",
    "    # take min over multi-starts\n",
    "    error_mono.sort()\n",
    "    simple_model_monolix_errors[cell_idx] = np.nanmedian(error_mono)\n",
    "    simple_model_monolix_var[cell_idx] = np.nanvar(error_mono)\n",
    "\n",
    "    # results are sorted    \n",
    "    # get timing        \n",
    "    timing_monolix_df = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                        f'simple/synthetic_{n_cells}/other/synthetic_{n_cells}_walltimes.csv', \n",
    "                                        header=0)[:100]\n",
    "    simple_model_timing_monolix[cell_idx] = np.nanmedian(timing_monolix_df.saem / 60 / 60)  # in hours\n",
    "    simple_model_timing_monolix_std[cell_idx] = np.nanstd(timing_monolix_df.saem / 60 / 60)  # in hours\n",
    "    \n",
    "    \n",
    "detailed_model_monolix_errors = np.ones(len(test_n_cells)) * np.nan\n",
    "detailed_model_monolix_var = np.ones(len(test_n_cells)) * np.nan\n",
    "detailed_model_timing_monolix = np.ones(len(test_n_cells)) * np.nan\n",
    "detailed_model_timing_monolix_std = np.ones(len(test_n_cells)) * np.nan\n",
    "\n",
    "reorder_monolix_params = [1,2,3,7,6,5,19,4,20,8,0,9,10,11,15,14,13,17,12,18,16]\n",
    "for cell_idx, n_cells in enumerate(test_n_cells):    \n",
    "    estimates_monolix = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                    f'detailed/synthetic_{n_cells}/other/synthetic_{n_cells}_population_parameters.csv', \n",
    "                                        index_col=0, header=0)\n",
    "    \n",
    "    true_pop_parameters = detailed_model.load_synthetic_parameter(n_data=n_cells)\n",
    "    # set very small variances to 0.001\n",
    "    true_pop_parameters[detailed_model.n_params:][true_pop_parameters[detailed_model.n_params:] < 0.001] = 0.001\n",
    "\n",
    "    results_to_compare = []\n",
    "    for row_id, row in estimates_monolix.iterrows():\n",
    "        temp_res = row.values[reorder_monolix_params]\n",
    "        # standard deviation is not on log-scale\n",
    "        temp_res[detailed_model.n_params-1] = np.log(np.abs(temp_res[detailed_model.n_params-1]))\n",
    "        temp_res = np.concatenate((temp_res, [0.001]))  # add variance of noise\n",
    "        results_to_compare.append(temp_res)\n",
    "    results_to_compare = results_to_compare[:n_runs]\n",
    "\n",
    "    error_mono = compute_error_estimate(np.array(results_to_compare), \n",
    "                                        true_pop_parameters, \n",
    "                                        relative_error=compute_relative_error)\n",
    "    # take min over multi-starts\n",
    "    error_mono.sort()\n",
    "    detailed_model_monolix_errors[cell_idx] = np.nanmedian(error_mono)\n",
    "    detailed_model_monolix_var[cell_idx] = np.nanvar(error_mono)\n",
    "    \n",
    "    # get timing\n",
    "    timing_monolix_df = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                        f'detailed/synthetic_{n_cells}/other/synthetic_{n_cells}_walltimes.csv', \n",
    "                                        header=0)[:100]\n",
    "    detailed_model_timing_monolix[cell_idx] = np.nanmedian(timing_monolix_df.saem / 60 / 60)  # in hours\n",
    "    detailed_model_timing_monolix_std[cell_idx] = np.nanstd(timing_monolix_df.saem / 60 / 60)  # in hours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_simple = read_from_hdf5.read_result('../Experiments/multi-experiment/fröhlich-simple_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_simple.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_simple = result_simple.optimize_result.as_dataframe()['x'][0][param_idx_egfp]\n",
    "estimated_beta_simple = result_simple[:6]\n",
    "estimated_psi_simple = get_covariance(result_simple[6:], covariance_format='diag', param_dim=6)\n",
    "\n",
    "result_detailed = read_from_hdf5.read_result('../Experiments/multi-experiment/fröhlich-detailed_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_detailed.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_detailed = result_detailed.optimize_result.as_dataframe()['x'][0][param_idx_egfp]\n",
    "estimated_beta_detailed = result_detailed[:11]\n",
    "estimated_psi_detailed = get_covariance(result_detailed[11:], covariance_format='diag', param_dim=11)\n",
    "\n",
    "result_sde = read_from_hdf5.read_result('../Experiments/multi-experiment/fröhlich-sde_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_sde.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_sde = result_sde.optimize_result.as_dataframe()['x'][0][param_idx_egfp]\n",
    "estimated_beta_sde = result_sde[:8]\n",
    "estimated_psi_sde = get_covariance(result_sde[8:], covariance_format='diag', param_dim=8)\n",
    "\n",
    "mat_simple = scipy.io.loadmat('../data/froehlich_eGFP/code/S=[5,6]_transfection_norm.mat')\n",
    "param_estimates_simple = mat_simple['parameters_MEM'][0,0][6][0][0][4]\n",
    "likelihood_simple = mat_simple['parameters_MEM'][0,0][6][0][0][2]\n",
    "best_id_small = np.nanargmax(likelihood_simple)\n",
    "estimated_beta_fro = param_estimates_simple[:6, best_id_small][[0,1,3,4,5,5]]\n",
    "var_simple = np.exp(param_estimates_simple[6:, best_id_small])[[0,1,3,4,5,5]]\n",
    "estimated_psi_fro = np.diag(var_simple)\n",
    "\n",
    "np.random.seed(42)\n",
    "# sample from log normal distribution\n",
    "n_trajectories = len(single_real_data)\n",
    "reproduced_param_simple = np.random.multivariate_normal(estimated_beta_simple,\n",
    "                                                     estimated_psi_simple,\n",
    "                                                     size=n_trajectories)\n",
    "reproduced_param_detailed = np.random.multivariate_normal(estimated_beta_detailed,\n",
    "                                                        estimated_psi_detailed,\n",
    "                                                        size=n_trajectories)\n",
    "reproduced_param_sde = np.random.multivariate_normal(estimated_beta_sde,\n",
    "                                                        estimated_psi_sde,\n",
    "                                                        size=n_trajectories)\n",
    "reproduced_param_fro = np.random.multivariate_normal(estimated_beta_fro,\n",
    "                                                        estimated_psi_fro,\n",
    "                                                        size=n_trajectories)\n",
    "\n",
    "reproduced_data_simple = simulator_simple(reproduced_param_simple)\n",
    "reproduced_data_detailed = simulator_detailed(reproduced_param_detailed)\n",
    "reproduced_data_sde = simulator_sde(reproduced_param_sde)\n",
    "\n",
    "median_sim_simple = simulator_simple(estimated_beta_simple, with_noise=False)\n",
    "median_sim_detailed = simulator_detailed(estimated_beta_detailed, with_noise=False)\n",
    "median_sim_sde = simulator_sde(np.repeat(estimated_beta_sde[np.newaxis], 100, axis=0), with_noise=False)\n",
    "\n",
    "reproduced_data_fro = simulator_simple(reproduced_param_fro, with_noise=False, exp_func='power10')\n",
    "\n",
    "real_mean = np.mean(single_real_data, axis=0)\n",
    "\n",
    "simple_mean = np.mean(reproduced_data_simple, axis=0)\n",
    "dif_simple = simple_mean - real_mean\n",
    "std_simple = np.std(reproduced_data_simple, axis=0)\n",
    "detailed_mean = np.mean(reproduced_data_detailed, axis=0)\n",
    "dif_detailed = detailed_mean - real_mean\n",
    "std_detailed = np.std(reproduced_data_detailed, axis=0)\n",
    "sde_mean = np.mean(reproduced_data_sde, axis=0)\n",
    "dif_sde = sde_mean - real_mean\n",
    "std_sde = np.std(reproduced_data_sde, axis=0)\n",
    "dif_fro = np.mean(reproduced_data_fro, axis=0) - real_mean\n",
    "std_fro = np.std(reproduced_data_fro, axis=0)\n",
    "\n",
    "t_value_05 = abs(t_dist.ppf(0.05 / reproduced_data_simple.shape[1], df=reproduced_data_simple.shape[0] - 1))\n",
    "\n",
    "confidence_band_upper_05_simple = dif_simple + t_value_05 * std_simple / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_lower_05_simple = dif_simple - t_value_05 * std_simple / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_upper_05_detailed = dif_detailed + t_value_05 * std_detailed / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_lower_05_detailed = dif_detailed - t_value_05 * std_detailed / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_upper_05_sde = dif_sde + t_value_05 * std_sde / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_lower_05_sde = dif_sde - t_value_05 * std_sde / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_upper_05_fro = dif_fro + t_value_05 * std_fro / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_lower_05_fro = dif_fro - t_value_05 * std_fro / np.sqrt(reproduced_data_simple.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result Figure 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_total, ax_total = plt.subplots(nrows=2, ncols=3, figsize=(16, 6), gridspec_kw={'height_ratios': [1, 1]},\n",
    "                                   layout=\"tight\")\n",
    "ax0, ax1_0, ax1, ax2, ax4, ax3 = ax_total.flatten()\n",
    "\n",
    "cell_color = '#609146'  # '#3FC834'\n",
    "\n",
    "##################### Data & Models\n",
    "#ax0.set_title('Single-Cell Translation Kinetics ')\n",
    "#ax1_0.set_title('State Variables of ODE Models')\n",
    "ax0.axis('off')\n",
    "ax1_0.axis('off')\n",
    "\n",
    "#ax1.set_title('Single-Cell Fluorescence Intensities')\n",
    "for i, cell in enumerate(single_real_data[:200]):\n",
    "    ax1.plot(t_points, np.exp(cell.flatten()), color=cell_color, alpha=0.2)\n",
    "ax1.set_xlabel('Time (in hours)')\n",
    "ax1.set_ylabel('Measurements')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('Time (in hours)')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(ax1.get_ylim()[0], 2e4)\n",
    "\n",
    "###################### Posterior Simulation\n",
    "ax2.scatter(t_points, np.exp(real_single_cell2.flatten()), c=cell_color, marker='x', linewidth=0.5)\n",
    "ax2.scatter(t_points, np.exp(real_single_cell.flatten()), c=cell_color, marker='x', linewidth=0.5)\n",
    "ax2.fill_between(t_points, np.exp(real_perc2[0, :]), np.exp(real_perc2[1, :]), \n",
    "                 color='grey', alpha=0.5, label=f'95\\% credible region')\n",
    "region = ax2.fill_between(t_points, np.exp(real_perc[0, :]), np.exp(real_perc[1, :]), \n",
    "                          color='grey', alpha=0.5, label=f'95\\% credible region')\n",
    "median, = ax2.plot(t_points, np.exp(real_median), color='black', label=f'posterior median')\n",
    "ax2.plot(t_points, np.exp(real_median2), color='black')\n",
    "ax2.set_xlabel('Time (in hours)')\n",
    "ax2.set_ylabel('Measurements')\n",
    "ax2.set_yscale('log')\n",
    "#ax2.set_title('Posterior Fit to Single Cell')\n",
    "real_patch = ax2.scatter([],[], marker='x',  c=cell_color, linewidth=2.5, label='measurements')\n",
    "\n",
    "# plot zoom in\n",
    "zax = ax2.inset_axes([0.4, 0.2, 0.45, 0.45])\n",
    "zax.scatter(t_points, np.exp(real_single_cell2.flatten()), c=cell_color, marker='x', linewidth=1)\n",
    "zax.scatter(t_points, np.exp(real_single_cell.flatten()), c=cell_color, marker='x', linewidth=1)\n",
    "zax.fill_between(t_points, np.exp(real_perc2[0, :]), np.exp(real_perc2[1, :]), color='grey', alpha=0.5, label=f'95\\% credible region')\n",
    "zax.fill_between(t_points, np.exp(real_perc[0, :]), np.exp(real_perc[1, :]), color='grey', alpha=0.5, label=f'95\\% credible region')\n",
    "zax.plot(t_points, np.exp(real_median), color='black', label=f'posterior median')\n",
    "zax.plot(t_points, np.exp(real_median2), color='black')\n",
    "zax.set_yscale('log')\n",
    "zax.set_xlim(2,5)\n",
    "zax.set_ylim(3e2,6e2)\n",
    "zax.set_xticks([])\n",
    "zax.set_yticks([], minor=True)\n",
    "zax.set_yticks([])\n",
    "ax2.indicate_inset_zoom(zax, edgecolor=\"black\")\n",
    "\n",
    "###################### population fit (small, large, fröhlich) compared to Fröhlich\n",
    "# plot real synthetic data vs estimated data\n",
    "t_points = np.linspace(start=1 / 6, stop=30, num=real_single_cell.shape[1], endpoint=True)\n",
    "\n",
    "ax3.fill_between(t_points, confidence_band_upper_05_simple.flatten(), confidence_band_lower_05_simple.flatten(),\n",
    "                         color=colors[0], alpha=0.5, label='95\\% confidence band')\n",
    "ax3.plot(t_points, dif_simple, color=colors[0], label='estimation difference')\n",
    "ax3.plot(t_points, np.zeros(t_points.size), color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "ax3.fill_between(t_points, confidence_band_upper_05_detailed.flatten(), confidence_band_lower_05_detailed.flatten(),\n",
    "                         color=colors[4], alpha=0.5, label='95\\% confidence band')\n",
    "ax3.plot(t_points, dif_detailed, color=colors[4], label='estimation difference')\n",
    "\n",
    "ax3.fill_between(t_points, confidence_band_upper_05_fro.flatten(), confidence_band_lower_05_fro.flatten(),\n",
    "                         color=colors[1], alpha=0.5, label='95\\% confidence band')\n",
    "ax3.plot(t_points, dif_fro, color=colors[1], label='estimation difference')\n",
    "\n",
    "#ax3.set_title('Fit to Population Mean')\n",
    "ax3.set_ylabel('Diff. to pop. mean')\n",
    "small_patch = mpatches.Patch(color=colors[0], label='simple ODE NLME model')\n",
    "large_patch = mpatches.Patch(color=colors[4], label='detailed ODE NLME model')\n",
    "ref_patch = mpatches.Patch(color=colors[1], label='simple ODE NLME model (Fröhlich et.\\ al.)')\n",
    "ax3.set_xlabel('Time (in hours)')\n",
    "\n",
    "######################  Error on Synthetic Data\n",
    "for j, n_samples_opt in enumerate([10, 50, 100, 250]):\n",
    "    if n_samples_opt != 100: continue\n",
    "    ax4.errorbar(x=np.arange(len(test_n_cells))-0.21, \n",
    "                 y=np.median(simple_model_amortized_error[:, j], axis=1), \n",
    "                 yerr=np.stack([np.minimum(np.sqrt(simple_model_amortized_var[:, j]), \n",
    "                                                    np.median(simple_model_amortized_error[:, j], axis=1)), \n",
    "                                         np.sqrt(simple_model_amortized_var[:, j])]),\n",
    "                 alpha=1, color=colors[0],\n",
    "                  linestyle='None', marker='x', capsize=3,\n",
    "                                                )\n",
    "ax4.errorbar(x=np.arange(len(test_n_cells))-0.07, \n",
    "                          y=simple_model_monolix_errors, \n",
    "                          yerr=np.stack([np.minimum(np.sqrt(simple_model_monolix_var), \n",
    "                                                    simple_model_monolix_errors), \n",
    "                                         np.sqrt(simple_model_monolix_var)]),\n",
    "              color=colors[0], linestyle='None', marker='^', capsize=3)\n",
    "    \n",
    "for j, n_samples_opt in enumerate([10, 50, 100, 250]):\n",
    "    if n_samples_opt != 100: continue\n",
    "    ax4.errorbar(x=np.arange(len(test_n_cells))+0.07,\n",
    "                 y=np.median(detailed_model_amortized_error[:, j], axis=1), \n",
    "                 yerr=np.stack([np.minimum(np.sqrt(detailed_model_amortized_var[:, j]), \n",
    "                                                    np.median(detailed_model_amortized_error[:, j], axis=1)), \n",
    "                                         np.sqrt(detailed_model_amortized_var[:, j])]),\n",
    "                 alpha=1, color=colors[4],\n",
    "                  linestyle='None', marker='x', capsize=3,\n",
    "                 )\n",
    "    \n",
    "ax4.errorbar(x=np.arange(len(test_n_cells))+0.21, \n",
    "                          y=detailed_model_monolix_errors, \n",
    "                          yerr=np.stack([np.minimum(np.sqrt(detailed_model_monolix_var), \n",
    "                                                    detailed_model_monolix_errors), \n",
    "                                         np.sqrt(detailed_model_monolix_var)]),\n",
    "             color=colors[4], linestyle='None', marker='^', capsize=3)\n",
    "\n",
    "ax4.set_ylabel('Median MSE')\n",
    "ax4.set_xlabel('Number of cells $N$')\n",
    "#ax4.set_title('Parameter Recovery Error')\n",
    "ax4.set_xticks(ticks=np.arange(len(test_n_cells)), labels=np.array(test_n_cells))\n",
    "\n",
    "ax4.errorbar([], [], [], color='black', linestyle='None', marker='x', capsize=3, label='amortized approach')\n",
    "ax4.errorbar([], [], [], color='black', linestyle='None', marker='^', capsize=3, label='baseline (SAEM)')\n",
    "ax4.legend(loc='upper left')\n",
    "ax4.set_ylim(-1, 8)\n",
    "\n",
    "#### Legend\n",
    "median, = ax2.plot([],[],  color='black', label='median')\n",
    "mean, = ax4.plot([],[],  color='black', label='mean')\n",
    "credible = mpatches.Patch(color='grey', label='95\\% credible region')\n",
    "confidence = mpatches.Patch(color='grey', label='95\\% CI')\n",
    "lgd1 = fig_total.legend(handles=[median, credible, real_patch],\n",
    "            loc='lower center', ncol=2, bbox_to_anchor=(0.195, -0.1))\n",
    "lgd3 = ax3.legend(handles=[mean, confidence],\n",
    "            loc='upper right', ncol=2)\n",
    "lgd = fig_total.legend(handles=[small_patch, large_patch, ref_patch],\n",
    "            loc='lower center', ncol=2, bbox_to_anchor=(0.695, -0.1))\n",
    "\n",
    "ax0.text(-0.2, 1, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax0.transAxes, fontsize=22)\n",
    "ax1.text(-0.25, 1, '\\\\bf{C}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax1.transAxes, fontsize=22)\n",
    "ax1_0.text(-0.25, 1, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax1_0.transAxes, fontsize=22)\n",
    "ax2.text(-0.2, 1, '\\\\bf{D}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax2.transAxes, fontsize=22)\n",
    "ax3.text(-0.25, 1, '\\\\bf{F}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax3.transAxes, fontsize=22)\n",
    "ax4.text(-0.25, 1, '\\\\bf{E}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax4.transAxes, fontsize=22)\n",
    "\n",
    "#plt.savefig('../plots/paper/results_plot.svg', format='svg', bbox_inches='tight', pad_inches=0.3,\n",
    "#           bbox_extra_artists=(lgd1,))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " #### Result Figure 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_names = simple_model.param_names.copy()\n",
    "pop_param_names = ['median-' + name for name in param_names]\n",
    "var_param_names = ['var-' + name for name in param_names]\n",
    "param_names_plot = param_names + param_names\n",
    "\n",
    "n_data = 500\n",
    "true_sample_params = simple_model.load_synthetic_parameter(n_data=n_data)\n",
    "result_simple = read_from_hdf5.read_result(\n",
    "    f'../Experiments/synthetic_results_amortized/uncertainty_{simple_model.name}_cells_{n_data}_samples_{100}.hd5')\n",
    "n_opt_param = simple_model.n_params * 2\n",
    "\n",
    "# load monolix results\n",
    "monolix_likelihood = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                    f'simple/synthetic_{n_data}/other/synthetic_{n_data}_likelihoods.csv', \n",
    "                                        index_col=0, header=0)\n",
    "monolix_rse_df = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                    f'simple/synthetic_{n_data}/other/synthetic_{n_data}_standard_errors.csv', \n",
    "                                        index_col=0, header=0)\n",
    "monolix_param_df = pd.read_csv(f'synthetic_results_monolix/model_analysis/projects/froehlich/'\n",
    "                                    f'simple/synthetic_{n_data}/other/synthetic_{n_data}_population_parameters.csv', \n",
    "                                        header=0)\n",
    "\n",
    "# compute confidence intervals and save them\n",
    "profile_list = result_simple.profile_result.list[0]\n",
    "profile_indices = [ix for ix, res in enumerate(profile_list) if res]\n",
    "\n",
    "intervals = []\n",
    "for i_par in range(result_simple.problem.dim_full):\n",
    "    if i_par not in profile_indices:\n",
    "        continue\n",
    "    xs = profile_list[i_par].x_path[i_par]\n",
    "    ratios = profile_list[i_par].ratio_path\n",
    "    lb_01, ub_01 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.99)\n",
    "    )\n",
    "    lb_05, ub_05 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.95)\n",
    "    )\n",
    "    lb_2, ub_2 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.80)\n",
    "    )\n",
    "    if i_par < simple_model.n_params:\n",
    "        intervals.append((lb_2, lb_05, lb_01, ub_01, ub_05, ub_2))\n",
    "    else:\n",
    "        intervals.append((np.exp(-ub_2), np.exp(-ub_05), np.exp(-ub_01), np.exp(-lb_01), np.exp(-lb_05), np.exp(-lb_2)))\n",
    "intervals = np.array(intervals)\n",
    "\n",
    "# other mode\n",
    "intervals = intervals[[1, 0, 2, 3, 4, 5, 7, 6, 8, 9, 10]]\n",
    "\n",
    "# prepare monolix results\n",
    "n_runs = len(monolix_likelihood[\"run\"])\n",
    "monolix_intervals = np.zeros((n_runs, 11, 6))\n",
    "reorder_monolix_index = [1, 2, 3, 4, 10, 0, 5, 6, 7, 8, 9]  # to match the order of the model\n",
    "monolix_names = {\"a\": 5, \"delta_pop\": 0,\"gamma_pop\": 1,\"km0scale_pop\": 2,\"offset_pop\": 4,\"omega_delta\": 6,\n",
    "                 \"omega_gamma\": 7, \"omega_km0scale\": 8, \"omega_offset\": 10, \"omega_tBegin\": 9, \"tBegin_pop\": 3}\n",
    "reorder_monolix_index = sorted(monolix_names, key=monolix_names.get)\n",
    "print(reorder_monolix_index)\n",
    "for r_idx, monolix_run in enumerate(monolix_likelihood[\"run\"]):\n",
    "    # get relative standard error\n",
    "    monolix_rse = monolix_rse_df[f'run_{monolix_run}']\n",
    "    monolix_rse = monolix_rse[reorder_monolix_index].values.flatten()\n",
    "    # get estimated parameters\n",
    "    monolix_param = monolix_param_df[monolix_param_df['run'] == monolix_run]\n",
    "    # reorder parameters as in the model\n",
    "    monolix_param = monolix_param[reorder_monolix_index].values.flatten()\n",
    "    # we need standard errors, (relative standard error = se divided by the estimated parameter value * 100 [%] )\n",
    "    monolix_se = monolix_param * (monolix_rse / 100)\n",
    "    # calculate confidence intervals\n",
    "    monolix_ub_01 = monolix_param + 2.576 * monolix_se\n",
    "    monolix_ub_05 = monolix_param + 1.96 * monolix_se\n",
    "    monolix_ub_2 = monolix_param + 1.282 * monolix_se\n",
    "    monolix_ub_01[monolix_names[\"a\"]] = np.log(monolix_ub_01[monolix_names[\"a\"]])  # sigma population value is not log-transformed in monolix\n",
    "    monolix_ub_05[monolix_names[\"a\"]] = np.log(monolix_ub_05[monolix_names[\"a\"]])\n",
    "    monolix_ub_2[monolix_names[\"a\"]] = np.log(monolix_ub_2[monolix_names[\"a\"]])\n",
    "    monolix_lb_01 = monolix_param - 2.576 * monolix_se\n",
    "    monolix_lb_05 = monolix_param - 1.96 * monolix_se\n",
    "    monolix_lb_2 = monolix_param - 1.282 * monolix_se\n",
    "    monolix_lb_01[monolix_names[\"a\"]] = np.log(monolix_lb_01[monolix_names[\"a\"]])  \n",
    "    monolix_lb_05[monolix_names[\"a\"]] = np.log(monolix_lb_05[monolix_names[\"a\"]])\n",
    "    monolix_lb_2[monolix_names[\"a\"]] = np.log(monolix_lb_2[monolix_names[\"a\"]])\n",
    "    # save confidence intervals\n",
    "    monolix_intervals[r_idx] = np.array([monolix_lb_2, monolix_lb_05, monolix_lb_01,\n",
    "                                         monolix_ub_01, monolix_ub_05, monolix_ub_2]).T\n",
    "\n",
    "# plot population medians instead of log-means\n",
    "transformed_monolix_intervals = np.concatenate((np.exp(monolix_intervals[:, :simple_model.n_params]),\n",
    "                                                monolix_intervals[:, simple_model.n_params:]), axis=1)\n",
    "transformed_intervals = np.concatenate((np.exp(intervals[:simple_model.n_params]),\n",
    "                                                intervals[simple_model.n_params:]))\n",
    "transformed_true_params = np.concatenate((np.exp(true_sample_params[:simple_model.n_params]),\n",
    "                                          true_sample_params[simple_model.n_params:]))\n",
    "\n",
    "\n",
    "# analyse coverage of monolix\n",
    "coverage_perc = np.zeros(n_opt_param - 1)\n",
    "for run_idx in range(n_runs):\n",
    "    monolix_lb = transformed_monolix_intervals[run_idx, :, 1]\n",
    "    monolix_ub = transformed_monolix_intervals[run_idx, :, 4]\n",
    "    for p_idx, (ci_l, ci_u) in enumerate(zip(monolix_lb, monolix_ub)):\n",
    "        if ci_l <= transformed_true_params[p_idx] <= ci_u:\n",
    "            coverage_perc[p_idx] += 1\n",
    "coverage_perc /= n_runs\n",
    "print('Monolix')\n",
    "print(pd.DataFrame(np.array([param_names_plot[:-1], (coverage_perc * 100).round(2)]).T,\n",
    "                   columns=['Parameter', 'Coverage [%]']))\n",
    "\n",
    "coverage_perc = np.zeros(n_opt_param - 1)\n",
    "amortized_lb = transformed_intervals[:, 1]\n",
    "amortized_ub = transformed_intervals[:, 4]\n",
    "for p_idx, (ci_l, ci_u) in enumerate(zip(amortized_lb, amortized_ub)):\n",
    "    if ci_l <= transformed_true_params[p_idx] <= ci_u:\n",
    "        coverage_perc[p_idx] += 1\n",
    "print('Amortized')\n",
    "print(pd.DataFrame(np.array([param_names_plot[:-1], (coverage_perc * 100).round(2)]).T,\n",
    "                   columns=['Parameter', 'Coverage [%]']))\n",
    "\n",
    "\n",
    "def plot_intervals(median, cis,\n",
    "                   ax=None, alpha_median=0.3,\n",
    "                   par_names: list = None,\n",
    "                   levels: list = [0.05, 0.95],\n",
    "                   offset: float = 0,\n",
    "                   color: str = None):\n",
    "    for i_par, par in enumerate(par_names):\n",
    "        for i_c, confidence in reversed(list(enumerate(levels))):\n",
    "            ax.hlines(i_par + offset,\n",
    "                      cis[i_par, i_c],\n",
    "                      cis[i_par, -1 - i_c],\n",
    "                      linewidth=8 / len(levels) * (len(levels) - i_c),\n",
    "                      alpha=1 / len(levels) * (len(levels) - i_c),\n",
    "                      color=color)\n",
    "            ax.vlines(median[i_par], offset + i_par - 0.15, offset + i_par + 0.15, color=\"black\", \n",
    "                      alpha=alpha_median)\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    for i_par, par in enumerate(par_names[:-1]):\n",
    "        ax.hlines(i_par + 0.5, xmin, xmax, color=\"black\", linewidth=1, linestyle=\"dashed\", alpha=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lower_bound, upper_bound = create_boundaries_from_prior(\n",
    "        prior_mean=simple_model.prior_mean,\n",
    "        prior_std=simple_model.prior_std,\n",
    "        boundary_width_from_prior=2.58,  # 99% of the prior mass is within 2.58 standard deviations\n",
    "        covariance_format='diag',\n",
    "        prior_type='normal'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_real_simple = read_from_hdf5.read_result(f'../Experiments/real_data/fröhlich-simple_cholesky.hdf5')\n",
    "result_real_sde = read_from_hdf5.read_result(f'../Experiments/real_data/fröhlich-sde_cholesky.hdf5')\n",
    "\n",
    "result_real_simple = result_real_simple.optimize_result.x[0]\n",
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=simple_model.name, prior_mean=simple_model.prior_mean,\n",
    "                                          prior_std=simple_model.prior_std,\n",
    "                                          covariance_format='cholesky')\n",
    "\n",
    "estimated_beta, psi_inverse, _, _ = obj_fun_amortized.get_params(result_real_simple)\n",
    "estimated_psi = np.linalg.inv(psi_inverse)\n",
    "estimated_var = estimated_psi.diagonal()\n",
    "estimated_corr = estimated_psi[np.tril_indices(obj_fun_amortized.param_dim, k=-1)]\n",
    "result_real_simple = np.concatenate((estimated_beta, estimated_var, estimated_corr))\n",
    "\n",
    "# switch to other mode\n",
    "results_simple_new = result_real_simple.copy()\n",
    "results_simple_new[0] = result_real_simple[1]\n",
    "results_simple_new[1] = result_real_simple[0]\n",
    "results_simple_new[6] = result_real_simple[7]\n",
    "results_simple_new[7] = result_real_simple[6]\n",
    "result_real_simple = results_simple_new\n",
    "\n",
    "result_real_sde = result_real_sde.optimize_result.x[0]\n",
    "obj_fun_amortized_sde = ObjectiveFunctionNLME(model_name=sde_model.name, prior_mean=sde_model.prior_mean,\n",
    "                                              prior_std=sde_model.prior_std,\n",
    "                                              covariance_format='cholesky')\n",
    "estimated_beta, psi_inverse, _, _ = obj_fun_amortized_sde.get_params(result_real_sde)\n",
    "estimated_psi = np.linalg.inv(psi_inverse)\n",
    "estimated_var = estimated_psi.diagonal()\n",
    "estimated_corr = estimated_psi[np.tril_indices(obj_fun_amortized_sde.param_dim, k=-1)]\n",
    "result_real_sde = np.concatenate((estimated_beta, estimated_var, estimated_corr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_real_detailed = read_from_hdf5.read_result('../Experiments/real_data/fröhlich-detailed_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_real_detailed.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_real_detailed = result_real_detailed.optimize_result.as_dataframe()['x'][0][param_idx_egfp]\n",
    "\n",
    "estimated_beta_detailed_diag = result_real_detailed[:11]\n",
    "estimated_psi_detailed_diag = get_covariance(result_real_detailed[11:], covariance_format='diag', param_dim=11)\n",
    "\n",
    "result_detailed_with_corr = read_from_hdf5.read_result('../Experiments/real_data/fröhlich-detailed_cholesky.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_detailed_with_corr.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_detailed_with_corr = result_detailed_with_corr.optimize_result.as_dataframe()['x'][0][param_idx_egfp]\n",
    "\n",
    "estimated_beta_detailed_cholesky = result_detailed_with_corr[:11]\n",
    "estimated_psi_detailed_cholesky = get_covariance(result_detailed_with_corr[11:], covariance_format='cholesky', param_dim=11)\n",
    "\n",
    "np.random.seed(42)\n",
    "# sample from log normal distribution\n",
    "n_trajectories = len(single_real_data)\n",
    "reproduced_param_diag = np.random.multivariate_normal(estimated_beta_detailed_diag,\n",
    "                                                     estimated_psi_detailed_diag,\n",
    "                                                     size=n_trajectories)\n",
    "reproduced_param_cholesky = np.random.multivariate_normal(estimated_beta_detailed_cholesky,\n",
    "                                                        estimated_psi_detailed_cholesky,\n",
    "                                                        size=n_trajectories)\n",
    "\n",
    "reproduced_data_diag = simulator_detailed(reproduced_param_diag, with_noise=False)\n",
    "reproduced_data_cholesky = simulator_detailed(reproduced_param_cholesky, with_noise=False)\n",
    "\n",
    "pop_spread_lower_no_corr = np.mean(reproduced_data_diag, axis=0) +  2.576 * np.std(reproduced_data_diag, axis=0) \n",
    "pop_spread_upper_no_corr = np.mean(reproduced_data_diag, axis=0) -  2.576 * np.std(reproduced_data_diag, axis=0)\n",
    "pop_spread_upper_corr = np.mean(reproduced_data_cholesky, axis=0) +  2.576 * np.std(reproduced_data_cholesky, axis=0)\n",
    "pop_spread_lower_corr = np.mean(reproduced_data_cholesky, axis=0) -  2.576 * np.std(reproduced_data_cholesky, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "param_samples = detailed_model.draw_posterior_samples(data=single_real_data, n_samples=100)\n",
    "param_median = np.median(param_samples, axis=1)\n",
    "names = ['$\\\\mathbf{\\\\phi}_' + '{'+ str(i) + '}$' for i in range(detailed_model.n_params)] \n",
    "median_df = pd.DataFrame(param_median, columns=names)\n",
    "corr_df = median_df.corr()\n",
    "#corrplot(corr_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_total = plt.figure(figsize=(16,6))\n",
    "grid = plt.GridSpec(3, 2, figure=fig_total, width_ratios=[1,1], height_ratios=[1, 0.15, 0.8])\n",
    "ax1 = fig_total.add_subplot(grid[0, 1])\n",
    "ax2 = fig_total.add_subplot(grid[2, 0])\n",
    "ax3 = fig_total.add_subplot(grid[0, 0])\n",
    "ax4 = fig_total.add_subplot(grid[2, 1])\n",
    "\n",
    "\n",
    "###################### # Correlation Plot\n",
    "#ax1.set_title('Parameter Correlation in Detailed NLME Model')\n",
    "\n",
    "corrplot(corr_df, square=False, ax=ax1)\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax1.set_title('')\n",
    "ax1.set_ylabel('Correlation Coefficient', rotation=270, labelpad=100)\n",
    "\n",
    "###################### population fit (no corr, corr)\n",
    "# plot real synthetic data vs estimated data\n",
    "colors_corr = [colors[4], sns.diverging_palette(220, 20, n=220)[-1]]\n",
    "\n",
    "t_points = np.linspace(start=1 / 6, stop=30, num=real_single_cell.shape[1], endpoint=True)\n",
    "for cell in single_real_data:\n",
    "    ax2.plot(t_points, np.exp(cell), '-', color='grey', alpha=0.2, label='data')\n",
    "\n",
    "ax2.plot(t_points, np.exp(pop_spread_lower_no_corr.flatten()), '-', color=colors_corr[0])\n",
    "ax2.plot(t_points, np.exp(pop_spread_upper_no_corr.flatten()), '-', color=colors_corr[0])\n",
    "\n",
    "ax2.plot(t_points, np.exp(pop_spread_lower_corr.flatten()), '-', color=colors_corr[1])\n",
    "ax2.plot(t_points, np.exp(pop_spread_upper_corr.flatten()), '-', color=colors_corr[1])\n",
    "\n",
    "\n",
    "ax2.plot(t_points, np.exp(real_mean), '--', color='black', label='mean')\n",
    "ax2.plot(t_points, np.exp(np.mean(reproduced_data_diag, axis=0)), '--', color=colors_corr[0],\n",
    "         label='without correlation')\n",
    "ax2.plot(t_points, np.exp(np.mean(reproduced_data_cholesky, axis=0)), '--', color=colors_corr[1],\n",
    "         label='with correlation')\n",
    "\n",
    "no_corr_patch = mpatches.Patch(color=colors_corr[0], label='model without correlation')\n",
    "corr_patch = mpatches.Patch(color=colors_corr[1], label='model with correlation')\n",
    "mean, = plt.plot([], [], '--', color='black', label='mean')\n",
    "data_label = mpatches.Patch(color='grey', label='real data')\n",
    "ax2.legend(handles=[no_corr_patch, corr_patch, data_label, mean], ncol=2,\n",
    "           loc='lower center', bbox_to_anchor=(0.5, -0.9))\n",
    "ax2.set_yscale('log')\n",
    "#ax2.set_title('Fitting Correlation in Detailed NLME Model')\n",
    "ax2.set_xlabel('Time (in hours)')\n",
    "ax2.set_ylabel('Measurements')\n",
    "\n",
    "###################### Scalability\n",
    "#ax3.set_title('Inference Time')\n",
    "\n",
    "### Time on Synthetic Data\n",
    "ax3.hlines(6.11, xmin=test_n_cells[0], xmax=test_n_cells[-1], color=colors[0], alpha=0.5)\n",
    "ax3.hlines(11.74, xmin=test_n_cells[0], xmax=test_n_cells[-1], color=colors[4], alpha=0.5)\n",
    "ax3.annotate('Average training time of Neural Posterior Estimator', xy=(75, 15), fontsize=11, color='black')\n",
    "\n",
    "for j, n_samples_opt in enumerate([10, 50, 100, 250]):\n",
    "    if n_samples_opt != 100: continue\n",
    "    ax3.errorbar(test_n_cells, np.median(simple_model_time_opt[:, j], axis=-1), np.std(simple_model_time_opt[:, j], axis=-1), \n",
    "                 color=colors[0], marker='x', capsize=3)\n",
    "for j, n_samples_opt in enumerate([10, 50, 100]):\n",
    "    if n_samples_opt != 100: continue\n",
    "    ax3.errorbar(test_n_cells, np.median(detailed_model_time_opt[:, j], axis=-1), np.std(detailed_model_time_opt[:, j], axis=-1), \n",
    "                 color=colors[4], marker='x', capsize=3)\n",
    "ax3.errorbar(test_n_cells, simple_model_timing_monolix, simple_model_timing_monolix_std, color=colors[0],\n",
    "                    marker='x', linestyle='--', capsize=3)\n",
    "ax3.errorbar(test_n_cells, detailed_model_timing_monolix, detailed_model_timing_monolix_std, color=colors[4],\n",
    "                    marker='^', linestyle='--', capsize=3, markersize=3)\n",
    "\n",
    "ax3.set_ylabel('Inference time/start\\n(in hours)')\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_xlabel('Number of cells $N$')\n",
    "ax3.set_xticks(ticks=test_n_cells, labels=test_n_cells)\n",
    "ax3.set_ylim((1e-7,100))\n",
    "\n",
    "amortized = ax4.errorbar([], [], [], color='black', linestyle= '-', marker='x', capsize=3, label='amortized approach')\n",
    "baseline = ax4.errorbar([], [], [], color='black', linestyle='--', marker='^', capsize=3, label='baseline (SAEM)')\n",
    "small_patch = mpatches.Patch(color=colors[0], label='simple model')\n",
    "large_patch = mpatches.Patch(color=colors[4], label='detailed model')\n",
    "ax3.legend(handles=[baseline, amortized, small_patch, large_patch, ], ncols=2, loc='lower right')\n",
    "\n",
    "\n",
    "###################### Uncertainty\n",
    "#ax4.set_title('Confidence Intervals for Simple NLME Model')\n",
    "\n",
    "offset = 0.2\n",
    "# plot boundaries\n",
    "for i in range(n_opt_param - 1):\n",
    "    ax4.fill_betweenx([i - offset, i + offset], np.exp(lower_bound[i]), np.exp(upper_bound[i]),\n",
    "                      color='grey', alpha=0.2)\n",
    "\n",
    "plot_intervals(np.median(transformed_monolix_intervals[0], axis=1),\n",
    "               transformed_monolix_intervals[0],\n",
    "               ax=ax4,\n",
    "               alpha_median=0.5,\n",
    "               par_names=param_names_plot[:-1],\n",
    "               levels=[0.2, 0.05, 0.01, 0.99, 0.95, 0.8],\n",
    "               offset=-offset,\n",
    "               color=colors[3])\n",
    "plot_intervals(np.median(transformed_intervals, axis=1),\n",
    "               transformed_intervals,\n",
    "               ax=ax4, alpha_median=0.5,\n",
    "               par_names=param_names_plot[:-1],\n",
    "               levels=[0.2, 0.05, 0.01, 0.99, 0.95, 0.8],\n",
    "               offset=offset,\n",
    "               color=colors[0])\n",
    "\n",
    "ax4.scatter(transformed_true_params[:-1], np.arange(n_opt_param - 1),\n",
    "           c='black', marker='x', label='True Parameters', zorder=2)\n",
    "plot_param_names = [r'$\\mathbf{\\beta}_{' + f'{i}' + r'}$' for i in range(6)] + [r'$\\mathbf{\\Psi}_{' + f'{i}{i}' + r'}$' for i in range(5)]\n",
    "ax4.set_yticks([], [])\n",
    "ax4.set_xlabel('Parameter Value')\n",
    "ax4.set_xscale('log')\n",
    "\n",
    "true_params, = ax4.plot([], [], 'x', color='black', label='true parameters')  # not visible\n",
    "baseline = mpatches.Patch(color=colors[3], label='baseline (SAEM)')\n",
    "amortized = mpatches.Patch(color=colors[0], label='amortized approach')\n",
    "prior_range = mpatches.Patch(color='grey', alpha=0.2, label='99\\% prior bound')\n",
    "ax4.legend(handles=[amortized, baseline, true_params, prior_range], loc='lower center',\n",
    "           bbox_to_anchor=(0.5, -0.9), ncols=2)\n",
    "\n",
    "# more comprehensive y labels\n",
    "plt.text(-0.1, 0.5, 'log-normal distribution', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax4.transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.05, 0.8, 'variance', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax4.transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.05, 0.25, 'median', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax4.transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.07, 0.54, '---', horizontalalignment='left',\n",
    "     verticalalignment='center', transform=ax4.transAxes)\n",
    "\n",
    "ax1.text(-0.2, 1.1, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax1.transAxes, fontsize=22)\n",
    "ax2.text(-0.17, 1.1, '\\\\bf{C}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax2.transAxes, fontsize=22)\n",
    "ax3.text(-0.17, 1.1, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax3.transAxes, fontsize=22)\n",
    "ax4.text(-0.15, 1.1, '\\\\bf{D}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax4.transAxes, fontsize=22)\n",
    "#plt.savefig('../plots/paper/results_plot2.pdf', format='pdf', bbox_inches='tight',\n",
    "#            dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Uncertainty Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_names = detailed_model.param_names.copy()\n",
    "pop_param_names = ['median-' + name for name in param_names]\n",
    "var_param_names = ['var-' + name for name in param_names]\n",
    "param_names_plot_large = param_names + param_names\n",
    "\n",
    "n_data = 500\n",
    "true_sample_params = detailed_model.load_synthetic_parameter(n_data)\n",
    "result_optimization = read_from_hdf5.read_result(f'../Experiments/synthetic_results_amortized/uncertainty_fröhlich-detailed_cells_{n_data}_samples_100.hdf5')\n",
    "\n",
    "# compute confidence intervals and save them\n",
    "profile_list = result_optimization.profile_result.list[0]\n",
    "profile_indices = [ix for ix, res in enumerate(profile_list) if res]\n",
    "\n",
    "intervals_large = []\n",
    "for i_par in range(result_optimization.problem.dim_full):\n",
    "    if i_par not in profile_indices:\n",
    "        continue\n",
    "    xs = profile_list[i_par].x_path[i_par]\n",
    "    ratios = profile_list[i_par].ratio_path\n",
    "    lb_01, ub_01 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.99)\n",
    "    )\n",
    "    lb_05, ub_05 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.95)\n",
    "    )\n",
    "    lb_2, ub_2 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.80)\n",
    "    )\n",
    "    if i_par < detailed_model.n_params:\n",
    "        intervals_large.append((lb_2, lb_05, lb_01, ub_01, ub_05, ub_2))\n",
    "    else:\n",
    "        intervals_large.append((np.exp(-ub_2), np.exp(-ub_05), np.exp(-ub_01), np.exp(-lb_01), np.exp(-lb_05), np.exp(-lb_2)))\n",
    "intervals_large = np.array(intervals_large)\n",
    "\n",
    "transformed_intervals_large = np.concatenate((np.exp(intervals_large[:detailed_model.n_params]),\n",
    "                                                intervals_large[detailed_model.n_params:]))\n",
    "transformed_true_params_large = np.concatenate((np.exp(true_sample_params[:detailed_model.n_params]),\n",
    "                                          true_sample_params[detailed_model.n_params:]))\n",
    "\n",
    "lower_bound_large, upper_bound_large = create_boundaries_from_prior(\n",
    "        prior_mean=detailed_model.prior_mean,\n",
    "        prior_std=detailed_model.prior_std,\n",
    "        boundary_width_from_prior=2.58,  # 99% of the prior mass is within 2.58 standard deviations\n",
    "        covariance_format='diag',\n",
    "        prior_type='normal'\n",
    ")\n",
    "\n",
    "## sde model\n",
    "from models.froehlich_model_sde import FroehlichModelSDE\n",
    "model_sde = FroehlichModelSDE(load_best=True)\n",
    "param_names = model_sde.param_names.copy()\n",
    "#param_names[2] = 'scale'\n",
    "pop_param_names = ['median-' + name for name in param_names]\n",
    "var_param_names = ['var-' + name for name in param_names]\n",
    "param_names_plot_sde = param_names + param_names\n",
    "\n",
    "true_sample_params = model_sde.load_synthetic_parameter(n_data)\n",
    "result_optimization = read_from_hdf5.read_result(f'../Experiments/synthetic_results_amortized/uncertainty_fröhlich-sde_cells_{n_data}_samples_100.hdf5')\n",
    "\n",
    "# compute confidence intervals and save them\n",
    "profile_list = result_optimization.profile_result.list[0]\n",
    "profile_indices = [ix for ix, res in enumerate(profile_list) if res]\n",
    "\n",
    "intervals_sde = []\n",
    "for i_par in range(result_optimization.problem.dim_full):\n",
    "    if i_par not in profile_indices:\n",
    "        continue\n",
    "    xs = profile_list[i_par].x_path[i_par]\n",
    "    ratios = profile_list[i_par].ratio_path\n",
    "    lb_01, ub_01 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.99)\n",
    "    )\n",
    "    lb_05, ub_05 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.95)\n",
    "    )\n",
    "    lb_2, ub_2 = profile.calculate_approximate_ci(\n",
    "        xs=xs, ratios=ratios, confidence_ratio=profile.chi2_quantile_to_ratio(0.80)\n",
    "    )\n",
    "    if i_par < model_sde.n_params:\n",
    "        intervals_sde.append((lb_2, lb_05, lb_01, ub_01, ub_05, ub_2))\n",
    "    else:\n",
    "        intervals_sde.append((np.exp(-ub_2), np.exp(-ub_05), np.exp(-ub_01), np.exp(-lb_01), np.exp(-lb_05), np.exp(-lb_2)))\n",
    "intervals_sde = np.array(intervals_sde)\n",
    "\n",
    "transformed_intervals_sde = np.concatenate((np.exp(intervals_sde[:model_sde.n_params]),\n",
    "                                                intervals_sde[model_sde.n_params:]))\n",
    "transformed_true_params_sde = np.concatenate((np.exp(true_sample_params[:simple_model.n_params]),\n",
    "                                          true_sample_params[simple_model.n_params:]))\n",
    "\n",
    "lower_bound_sde, upper_bound_sde = create_boundaries_from_prior(\n",
    "        prior_mean=model_sde.prior_mean,\n",
    "        prior_std=model_sde.prior_std,\n",
    "        boundary_width_from_prior=2.58,  # 99% of the prior mass is within 2.58 standard deviations\n",
    "        covariance_format='diag',\n",
    "        prior_type='normal'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 5))\n",
    "ax[0].set_title('Simple ODE Model')\n",
    "\n",
    "offset = 0.2\n",
    "\n",
    "# plot boundaries\n",
    "for i in range(simple_model.n_params * 2 - 1):\n",
    "    ax[0].fill_betweenx([i - offset, i + offset], np.exp(lower_bound[i]), np.exp(upper_bound[i]),\n",
    "                      color='grey', alpha=0.1)\n",
    "\n",
    "rearange_index = [1,0,2,3,4,5,7,6,8,9,10] # to avoid overlapping of labels\n",
    "plot_intervals(np.median(transformed_intervals, axis=1)[rearange_index],\n",
    "               transformed_intervals[rearange_index],\n",
    "               ax=ax[0],\n",
    "               alpha_median=0.3,\n",
    "               par_names=np.array(param_names_plot[:-1])[rearange_index],\n",
    "               levels=[0.2, 0.05, 0.01, 0.99, 0.95, 0.8],\n",
    "               offset=-offset,\n",
    "               color=colors[0])\n",
    "\n",
    "ax[0].scatter(transformed_true_params[:-1][rearange_index], np.arange(simple_model.n_params * 2 - 1),\n",
    "           c='black', marker='x', label='True Parameters')\n",
    "ax[0].set_yticks([],[])\n",
    "ax[0].set_xlabel('Parameter Value')\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "ax[1].set_title('Detailed ODE Model')\n",
    "for i in range(detailed_model.n_params * 2 - 1):\n",
    "    ax[1].fill_betweenx([i - offset, i + offset], np.exp(lower_bound_large[i]), np.exp(upper_bound_large[i]),\n",
    "                      color='grey', alpha=0.1)\n",
    "plot_intervals(np.median(transformed_intervals_large, axis=1),\n",
    "               transformed_intervals_large,\n",
    "               ax=ax[1],\n",
    "               alpha_median=0.3,\n",
    "               par_names=param_names_plot_large[:-1],\n",
    "               levels=[0.2, 0.05, 0.01, 0.99, 0.95, 0.8],\n",
    "               offset=-offset,\n",
    "               color=colors[0])\n",
    "\n",
    "\n",
    "ax[1].scatter(transformed_true_params_large[:-1], np.arange(detailed_model.n_params * 2 - 1),\n",
    "           c='black', marker='x', label='True Parameters')\n",
    "ax[1].set_yticks([],[])\n",
    "ax[1].set_xlabel('Parameter Value')\n",
    "ax[1].set_xscale('log')\n",
    "\n",
    "\n",
    "ax[2].set_title('SDE Model')\n",
    "for i in range(model_sde.n_params * 2 - 1):\n",
    "    ax[2].fill_betweenx([i - offset, i + offset], np.exp(lower_bound_sde[i]), np.exp(upper_bound_sde[i]),\n",
    "                      color='grey', alpha=0.1)\n",
    "plot_intervals(np.median(transformed_intervals_sde, axis=1),\n",
    "               transformed_intervals_sde,\n",
    "               ax=ax[2],\n",
    "               alpha_median=0.3,\n",
    "               par_names=param_names_plot_sde[:-1],\n",
    "               levels=[0.2, 0.05, 0.01, 0.99, 0.95, 0.8],\n",
    "               offset=-offset,\n",
    "               color=colors[0])\n",
    "\n",
    "ax[2].scatter(transformed_true_params_sde[:-1], np.arange(model_sde.n_params * 2 - 1),\n",
    "           c='black', marker='x', label='True Parameters')\n",
    "ax[2].set_yticks([],[])\n",
    "ax[2].set_xlabel('Parameter Value')\n",
    "ax[2].set_xscale('log')\n",
    "\n",
    "\n",
    "true_params, = ax[0].plot([], [], 'x', color='black', label='True Parameters')  # not visible\n",
    "amortized = mpatches.Patch(color=colors[0], label='Confidence Intervals (80\\%, 95\\%, 99\\%)')\n",
    "prior_range = mpatches.Patch(color='grey', alpha=0.1, label='99\\% Prior Bound')\n",
    "\n",
    "lgd = fig.legend(handles=[amortized, prior_range, true_params],\n",
    "            loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.18))\n",
    "\n",
    "# more comprehensive y labels\n",
    "plt.text(-0.25, 0.5, 'log-normal distribution', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax[0].transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.1, 0.75, 'variance', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax[0].transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.1, 0.25, 'median', horizontalalignment='center',\n",
    "     verticalalignment='center', transform=ax[0].transAxes, rotation=90, fontsize='small')\n",
    "plt.text(-0.2, 0.56, '-----', horizontalalignment='left',\n",
    "     verticalalignment='center', transform=ax[0].transAxes)\n",
    "\n",
    "\n",
    "ax[0].text(-0.25, 1.1, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[0].transAxes, fontsize=22)\n",
    "ax[1].text(-0.1, 1.1, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[1].transAxes, fontsize=22)\n",
    "ax[2].text(-0.1, 1.1, '\\\\bf{C}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[2].transAxes, fontsize=22)\n",
    "\n",
    "#plt.savefig('../plots/paper/uncertainty_cell_models.pdf', format='pdf', pad_inches=1,\n",
    "#            bbox_inches='tight', bbox_extra_artists=(lgd,), dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze SDE model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obs_data = sde_model.load_data(load_egfp=True, load_d2egfp=False)\n",
    "data = obs_data[5, :][np.newaxis, :]\n",
    "param_samples = sde_model.draw_posterior_samples(data=data, n_samples=1000)\n",
    "\n",
    "syn_sim = simulator_sde(param_samples)\n",
    "# compute mean and 95% credible region\n",
    "syn_median = np.median(syn_sim, axis=0)\n",
    "syn_perc = np.percentile(syn_sim.reshape(syn_sim.shape[0], 180), (5, 95), axis=0)\n",
    "\n",
    "# compute simulations from median made only by model\n",
    "param_median = np.median(param_samples, axis=0)[np.newaxis]\n",
    "param_samples_median = np.repeat(param_median, 1000, axis=0)\n",
    "simulation_median = simulator_sde(param_samples_median)\n",
    "\n",
    "t_points = np.linspace(start=1 / 6, stop=30, num=180, endpoint=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov_format = 'cholesky'\n",
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=simple_model.name,\n",
    "                                          prior_mean=simple_model.prior_mean,\n",
    "                                          prior_std=simple_model.prior_std,\n",
    "                                          covariance_format=cov_format)\n",
    "\n",
    "result_small = read_from_hdf5.read_result(f'../Experiments/multi-experiment/fröhlich-simple_{cov_format}.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_small.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_small = result_small.optimize_result.x[0][param_idx_egfp]\n",
    "estimated_beta, estimated_psi_inv, _, _ = obj_fun_amortized.get_params(result_small)\n",
    "estimated_psi = np.linalg.inv(estimated_psi_inv)\n",
    "\n",
    "obj_fun_amortized_sde = ObjectiveFunctionNLME(model_name=sde_model.name,\n",
    "                                          prior_mean=sde_model.prior_mean,\n",
    "                                          prior_std=sde_model.prior_std,\n",
    "                                          covariance_format=cov_format)\n",
    "result_sde = read_from_hdf5.read_result(f'../Experiments/multi-experiment/fröhlich-sde_{cov_format}.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(result_sde.problem.x_names) if 'd2eGFP' not in name]\n",
    "result_sde = result_sde.optimize_result.x[0][param_idx_egfp]\n",
    "estimated_beta_sde, estimated_psi_inv, _, _ = obj_fun_amortized_sde.get_params(result_sde)\n",
    "estimated_psi_sde = np.linalg.inv(estimated_psi_inv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4)) #, layout=\"tight\", )\n",
    "grid = plt.GridSpec(2, 3, figure=fig, wspace=0.3, hspace=0.5, width_ratios=[1,0.5,0.5])\n",
    "axis_joint = fig.add_subplot(grid[1, 2])\n",
    "axis_fit = fig.add_subplot(grid[:2, 0])\n",
    "zax = axis_fit.inset_axes([0.4, 0.2, 0.45, 0.45])\n",
    "\n",
    "axis_sde1 = fig.add_subplot(grid[0, 1], sharex=axis_joint, sharey=axis_joint)\n",
    "axis_sde2 = fig.add_subplot(grid[0, 2], sharex=axis_sde1, sharey=axis_sde1)\n",
    "axis_sde3 = fig.add_subplot(grid[1, 1], sharex=axis_sde2, sharey=axis_sde2)\n",
    "\n",
    "\n",
    "region = axis_fit.fill_between(t_points, np.exp(syn_perc[0, :]), np.exp(syn_perc[1, :]),\n",
    "                               color=colors[2], alpha=0.2, label=f'95\\% credible region')\n",
    "zax.fill_between(t_points, np.exp(syn_perc[0, :]), np.exp(syn_perc[1, :]),\n",
    "                 color=colors[2], alpha=0.2, label=f'95\\% credible region')\n",
    "\n",
    "for sim_i, sim in enumerate(simulation_median):\n",
    "    axis_fit.plot(t_points, np.exp(sim), alpha=0.5, c=colors[2])\n",
    "    zax.plot(t_points, np.exp(sim), alpha=0.5, c=colors[2])\n",
    "    if sim_i > 10:\n",
    "        break\n",
    "axis_fit.plot([], [], c='black', label=f'median')\n",
    "measurements = axis_fit.scatter(t_points, np.exp(data.flatten()), c='red', marker='o', label=f'single cell measurements')\n",
    "zax.scatter(t_points, np.exp(data.flatten()), c='red', marker='o')\n",
    "\n",
    "zax.set_yscale('log')\n",
    "zax.set_xlim(4,16)\n",
    "zax.set_ylim(8e2,2e3)\n",
    "zax.set_xticks([], labels=[])\n",
    "zax.set_yticks([], labels=[], minor=True)\n",
    "zax.set_yticks([])\n",
    "axis_fit.indicate_inset_zoom(zax, edgecolor=\"black\")\n",
    "\n",
    "axis_fit.set_xlabel('Time (in hours)')\n",
    "axis_fit.set_ylabel('Measurements')\n",
    "axis_fit.set_yscale('log')\n",
    "axis_fit.set_title('Cell-Specific Posterior Samples')\n",
    "\n",
    "\n",
    "index_params = [2,3,4]\n",
    "p_names = ['$k$', '$m_0$', '$scale$']\n",
    "for a_i, ax in enumerate([axis_sde1, axis_sde2, axis_sde3]):\n",
    "    xmax = estimated_beta_sde[index_params[a_i]] + 3* sde_model.prior_std[index_params[a_i]]\n",
    "    xmin = estimated_beta_sde[index_params[a_i]] - 3* sde_model.prior_std[index_params[a_i]]\n",
    "    x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "    # Create a log-normal distribution with the given parameters\n",
    "    norm_distr = norm(loc=estimated_beta_sde[index_params[a_i]],\n",
    "                      scale=np.sqrt(estimated_psi_sde.diagonal()[index_params[a_i]]))\n",
    "    ax.plot(np.exp(x), norm_distr.pdf(x), color=colors[2])\n",
    "    ax.set_xlabel(p_names[a_i])\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "joint_variance = estimated_psi_sde.diagonal()[2:5].sum()+2*estimated_psi_sde[2,3]+2*estimated_psi_sde[2,4]+2*estimated_psi_sde[3,4]\n",
    "x = np.linspace(np.log(1e-3), np.log(1e6), 10000)\n",
    "\n",
    "norm_distr_sde = norm(loc=estimated_beta_sde[2:5].sum(), scale=np.sqrt(joint_variance))\n",
    "sde, = axis_joint.plot(np.exp(x), norm_distr_sde.pdf(x), color=colors[2], label='SDE NLME model')\n",
    "\n",
    "norm_distr_ode = norm(loc=estimated_beta[2], scale=np.sqrt(estimated_psi.diagonal()[2]))\n",
    "ode, = axis_joint.plot(np.exp(x), norm_distr_ode.pdf(x), color=colors[0], label='simple ODE NLME model')\n",
    "\n",
    "axis_joint.set_xscale('log')\n",
    "axis_joint.set_xlabel('$k\\cdot m_0 \\cdot scale$')\n",
    "axis_sde1.set_ylabel('Density')\n",
    "#axis_sde2.set_ylabel('Density')\n",
    "axis_sde3.set_ylabel('Density')\n",
    "#axis_joint.set_ylabel('Density')\n",
    "axis_joint.set_xticks([1e-2, 1e2, 1e6])\n",
    "\n",
    "lgd = fig.legend(handles=[measurements, region, sde, ode],\n",
    "            loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.2))\n",
    "axis_sde1.set_title('{\\\\tiny .}\\qquad\\quad Distribution of Population Parameters', loc='left')\n",
    "\n",
    "axis_fit.text(-0.15, 1.085, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "              transform=axis_fit.transAxes, fontsize=22)\n",
    "axis_sde1.text(-0.3, 1.2, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "               transform=axis_sde1.transAxes, fontsize=22)\n",
    "\n",
    "#plt.savefig('../plots/paper/sde_analysis.pdf', format='pdf', bbox_inches='tight', pad_inches=0.26,\n",
    "#             bbox_extra_artists=(lgd,), dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare SDE and ODE model on synthetic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_data = 500\n",
    "sde_obs_data = sde_model.load_data(n_data=n_data, synthetic=True)\n",
    "\n",
    "obj_fun_amortized = ObjectiveFunctionNLME(model_name=simple_model.name,\n",
    "                                          prior_mean=simple_model.prior_mean,\n",
    "                                          prior_std=simple_model.prior_std,\n",
    "                                          covariance_format='diag')\n",
    "obj_fun_amortized_sde = ObjectiveFunctionNLME(model_name=sde_model.name,\n",
    "                                          prior_mean=sde_model.prior_mean,\n",
    "                                          prior_std=sde_model.prior_std,\n",
    "                                          covariance_format='diag')\n",
    "\n",
    "simple_result_sde = read_from_hdf5.read_result(f'../Experiments/sde_comparison/fröhlich-simple_{n_data}_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(simple_result_sde.problem.x_names) if 'd2eGFP' not in name]\n",
    "simple_result_sde = simple_result_sde.optimize_result.x[0][param_idx_egfp]\n",
    "\n",
    "estimated_beta, estimated_psi_inv, _, _ = obj_fun_amortized.get_params(simple_result_sde)\n",
    "estimated_psi = np.linalg.inv(estimated_psi_inv)\n",
    "\n",
    "sde_result_sde = read_from_hdf5.read_result(f'../Experiments/sde_comparison/fröhlich-sde_{n_data}_diag.hdf5')\n",
    "param_idx_egfp = [i_n for i_n, name in enumerate(sde_result_sde.problem.x_names) if 'd2eGFP' not in name]\n",
    "sde_result_sde = sde_result_sde.optimize_result.x[0][param_idx_egfp]\n",
    "\n",
    "estimated_beta_sde, estimated_psi_inv, _, _ = obj_fun_amortized_sde.get_params(sde_result_sde)\n",
    "estimated_psi_sde = np.linalg.inv(estimated_psi_inv)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_trajectories = len(sde_obs_data)\n",
    "reproduced_param_simple = np.random.multivariate_normal(estimated_beta,\n",
    "                                                     estimated_psi,\n",
    "                                                     size=n_trajectories*10)\n",
    "reproduced_param_sde = np.random.multivariate_normal(estimated_beta_sde,\n",
    "                                                        estimated_psi_sde,\n",
    "                                                        size=n_trajectories*10)\n",
    "\n",
    "reproduced_data_simple = simulator_simple(reproduced_param_simple, with_noise=False)\n",
    "reproduced_data_sde = simulator_sde(reproduced_param_sde, with_noise=False)\n",
    "\n",
    "real_mean = np.mean(sde_obs_data, axis=0)\n",
    "real_var = np.var(sde_obs_data, axis=0)\n",
    "dif_simple = np.mean(reproduced_data_simple, axis=0) - real_mean\n",
    "dif_var_simple = np.var(reproduced_data_simple, axis=0) - real_var\n",
    "std_simple = np.std(reproduced_data_simple, axis=0)\n",
    "\n",
    "dif_sde = np.mean(reproduced_data_sde, axis=0) - real_mean\n",
    "dif_var_sde = np.var(reproduced_data_sde, axis=0) - real_var\n",
    "std_sde = np.std(reproduced_data_sde, axis=0)\n",
    "\n",
    "t_value_05 = abs(t_dist.ppf(0.05 / reproduced_data_simple.shape[1], df=reproduced_data_simple.shape[0] - 1))\n",
    "\n",
    "confidence_band_upper = dif_simple + t_value_05 * std_simple / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_lower = dif_simple - t_value_05 * std_simple / np.sqrt(reproduced_data_simple.shape[0])\n",
    "confidence_band_upper_sde = dif_sde + t_value_05 * std_sde / np.sqrt(reproduced_data_sde.shape[0])\n",
    "confidence_band_lower_sde = dif_sde - t_value_05 * std_sde / np.sqrt(reproduced_data_sde.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 5), layout=\"tight\")\n",
    "# plot real synthetic data vs estimated data\n",
    "t_points = np.linspace(start=1 / 6, stop=30, num=single_real_data.shape[1], endpoint=True)\n",
    "\n",
    "ax[0].set_title('Single-Cell Data')\n",
    "for i, cell in enumerate(sde_obs_data):\n",
    "    if i > 100: break\n",
    "    ax[0].plot(t_points, np.exp(cell.flatten()), color='grey', alpha=0.5)\n",
    "ax[0].set_xlabel('Time (in hours)')\n",
    "ax[0].set_ylabel('Measurements')\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].fill_between(t_points, confidence_band_upper.flatten(), confidence_band_lower.flatten(),\n",
    "                         color=colors[0], alpha=0.5, label='ODE')\n",
    "ax[1].plot(t_points, dif_simple, color=colors[0])\n",
    "ax[1].plot(t_points, np.zeros(t_points.size), color='black', linestyle='--', alpha=0.25)\n",
    "ax[1].fill_between(t_points, confidence_band_upper_sde.flatten(), confidence_band_lower_sde.flatten(),\n",
    "                         color=colors[2], alpha=0.5, label='SDE')\n",
    "ax[1].plot(t_points, dif_sde, color=colors[2])\n",
    "\n",
    "ax[2].plot(t_points, dif_var_simple, color=colors[2])\n",
    "ax[2].plot(t_points, np.zeros(t_points.size), color='black', linestyle='--', alpha=0.25)\n",
    "ax[2].plot(t_points, dif_var_sde, color=colors[1])\n",
    "\n",
    "ax[1].set_title('Estimated Population Mean')\n",
    "ax[2].set_title('Estimated Population Variance')\n",
    "ax[1].set_ylabel('Difference to sample mean')\n",
    "ax[2].set_ylabel('Difference to sample variance')\n",
    "ax[1].set_xlabel('Time (in hours)')\n",
    "ax[2].set_xlabel('Time (in hours)')\n",
    "\n",
    "real_measurement = mpatches.Patch(color='grey', label='Single-cell data')\n",
    "ode_patch = mpatches.Patch(color=colors[0], label='Simple ODE model')\n",
    "sde_patch = mpatches.Patch(color=colors[2], label='SDE model')\n",
    "lgd = fig.legend(handles=[real_measurement, ode_patch, sde_patch],\n",
    "            loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "ax[0].text(-0.18, 1.1, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[0].transAxes, fontsize=22)\n",
    "ax[1].text(-0.25, 1.1, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[1].transAxes, fontsize=22)\n",
    "ax[2].text(-0.25, 1.1, '\\\\bf{C}', horizontalalignment='center', verticalalignment='center',\n",
    "           transform=ax[2].transAxes, fontsize=22)\n",
    "\n",
    "#plt.savefig('plots/sde_vs_ode.pdf', format='pdf', bbox_inches='tight',  pad_inches=0.2,\n",
    "#            bbox_extra_artists=(lgd,), dpi=600)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
