{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model\n",
    "\n",
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb930b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:11:29.181472Z",
     "start_time": "2023-11-09T18:11:27.442844Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde',\n",
    "              'pharmacokinetic_model', 'clairon_small_model'][-2]\n",
    "if model_name == 'fröhlich-detailed' or model_name == 'pharmacokinetic_model' or 'clairon' in model_name:\n",
    "    from juliacall import Main as jl  # needed for cluster to load julia\n",
    "\n",
    "# specify which model to use\n",
    "network_idx = 0\n",
    "load_best_network = False\n",
    "\n",
    "# load necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for plots\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# minor stuff\n",
    "from datetime import datetime\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c74e8a",
   "metadata": {},
   "source": [
    "load BayesFlow package (https://bayesflow.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de354ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:11:32.271722Z",
     "start_time": "2023-11-09T18:11:29.181968Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas.arruda/miniconda/envs/amortizedNLME/lib/python3.10/site-packages/bayesflow/trainers.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from bayesflow.simulation import GenerativeModel\n",
    "from bayesflow import diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adc6d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:11:32.271887Z",
     "start_time": "2023-11-09T18:11:32.268526Z"
    }
   },
   "outputs": [],
   "source": [
    "# example training\n",
    "max_epochs = 10\n",
    "iterations_per_epoch = 100\n",
    "# show or save plots\n",
    "show_plots = True\n",
    "    \n",
    "# training params\n",
    "early_stopping = False\n",
    "presimulate = False\n",
    "train_network = False\n",
    "batch_size = 128\n",
    "max_to_keep = 3  # standard 3, if all should be saved: set to max_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "## Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf260c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "presimulation_path = 'data/'\n",
    "\n",
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    model = FroehlichModelSimple(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "    use_presimulation = False\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    model = FroehlichModelDetailed(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_froehlich_large'\n",
    "\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    model = FroehlichModelSDE(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_froehlich_sde'\n",
    "    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    model = PharmacokineticModel(network_idx=network_idx, load_best=load_best_network)\n",
    "    \n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_pharma'\n",
    "    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    model = ClaironSmallModel(network_idx=network_idx, load_best=load_best_network)\n",
    "\n",
    "    use_presimulation = True\n",
    "    presimulation_path += 'presimulations_small_clairon'\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if show_plots:\n",
    "    model.print_and_plot_example()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f64b5b9e73dd23b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc975f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = model.network_name\n",
    "if network_name is None:\n",
    "    network_name = 'amortizer-' + str(datetime.now())\n",
    "print(network_name)\n",
    "\n",
    "path_store_network = 'networks/' + network_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if presimulate:\n",
    "    # sleep(int(job_array_id) % 200)  # so batch file does not get overwritten\n",
    "\n",
    "    generative_model = GenerativeModel(model.prior, model.build_simulator(),\n",
    "                                       simulator_is_batched=True,\n",
    "                                       prior_is_batched=True)\n",
    "    start_time = perf_counter()\n",
    "    np.random.seed(42)\n",
    "    generative_model.presimulate_and_save(batch_size, folder_path=presimulation_path,\n",
    "                                          iterations_per_epoch=iterations_per_epoch,\n",
    "                                          epochs=max_epochs,\n",
    "                                          disable_user_input=True)\n",
    "                                          # extend_from=int(job_array_id)*max_epochs)\n",
    "    end_time = perf_counter()\n",
    "    print(f'simulation time: {(end_time-start_time)/60} minutes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd61cc5af258596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generative_model = GenerativeModel(model.prior, model.build_simulator(),\n",
    "                                       simulator_is_batched=True,\n",
    "                                       prior_is_batched=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df470d63d4735641"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d45083fd2df63ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = model.build_trainer(path_store_network)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f26e0cc5ebc90932"
  },
  {
   "cell_type": "markdown",
   "source": [
    "each epoch a number of iterations each with batch_size many simulations is performed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8057db1e429a962c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = {}\n",
    "if True: #train_network and not use_presimulation:\n",
    "    # simulation is done whenever needed\n",
    "    start_time = perf_counter()\n",
    "    history = trainer.train_online(epochs=max_epochs,\n",
    "                                  iterations_per_epoch=iterations_per_epoch,\n",
    "                                  batch_size=batch_size,\n",
    "                                  early_stopping=early_stopping,\n",
    "                                  validation_sims=iterations_per_epoch)\n",
    "    end_time = perf_counter()\n",
    "    print(f'training time: {(end_time-start_time)/60} minutes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d096777fe7956c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_network and use_presimulation:\n",
    "    trainer._setup_optimizer(optimizer=None,\n",
    "                             epochs=max_epochs,\n",
    "                             iterations_per_epoch=iterations_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858bc0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if train_network and use_presimulation:\n",
    "    # simulation done before\n",
    "    start_time = perf_counter()\n",
    "    history = trainer.train_from_presimulation(presimulation_path=presimulation_path,\n",
    "                                                  optimizer=trainer.optimizer,\n",
    "                                                  max_epochs=max_epochs,\n",
    "                                                  early_stopping=early_stopping,\n",
    "                                                  validation_sims=iterations_per_epoch)\n",
    "\n",
    "    end_time = perf_counter()\n",
    "    print(f'training time: {(end_time-start_time)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9684cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load or save losses\n",
    "if train_network:\n",
    "    history['train_losses'].to_csv(f\"output/losses/{network_name}_train_losses.csv\")\n",
    "    history['val_losses'].to_csv(f\"output/losses/{network_name}_val_losses.csv\")\n",
    "else:\n",
    "    train_losses = pd.read_csv(f\"output/losses/{network_name}_train_losses.csv\", index_col=0)\n",
    "    val_losses = pd.read_csv(f\"output/losses/{network_name}_val_losses.csv\", index_col=0)\n",
    "    history = {'train_losses': train_losses,\n",
    "              'val_losses': val_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b15192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_losses = diagnostics.plot_losses(history['train_losses'], history['val_losses'])\n",
    "#fig_losses.savefig(f'plots/calibration/{network_name}_fig_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import convert_to_observables, batch_simulator\n",
    "    test_patients = model.load_data(25)\n",
    "    patients_posterior_draws = model.draw_posterior_samples(data=test_patients, n_samples=100)\n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import convert_output_to_simulation, batch_simulator\n",
    "    test_patients = model.load_data(n_data=25)\n",
    "    patients_posterior_draws = model.draw_posterior_samples(data=test_patients, n_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e273381deae9877"
  },
  {
   "cell_type": "raw",
   "source": [
    "np.random.seed(42)\n",
    "prior_bounds = model.prior_bounds\n",
    "prior_bounds[1:3, 1] = 5\n",
    "print(prior_bounds)\n",
    "params = np.random.uniform(low=prior_bounds[:, 0], high=prior_bounds[:, 1],\n",
    "                                    size=(20, prior_bounds.shape[0]))\n",
    "params[:, -2:] = model.prior_mean[-2:] - 1\n",
    "test_patients = batch_simulator(param_batch=params)\n",
    "patients_posterior_draws = model.draw_posterior_samples(data=test_patients, n_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0e6103b516fad0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'pharmacokinetic_model' == model_name:\n",
    "    rows = 5\n",
    "    fig, ax = plt.subplots(rows, int(np.ceil(len(test_patients) / rows)),# sharey='all',\n",
    "                           tight_layout=True, figsize=(10, rows*3))\n",
    "    axis = ax.flatten()\n",
    "    \n",
    "    \n",
    "    for p_id in tqdm(range(len(test_patients))):\n",
    "        y, doses_time_points, DOS, wt = convert_output_to_simulation(test_patients[p_id])\n",
    "        t_measurements = np.linspace(0, y[-1, -1]+100, 100)\n",
    "        sim_data = batch_simulator(patients_posterior_draws[p_id],\n",
    "                             wt=wt,\n",
    "                             DOS=DOS,\n",
    "                             t_measurement=t_measurements,\n",
    "                             t_doses=doses_time_points,\n",
    "                             with_noise=False)\n",
    "        \n",
    "        y1_full = []\n",
    "        y2_full = []\n",
    "        for s in sim_data:\n",
    "            y, _, _, _ = convert_output_to_simulation(s)\n",
    "            y1_full.append(y[:, 0])\n",
    "            y2_full.append(y[:, 1])\n",
    "\n",
    "        axis[p_id].fill_between(t_measurements, np.percentile(y1_full, 2.5, axis=0), \n",
    "                                np.percentile(y1_full, 97.5, axis=0), \n",
    "                                alpha=0.2, color='orange')\n",
    "        axis[p_id].plot(t_measurements, np.median(y1_full, axis=0), 'orange')\n",
    "        y, _, _, _ = convert_output_to_simulation(test_patients[p_id])\n",
    "        axis[p_id].scatter(y[:, -1], y[:, 0], color='orange')\n",
    "        \n",
    "        axis[p_id].fill_between(t_measurements, np.percentile(y2_full, 2.5, axis=0), \n",
    "                                np.percentile(y2_full, 97.5, axis=0), \n",
    "                                alpha=0.2, color='red')\n",
    "        axis[p_id].plot(t_measurements, np.median(y2_full, axis=0), 'red')\n",
    "        y, _, _, _ = convert_output_to_simulation(test_patients[p_id])\n",
    "        axis[p_id].scatter(y[:, -1], y[:, 1], color='red')\n",
    "        \n",
    "        axis[p_id].vlines(doses_time_points, axis[p_id].get_ylim()[0], axis[p_id].get_ylim()[1],\n",
    "                          color='grey', alpha=0.1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2e349c2174fd68f"
  },
  {
   "cell_type": "raw",
   "source": [
    "pop_mean_monolix = np.array([-2.93353166411073, 6.31425341363383, 0.964473501759479, -13.7105711552498,\n",
    "                         -4.47952481537895, np.log(0.00476513494336853), np.log(0.233158512113676)])\n",
    "print(pop_mean_monolix)\n",
    "print(np.exp(pop_mean_monolix))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7879ba14f2751275"
  },
  {
   "cell_type": "raw",
   "source": [
    "from models.clairon_small_model import uniform_prior\n",
    "prior_bounds = model.prior_bounds.copy()\n",
    "#print(np.diff(prior_bounds))\n",
    "print(prior_bounds)\n",
    "prior_bounds[:, 1] = 7\n",
    "prior_bounds[:, 0] = -5\n",
    "prior_bounds[-2, 0] = -15\n",
    "prior_bounds[-2, 1] = -15\n",
    "prior_bounds[-1, 1] = 0\n",
    "prior_bounds[-3, 1] = 0\n",
    "#print(np.diff(prior_bounds))\n",
    "print(prior_bounds)\n",
    "\n",
    "param_batch = uniform_prior(prior_bounds=prior_bounds, batch_size=25)\n",
    "#param_batch = np.repeat(pop_mean_monolix[np.newaxis, :], repeats=20, axis=0)\n",
    "\n",
    "print(param_batch.shape)\n",
    "\n",
    "test_patients = batch_simulator(param_batch=param_batch)\n",
    "patients_posterior_draws = model.draw_posterior_samples(data=test_patients, n_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d44100f099efe64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'clairon' in model_name:\n",
    "    rows = 5\n",
    "    fig, ax = plt.subplots(rows, int(np.ceil(len(test_patients) / rows)), sharex='all', sharey='all',\n",
    "                           tight_layout=True, figsize=(10, rows*3))\n",
    "    axis = ax.flatten()\n",
    "    t_measurements = np.linspace(0, 700, 100)\n",
    "    \n",
    "    for p_id in tqdm(range(len(test_patients))):\n",
    "        _, _, dose_amount, doses_time_points = convert_to_observables(test_patients[p_id])\n",
    "        sim_data = batch_simulator(patients_posterior_draws[p_id],\n",
    "                            t_measurements=t_measurements,\n",
    "                            t_doses=doses_time_points,\n",
    "                            dose_amount=dose_amount,\n",
    "                            with_noise=False,\n",
    "                            convert_to_bf_batch=False)\n",
    "        axis[p_id].fill_between(t_measurements, np.percentile(sim_data, 2.5, axis=0), \n",
    "                                np.percentile(sim_data, 97.5, axis=0), \n",
    "                                alpha=0.2)\n",
    "        axis[p_id].vlines(doses_time_points, 0, 2500, color='grey', linestyles='--', alpha=0.5)\n",
    "        axis[p_id].plot(t_measurements, np.median(sim_data, axis=0), 'r')\n",
    "    \n",
    "        y, t_measurements_obs, _, _ = convert_to_observables(test_patients[p_id])\n",
    "        axis[p_id].scatter(t_measurements_obs, y, color='g')\n",
    "        #axis[p_id].set_yscale('log')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe342a5dc4aa4a95"
  },
  {
   "cell_type": "markdown",
   "id": "2a9fa2a8",
   "metadata": {},
   "source": [
    "## Get Posterior Parameter Samples and Plot Them Against True Values\n",
    "\n",
    "If the training is very short, one should see only uniformly distributed estimates.\n",
    "\n",
    "**quick and dirty validation:**\n",
    "\n",
    "\n",
    "If the model can generate data that is quite uninformative, the true posterior means may differ significantly from the ground truth parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb007564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_sims = model.generate_simulations_from_prior(trainer=trainer,\n",
    "                                                 simulator=model.build_simulator(),\n",
    "                                                 n_samples=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posterior_draws = model.draw_posterior_samples(data=new_sims['summary_conditions'], n_samples=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22da05741f24c103"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig_recovery = diagnostics.plot_recovery(post_samples=posterior_draws,\n",
    "#                                         prior_samples=new_sims['parameters'],\n",
    "#                                         param_names=model.log_param_names,\n",
    "#                                         n_row=2)\n",
    "#\n",
    "#if save_plots:\n",
    "#    fig_recovery.savefig(f'plots/calibration/{network_name}_fig_recovery.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d79e3fd645dce7f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sbc = diagnostics.plot_sbc_histograms(post_samples=posterior_draws,\n",
    "                                          prior_samples=new_sims['parameters'],\n",
    "                                          param_names=model.log_param_names)\n",
    "\n",
    "#fig_sbc.axes[-1].set_visible(False)\n",
    "if save_plots:\n",
    "    fig_sbc.savefig(f'plots/calibration/{network_name}_fig_sbc2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed81830",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ecdf_diff = diagnostics.plot_sbc_ecdf(post_samples=posterior_draws,\n",
    "                                          prior_samples=new_sims['parameters'],\n",
    "                                          difference=True,\n",
    "                                          stacked=False,\n",
    "                                          param_names=model.log_param_names)\n",
    "\n",
    "if save_plots:\n",
    "    fig_ecdf_diff.savefig(f'plots/calibration/{network_name}_fig_ecdf_diff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7add029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_posterior = diagnostics.plot_posterior_2d(posterior_draws=posterior_draws[0],\n",
    "                                              prior=model.prior,\n",
    "                                              param_names=model.log_param_names)\n",
    "\n",
    "if save_plots:\n",
    "    fig_posterior.savefig(f'plots/calibration/{network_name}_fig_posterior.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1d8e5",
   "metadata": {},
   "source": [
    "## Get SBC Plots for Different Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37567e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_list = []# [1, 10, 100, 200, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a720630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_sims = model.generate_from_prior(trainer=trainer,\n",
    "#                                     simulator=model.build_simulator(),\n",
    "#                                     n_smaples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de5011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ckpt in ckpt_list:\n",
    "    print('Load checkpoint', ckpt)\n",
    "    # restore checkpoint\n",
    "    trainer.checkpoint.restore(path_store_network + f'/ckpt-{ckpt}')\n",
    "    # sample posterior\n",
    "    posterior_draws = model.draw_posterior_samples(data=new_sims['summary_conditions'], n_samples=250)\n",
    "\n",
    "    # make sbc plots\n",
    "    fig_ecdf_diff = diagnostics.plot_sbc_ecdf(post_samples=posterior_draws,\n",
    "                                              prior_samples=new_sims['parameters'],\n",
    "                                              difference=True,\n",
    "                                              stacked=False,\n",
    "                                              param_names=model.log_param_names)\n",
    "    if save_plots:\n",
    "        fig_ecdf_diff.savefig(f'plots/calibration/epochs_compare/{network_name}_fig_ecdf_diff_{ckpt}_.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5284c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
